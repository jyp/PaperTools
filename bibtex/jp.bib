@inproceedings{abadi_formal_1993,
	author = {Martín Abadi and Luca Cardelli and {Pierre-Louis} Curien},
	address = {Charleston, South Carolina, United States},
	title = {Formal parametric polymorphism},
	isbn = {0-89791-560-7},
	doi = {10.1145/158511.158622},
	abstract = {A polymorphic function is parametric if its behavior does not depend on the type at which it is instantiated. Starting with Reynolds' work, the study of parametricity is typically semantic. In this paper, we develop a syntactic approach to parametricity, and a formal system that embodies this approach: system R . Girard's system F deals with terms and types; R is an extension of F that deals also with relations between types. In R **, it is possible to derive theorems about functions from their types, or “theorems for free”, as Wadler calls them. An easy “theorem for free” asserts that the type {∀X.X→ Bool} contains only constant functions; this is not provable in F. There are many harder and more substantial examples. Various metatheorems can also be obtained, such as a syntactic version of Reynolds' abstraction theorem.},
	booktitle = {Proceedings of the 20th {ACM} {SIGPLAN-SIGACT} symposium on Principles of programming languages},
	publisher = {{ACM}},
	year = {1993},
	pages = {157--170}
},

@inproceedings{abadi_core_1999,
	author = {M. Abadi and A. Banerjee and N. Heintze and J.G. Riecke},
	file = {:/home/bernardy/Papers/A core calculus of dependency-1999.pdf:pdf},
	title = {A core calculus of dependency},
	booktitle = {Proceedings of the 26th {ACM} {SIGPLAN-SIGACT} symposium on Principles of programming languages},
	pages = {147--160},
	year = {1999},
	organization = {ACM}
},

@inproceedings{abadi_tensorflow_2016,
	author = {Martín Abadi and Paul Barham and Jianmin Chen and Zhifeng Chen and Andy Davis and Jeffrey Dean and Matthieu Devin and Sanjay Ghemawat and Geoffrey Irving and Michael Isard and Manjunath Kudlur and Josh Levenberg and Rajat Monga and Sherry Moore and Derek G. Murray and Benoit Steiner and Paul Tucker and Vijay Vasudevan and Pete Warden and Martin Wicke and Yuan Yu and Xiaoqiang Zheng},
	title = {TensorFlow: A System for Large-Scale Machine Learning.},
	booktitle = {OSDI},
	volume = {16},
	pages = {265--283},
	year = {2016}
},

@incollection{abbott_categories_2003,
	author = {Michael Abbott and Thorsten Altenkirch and Neil Ghani},
	series = {Lecture Notes in Computer Science},
	title = {Categories of Containers},
	volume = {2620},
	isbn = {0302-9743},
	doi = {10.1007/3-540-36576-1_2},
	abstract = {We introduce the notion of containers as a mathematical formalisation of the idea that many important datatypes consist of
templates where data is stored. We show that containers have good closure properties under a variety of constructions including
the formation of initial algebras and final coalgebras. We also show that containers include strictly positive types and shapely
types but that there are containers which do not correspond to either of these. Further, we derive a representation result
classifying the nature of polymorphic functions between containers. We finish this paper with an application to the theory
of shapely types and refer to a forthcoming paper which applies this theory to differentiable types.},
	booktitle = {Foundations of Software Science and Computation Structures},
	publisher = {Springer, Heidelberg},
	year = {2003},
	pages = {23--38}
},

@article{abbott_data_2004,
	author = {Michael Abbott and Thorsten Altenkirch and Conor {McBride} and Neil Ghani},
	title = {∂ for Data: Differentiating Data Structures},
	volume = {65},
	shorttitle = {∂ for Data},
	url = {http://portal.acm.org/citation.cfm?id=1227145},
	abstract = {This paper and our conference paper {(Abbott,} Altenkirch, Ghani, and {McBride,} 2003b) explain and analyse the notion of the derivative of a data structure as the type of its one-hole contexts based on the central observation made by {McBride} (2001). To make the idea precise we need a generic notion of a data type, which leads to the notion of a container, introduced in {(Abbott,} Altenkirch, and Ghani, 2003a) and investigated extensively in {(Abbott,} 2003). Using containers we can provide a notion of linear map which is the concept missing from {McBride's} first analysis. We verify the usual laws of differential calculus including the chain rule and establish laws for initial algebras and terminal coalgebras.},
	number = {1-2},
	journal = {Fundam. Inf.},
	year = {2004},
	pages = {1--28}
},

@inproceedings{abel_semi-continuous_2006,
	author = {Andreas Abel},
	title = {Semi-continuous Sized Types and Termination},
	booktitle = {CSL},
	year = {2006},
	pages = {72-88},
	ee = {http://dx.doi.org/10.1007/11874683_5},
	bibsource = {DBLP, http://dblp.uni-trier.de}
},

@article{abel_normalization_2007,
	author = {Andreas Abel and Klaus Aehlig and Peter Dybjer},
	file = {:/home/bernardy/Papers/Normalization by Evaluation for Martin-Löf Type Theory with One Universe-2007.pdf:pdf},
	title = {Normalization by Evaluation for {Martin-Löf} Type Theory with One Universe},
	journal = {Electronic Notes Theoretical Computer Science},
	volume = {173},
	year = {2007},
	issn = {1571-0661},
	pages = {17--39},
	doi = {http://dx.doi.org/10.1016/j.entcs.2007.02.025},
	publisher = {Elsevier Science Publishers B. V.},
	address = {Amsterdam, The Netherlands, The Netherlands}
},

@conference{abel_algebraic_2008,
	author = {Andreas Abel and Thierry Coquand and Peter Dybjer},
	file = {:/home/bernardy/Papers/On the algebraic foundation of proof assistants for intuitionistic type theory-2008.pdf:pdf},
	title = {{On the algebraic foundation of proof assistants for intuitionistic type theory}},
	booktitle = {Proceedings of the 9th international conference on Functional and logic programming},
	pages = {3--13},
	year = {2008},
	organization = {Springer-Verlag}
},

@article{abel_modular_2009,
	author = {Andreas Abel and Thierry Coquand and Miguel Pagano},
	file = {:/home/bernardy/Papers/A modular type-checking algorithm for type theory with singleton types and proof irrelevance-2009.pdf:pdf},
	doi = {10.1007/978-3-642-02273-9_3},
	journal = {Logical Methods in Computer Science},
	keywords = {normalisation-by-evaluation,proof,singleton types,type theory,type-checking},
	pages = {1--51},
	title = {{A modular type-checking algorithm for type theory with singleton types and proof irrelevance}},
	year = {2009}
},

@unpublished{abel_miniagda_2010,
	author = {Andreas Abel},
	file = {:/home/bernardy/Papers/MiniAgda Integrating Sized and Dependent Types-2010.pdf:pdf},
	booktitle = {tcs.ifi.lmu.de},
	pages = {1--15},
	title = {{MiniAgda: Integrating Sized and Dependent Types}},
	url = {http://www2.tcs.ifi.lmu.de/\~{}abel/par10.pdf},
	year = {2010}
},

@inproceedings{abel_irrelevance_2011,
	author = {Andreas Abel},
	file = {:/home/bernardy/Papers/Irrelevance in Type Theory with a Heterogeneous Equality Judgement-2011.pdf:pdf},
	title = {Irrelevance in Type Theory with a Heterogeneous Equality Judgement},
	year = {2011},
	series = {Lecture Notes in Computer Science},
	editor = {Martin Hofmann},
	volume = {6604},
	pages = {57--71},
	booktitle = {Foundations Of Software Science And Computational Structures},
	publisher = {Springer}
},

@article{abel_irrelevance_2012,
	author = {Andreas Abel and Gabriel Scherer},
	file = {:/home/bernardy/Papers/On Irrelevance and Algorithmic Equality in Predicative Type Theory-2012.pdf:pdf},
	title = {On Irrelevance and Algorithmic Equality in Predicative Type Theory},
	journal = {Logical Methods in Computer Science},
	volume = {8},
	number = {1},
	year = {2012},
	pages = {1--36},
	note = {TYPES'10 special issue.},
	ee = {http://dx.doi.org/10.2168/LMCS-8(1:29)2012},
	bibsource = {DBLP, http://dblp.uni-trier.de}
},

@article{abel_unified_2020,
	author = {Andreas Abel and Jean-Philippe Bernardy},
	title = {A unified view of modalities in type systems},
	journal = {Proceedings of the ACM on Programming Languages},
	volume = {4},
	number = {ICFP},
	year = {2020},
	publisher = {ACM}
},

@misc{abel_parametric_????,
	author = {Andreas Abel},
	file = {:/home/bernardy/Papers/On Parametric Polymorphism and Irrelevance in Martin-L"of Type Theory-????.pdf:pdf},
	title = {{On Parametric Polymorphism and Irrelevance in Martin-L\"{o}f Type Theory}},
	url = {http://www2.tcs.ifi.lmu.de/\~{}abel/implicit.pdf}
},

@book{abelson_structure_1996,
	author = {Harold Abelson and Gerald Jay Sussman},
	title = {Structure and Interpretation of Computer Programs, second edition},
	isbn = {0-262-51087-1},
	year = {1996},
	publisher = {MIT Press}
},

@article{abramsky_domain_1988,
	author = {Samson Abramsky},
	file = {:/home/bernardy/Papers/Domain Theory In Logical Form-1988.pdf:pdf},
	journal = {Annals of Pure and Applied Logic},
	pages = {1--77},
	title = {{Domain Theory In Logical Form}},
	volume = {51},
	year = {1988}
},

@article{abramsky_computational_1993,
	author = {Samson Abramsky},
	file = {:/home/bernardy/Papers/Computational interpretations of linear logic-1993.pdf:pdf},
	title = {Computational interpretations of linear logic},
	journal = {Theoretical Computer Science},
	volume = {111},
	number = {1},
	pages = {3--57},
	year = {1993},
	publisher = {Elsevier}
},

@article{abramsky_proofs_1994,
	author = {Samson Abramsky},
	title = {Proofs as processes},
	journal = {Theoretical Computer Science},
	volume = {135},
	number = {1},
	pages = {5--9},
	year = {1994},
	publisher = {Elsevier}
},

@inproceedings{abramsky_interaction_1996,
	author = {Samson Abramsky and Simon Gay and Rajagopal Nagarajan},
	title = {Interaction categories and the foundations of typed concurrent programming},
	booktitle = {NATO ASI DPD},
	pages = {35--113},
	year = {1996}
},

@inproceedings{abzianidze_tableau_2015,
	author = {Lasha Abzianidze},
	address = {Lisbon, Portugal},
	title = {A Tableau Prover for Natural Logic and Language},
	url = {https://www.aclweb.org/anthology/D15-1296},
	doi = {10.18653/v1/D15-1296},
	urldate = {2021-03-01},
	booktitle = {Proceedings of the 2015 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	month = {sep},
	year = {2015},
	pages = {2492--2502}
},

@article{abzianidze_learning_2020,
	author = {Lasha Abzianidze},
	title = {Learning as {Abduction}: {Trainable} {Natural} {Logic} {Theorem} {Prover} for {Natural} {Language} {Inference}},
	shorttitle = {Learning as {Abduction}},
	url = {http://arxiv.org/abs/2010.15909},
	abstract = {Tackling Natural Language Inference with a logic-based method is becoming less and less common. While this might have been counterintuitive several decades ago, nowadays it seems pretty obvious. The main reasons for such a conception are that (a) logic-based methods are usually brittle when it comes to processing wide-coverage texts, and (b) instead of automatically learning from data, they require much of manual effort for development. We make a step towards to overcome such shortcomings by modeling learning from data as abduction: reversing a theorem-proving procedure to abduce semantic relations that serve as the best explanation for the gold label of an inference problem. In other words, instead of proving sentence-level inference relations with the help of lexical relations, the lexical relations are proved taking into account the sentence-level inference relations. We implement the learning method in a tableau theorem prover for natural language and show that it improves the performance of the theorem prover on the SICK dataset by 1.4\% while still maintaining high precision ({\textgreater}94\%). The obtained results are competitive with the state of the art among logic-based systems.},
	urldate = {2021-03-02},
	journal = {arXiv:2010.15909 [cs]},
	month = {dec},
	year = {2020},
	note = {arXiv: 2010.15909},
	keywords = {Computer Science - Computation and Language, I.2.7, 03B65, 68T50, F.4.1, I.2.3, I.2.6, K.3.2},
	annote = {Comment: Presented at *SEM, see the official link https://www.aclweb.org/anthology/2020.starsem-1.3 The code available at https://github.com/kovvalsky/LangPro}
},

@book{adams_primer_1998,
	author = {Ernest Adams},
	title = {A Primer of Probability Logic},
	year = {1998},
	publisher = {Stanford: CSLI Publications}
},

@inproceedings{adouane_comparison_2018,
	author = {Wafia Adouane and Jean-Philippe Bernardy and Simon Dobnik and Nasredine Semmar},
	title = {A Comparison of Character Neural Language Model and Bootstrapping for Language Identification in Multilingual Noisy Texts},
	booktitle = {Second Workshop on Subword and Character Level Models in NLP},
	year = {2018}
},

@inproceedings{adouane_improving_2018,
	author = {Wafia Adouane and Jean-Philippe Bernardy and Simon Dobnik and Nasredine Semmar},
	title = {Improving Neural Network Performance by Injecting Background Knowledge: Detecting Code-switching and Borrowing in Algerian texts},
	booktitle = {Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-switching},
	year = {2018}
},

@inproceedings{adouane_neural_2019,
	author = {Wafia Adouane and Jean-Philippe Bernardy and Simon Dobnik},
	title = {Neural Models for Detecting Binary Semantic Textual Similarity for Algerian and MSA},
	booktitle = {Proceedings of The Fourth Arabic Natural Language Processing Workshop},
	year = {2019}
},

@inproceedings{adouane_normalising_2019,
	author = {Wafia Adouane and Jean-Philippe Bernardy and Simon Dobnik},
	title = {Normalising Non-standardised Orthography in Algerian Code-switched User-generated Data},
	booktitle = {Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT)},
	year = {2019}
},

@inproceedings{adouane_identifying_2020,
	author = {Wafia Adouane and Samia Touileb and Jean-Philippe Bernardy},
	title = {Identifying Sentiments in Algerian Code-switched User-generated Comments},
	booktitle = {Proceedings of theLanguage Resources and Evaluation Conference, 2020},
	year = {2020}
},

@phdthesis{adouane_natural_2020,
	author = {Wafia Adouane},
	title = {Natural Language Processing for Low-resourced Code-switched Colloquial Languages – The Case of Algerian Language},
	school = {University of Gothenburg},
	type = {PhD Thesis},
	year = {2020}
},

@inproceedings{adouane_when_2020,
	author = {Wafia Adouane and Jean-Philippe Bernardy},
	title = {When is Multi-task Learning Beneficial for Low-Resource Noisy Code-switched User-generated Algerian Texts?},
	booktitle = {Proceedings of the Fourth Workshop on Computational Approaches to Linguistic Code-Switching},
	year = {2020}
},

@book{admek_abstract_1990,
	author = {J. Adámek and H. Herrlich and G.E. Strecker},
	file = {:/home/bernardy/Papers/Abstract and concrete categories The joy of cats-1990.pdf:pdf},
	title = {{Abstract and concrete categories: The joy of cats}},
	isbn = {0471609226},
	year = {1990},
	publisher = {Wiley}
},

@inproceedings{ager_functional_2003,
	author = {Mads Ager and Dariusz Biernacki and Olivier Danvy and Jan Midtgaard},
	title = {A functional correspondence between evaluators and abstract machines},
	isbn = {1581137052},
	url = {http://dx.doi.org/10.1145/888251.888254},
	booktitle = {{PPDP} '03: Proceedings of the 5th {ACM} {SIGPLAN} international conference on Principles and practice of declaritive programming},
	publisher = {{ACM} Press},
	year = {2003},
	keywords = {cps},
	pages = {8--19}
},

@article{ager_functional_2004,
	author = {Mads Ager and Olivier Danvy and Jan Midtgaard},
	file = {:/home/bernardy/Papers/A functional correspondence between call-by-need evaluators and lazy abstract machines-2004.pdf:pdf},
	title = {A functional correspondence between call-by-need evaluators and lazy abstract machines},
	doi = {10.1016/j.ipl.2004.02.012},
	volume = {90},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0020019004000638},
	abstract = {We bridge the gap between compositional evaluators and abstract machines for the lambda-calculus, using closure conversion, transformation into continuation-passing style, and defunctionalization of continuations. This article is a followup of our article at {PPDP} 2003, where we consider call by name and call by value. Here, however, we consider call by need. We derive a lazy abstract machine from an ordinary call-by-need evaluator that threads a heap of updatable cells. In this resulting abstract machine, the continuation fragment for updating a heap cell naturally appears as an [`]update marker', an implementation technique that was invented for the Three Instruction Machine and subsequently used to construct lazy variants of Krivine's abstract machine. Tuning the evaluator leads to other implementation techniques such as unboxed values. The correctness of the resulting abstract machines is a corollary of the correctness of the original evaluators and of the program transformations used in the derivation.},
	number = {5},
	journal = {Information Processing Letters},
	month = {jun},
	year = {2004},
	keywords = {abstract machines,closure conversion,cps transformation,functional programming,interpreters,program derivation},
	keywords = {cps, defunc},
	pages = {223--232},
	see = {:ager_functional_2003}
},

@article{ahmed_linear_2007,
	author = {Amal Ahmed and Matthew Fluet and Greg Morrisett},
	title = {L$^3$: A Linear Language with Locations},
	journal = {Fundamenta Informaticae},
	volume = {77},
	number = {4},
	pages = {397--449},
	year = {2007},
	publisher = {IOS Press}
},

@inproceedings{ahn_verbosity_2006,
	author = {Luis von Ahn and Mihir Kedia and Manuel Blum},
	title = {Verbosity: a game for collecting common-sense facts},
	booktitle = {{CHI}},
	pages = {75--78},
	publisher = {{ACM}},
	year = {2006}
},

@book{aho_theory_1972,
	author = {Alfred V. Aho and Jeffrey D. Ullman},
	title = {The Theory of Parsing, Translation and Compiling},
	year = {1972},
	volume = {1},
	publisher = {Prentice-Hall},
	address = {Englewood Cliffs, NJ}
},

@book{aigner_proofs_2009,
	author = {Martin Aigner and Gnter M. Ziegler},
	title = {Proofs from THE BOOK},
	year = {2009},
	isbn = {3642008550},
	publisher = {Springer Publishing Company, Incorporated},
	edition = {4th}
},

@phdthesis{alberti_abstract_1997,
	author = {Francisco J. Alberti},
	file = {:/home/bernardy/Papers/An abstract machine based on linear logic and explicit substitutions-1997.Yms:Yms},
	title = {An abstract machine based on linear logic and explicit substitutions},
	year = {1997},
	type = {Master Thesis},
	school = {The University of Birmingham}
},

@inproceedings{algehed_encoding_2017,
	author = {Maximilian Algehed and Alejandro Russo},
	title = {Encoding DCC in Haskell},
	booktitle = {Proceedings of the 2017 Workshop on Programming Languages and Analysis for Security},
	pages = {77--89},
	year = {2017},
	organization = {ACM}
},

@inproceedings{algehed_perspective_2018,
	author = {Maximilian Algehed},
	title = {A Perspective on the Dependency Core Calculus},
	booktitle = {Proceedings of the 13th Workshop on Programming Languages and Analysis
               for Security, PLAS@CCS 2018, Toronto, ON, Canada, October 15-19, 2018},
	pages = {24--28},
	year = {2018},
	crossref = {DBLP:conf/ccs/2018plas},
	url = {https://doi.org/10.1145/3264820.3264823},
	doi = {10.1145/3264820.3264823},
	timestamp = {Wed, 10 Apr 2019 15:29:55 +0200},
	biburl = {https://dblp.org/rec/bib/conf/ccs/Algehed18},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@inproceedings{algehed_optimising_2019,
	author = {Maximilian Algehed and Alejandro Russo and Cormac Flanagan},
	title = {Optimising Faceted Secure Multi-Execution},
	booktitle = {32nd {IEEE} Computer Security Foundations Symposium, {CSF} 2019, Hoboken,
               NJ, USA, June 25-28, 2019},
	pages = {1--16},
	year = {2019},
	crossref = {DBLP:conf/csfw/2019},
	url = {https://doi.org/10.1109/CSF.2019.00008},
	doi = {10.1109/CSF.2019.00008},
	timestamp = {Wed, 16 Oct 2019 14:14:49 +0200},
	biburl = {https://dblp.org/rec/bib/conf/csfw/AlgehedRF19},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@article{algehed_simple_2019,
	author = {Maximilian Algehed and Jean-Philippe Bernardy},
	title = {Simple noninterference from parametricity},
	journal = {Proceedings of the ACM on Programming Languages},
	volume = {3},
	number = {ICFP},
	pages = {89},
	year = {2019},
	publisher = {ACM}
},

@inproceedings{algehed_dynamic_2021,
	author = {Maximilian Algehed and Jean-Philippe Bernardy and Cătălin Hrițcu},
	title = {Dynamic IFC Theorems for Free!},
	booktitle = {Proceedings of the 34th IEEE Computer Security Foundations Symposium},
	pages = {?},
	year = {2021},
	publisher = {IEEE}
},

@article{allison_lazy_1992,
	author = {L. Allison},
	file = {:/home/bernardy/Papers/Lazy Dynamic-Programming Can Be Eager-1992.ps:ps},
	title = {Lazy {Dynamic-Programming} Can Be Eager},
	volume = {43},
	number = {4},
	journal = {Information Processing Letters},
	year = {1992},
	pages = {207--212}
},

@inproceedings{altenkirch_monadic_1999,
	author = {Thorsten Altenkirch and Bernhard Reus},
	file = {:/home/bernardy/Papers/Monadic presentations of lambda terms using generalized inductive types-1999.pdf:pdf},
	title = {Monadic presentations of lambda terms using generalized inductive types},
	booktitle = {Computer Science Logic},
	pages = {453--468},
	year = {1999},
	organization = {Springer}
},

@inproceedings{altenkirch_generic_2003,
	author = {Thorsten Altenkirch and Conor {McBride}},
	title = {Generic Programming within Dependently Typed Programming},
	isbn = {1402073747},
	url = {http://portal.acm.org/citation.cfm?id=647100.717294},
	booktitle = {Proceedings of the {IFIP} {TC2/WG2.1} Working Conference on Generic Programming},
	publisher = {Kluwer, {B.V.}},
	year = {2003},
	keywords = {aop, generic},
	pages = {1--20}
},

@inproceedings{altenkirch_normalization_2004,
	author = {Thorsten Altenkirch and Tarmo Uustalu},
	title = {Normalization by Evaluation for lambda$^{\mbox{-2}}$},
	booktitle = {FLOPS},
	year = {2004},
	pages = {260-275},
	ee = {http://dx.doi.org/10.1007/978-3-540-24754-8_19},
	bibsource = {DBLP, http://dblp.uni-trier.de}
},

@unpublished{altenkirch_dependent_2005,
	author = {T. Altenkirch and C. {McBride} and J. {McKinna}},
	title = {Why dependent types matter},
	url = {http://www.cs.nott.ac.uk/~txa/publ/ydtm.pdf},
	year = {2005},
	see = {talk:mckinna_dependent_2006}
},

@inproceedings{altenkirch_observational_2007,
	author = {T. Altenkirch and C. McBride and W. Swierstra},
	file = {:/home/bernardy/Papers/Observational equality, now!-2007.pdf:pdf},
	title = {Observational equality, now!},
	booktitle = {the 2nd {ACM} {SIGPLAN} workshop on Programming languages meets program verification},
	pages = {57--68},
	year = {2007},
	organization = {ACM}
},

@inproceedings{altenkirch_pisigma_2010,
	author = {Thorsten Altenkirch and Nils Anders Danielsson and Andres L{\"o}h and Nicolas Oury},
	title = {PiSigma: Dependent Types without the Sugar},
	booktitle = {FLOPS},
	year = {2010},
	pages = {40-55},
	ee = {http://dx.doi.org/10.1007/978-3-642-12251-4_5},
	crossref = {DBLP:conf/flops/2010},
	bibsource = {DBLP, http://dblp.uni-trier.de}
},

@article{altenkirch_generic_????,
	author = {Thorsten Altenkirch and Conor Mcbride and Peter Morris},
	file = {:/home/bernardy/Papers/Generic Programming with Dependent Types-????.pdf:pdf},
	title = {{Generic Programming with Dependent Types}}
},

@inproceedings{amorim_semantic_2017,
	author = {Arthur Azevedo de Amorim and Marco Gaboardi and Justin Hsu and Shin{-}ya Katsumata and Ikram Cherigui},
	title = {A semantic account of metric preservation},
	booktitle = {Proceedings of the 44th {ACM} {SIGPLAN} Symposium on Principles of
               Programming Languages, {POPL} 2017, Paris, France, January 18-20,
               2017},
	pages = {545--556},
	year = {2017},
	crossref = {DBLP:conf/popl/2017},
	url = {http://dl.acm.org/citation.cfm?id=3009890},
	timestamp = {Tue, 06 Nov 2018 11:07:42 +0100},
	biburl = {https://dblp.org/rec/conf/popl/AmorimGHKC17.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@article{andreoli_logic_1992,
	author = {Jean-Marc Andreoli},
	title = {Logic programming with focusing proofs in linear logic},
	journal = {Journal of Logic and Computation},
	volume = {2},
	number = {3},
	pages = {297--347},
	year = {1992},
	publisher = {Oxford Univ Press}
},

@inproceedings{angeli_naturalli_2014,
	author = {Gabor Angeli and Christopher D Manning},
	title = {NaturalLI: Natural Logic Inference for Common Sense Reasoning.},
	booktitle = {Proceedings of EMNLP},
	pages = {534-545},
	year = {2014}
},

@inproceedings{angelov_visual_2005,
	author = {Krasimir Angelov and Simon Marlow},
	address = {Tallinn, Estonia},
	title = {Visual haskell: a full-featured haskell development environment},
	isbn = {{159593071X}},
	url = {http://dx.doi.org/10.1145/1088348.1088350},
	booktitle = {Haskell '05: Proceedings of the 2005 {ACM} {SIGPLAN} workshop on Haskell},
	publisher = {{ACM}},
	year = {2005},
	keywords = {haskell},
	pages = {5--16}
},

@inproceedings{ankner_edsl_2013,
	author = {Johan Ankner and Josef David Svenningsson},
	title = {An EDSL approach to high performance Haskell programming},
	booktitle = {Proceedings of the 2013 ACM SIGPLAN symposium on Haskell},
	pages = {1--12},
	year = {2013},
	organization = {ACM}
},

@article{apiwattanapong_jdiff_2007,
	author = {Taweesup Apiwattanapong and Alessandro Orso and Mary Jean Harrold},
	file = {:/home/bernardy/Papers/JDiff A differencing technique and tool for object-oriented programs-2007.pdf:pdf},
	doi = {10.1007/s10515-006-0002-0},
	issn = {0928-8910},
	journal = {Automated Software Engineering},
	month = {dec},
	number = {1},
	pages = {3--36},
	title = {{JDiff: A differencing technique and tool for object-oriented programs}},
	url = {http://www.springerlink.com/index/10.1007/s10515-006-0002-0},
	volume = {14},
	year = {2007}
},

@book{appel_compiling_1992,
	author = {Andrew W Appel},
	title = {Compiling with continuations},
	year = {1992},
	publisher = {Cambridge University Press}
},

@inproceedings{arts_testing_2006,
	author = {Thomas Arts and John Hughes and Joakim Johansson and Ulf Wiger},
	address = {Portland, Oregon, {USA}},
	title = {Testing telecoms software with quviq {QuickCheck}},
	isbn = {1-59593-490-1},
	url = {http://portal.acm.org/citation.cfm?id=1159792},
	doi = {10.1145/1159789.1159792},
	abstract = {We present a case study in which a novel testing tool, Quviq {QuickCheck,} is used to test an industrial implementation of the Megaco protocol. We considered positive and negative testing and we used our developed specification to test an old version in order to estimate how useful {QuickCheck} could potentially be when used early in {development.The} results of the case study indicate that, by using Quviq {QuickCheck,} we would have been able to detect faults early in the {development.We} detected faults that had not been detected by other testing techniques. We found unclarities in the specifications and potential faults when the software is used in a different setting. The results are considered promising enough to Ericsson that they are investing in an even larger case study, this time from the beginning of the development of a new product.},
	booktitle = {Proceedings of the 2006 {ACM} {SIGPLAN}  workshop on Erlang},
	publisher = {{ACM}},
	year = {2006},
	keywords = {property based testing, test automation},
	pages = {2--10}
},

@misc{asklund_identifying_1994,
	author = {U Asklund},
	title = {Identifying conflicts during structural merge},
	url = {http://citeseer.ist.psu.edu/asklund94identifying.html},
	abstract = {. This paper presents a model for controlling the evolution of documents concurrently developed by teams of authors. Optimistic check-out of revisions and alternatives, and hierarchic merge making use of default rules is presented. In particular the different situations occurring during a merge of parallel development lines and the benefit of storing the full evolution history is discussed. 1 Introduction To cooperate have always been hard. Now when the cooperating persons may be spread all...},
	year = {1994},
	keywords = {vc},
	annote = {{\textless}p{\textgreater}older version of other paper by Asklund{\textless}/p{\textgreater}}
},

@book{asperti_categories_1991,
	author = {Andrea Asperti and Giuseppe Longo},
	file = {:/home/bernardy/Papers/Categories, types and structure-1991.pdf:pdf},
	booktitle = {Computing},
	publisher = {MIT Press},
	title = {{Categories, types and structure}},
	year = {1991}
},

@misc{asperti_modified_2006,
	author = {Andrea Asperti and Enrico Tassi},
	file = {:/home/bernardy/Papers/Modified Realizability and Inductive Types-2006.pdf:pdf},
	title = {{Modified Realizability and Inductive Types}},
	institution = {Department of Computer Science, University of Bologna},
	year = {2006}
},

@inproceedings{athiwaratkun_modeling_2018,
	author = {Ben Athiwaratkun and Andrew Gordon Wilson},
	title = {On Modeling Hierarchical Data via Probabilistic Order Embeddings},
	booktitle = {International Conference on Learning Representations},
	year = {2018}
},

@inproceedings{atkey_unembedding_2009,
	author = {Robert Atkey and Sam Lindley and Jeremy Yallop},
	file = {:/home/bernardy/Papers/Unembedding domain-specific languages-2009.pdf:pdf},
	title = {Unembedding domain-specific languages},
	booktitle = {Proceedings of the 2nd ACM SIGPLAN symposium on Haskell},
	year = {2009},
	isbn = {978-1-60558-508-6},
	location = {Edinburgh, Scotland},
	pages = {37--48},
	numpages = {12},
	url = {http://doi.acm.org/10.1145/1596638.1596644},
	doi = {http://doi.acm.org/10.1145/1596638.1596644},
	acmid = {1596644},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {domain-specific languages, higher-order abstract syntax, type classes, unembedding}
},

@inproceedings{atkey_when_2010,
	author = {Robert Atkey and Patricia Johann and Neil Ghani},
	title = {When is a Type Refinement an Inductive Type?},
	year = {2010},
	series = {Lecture Notes in Computer Science},
	editor = {Martin Hofmann},
	volume = {6604},
	pages = {72--87},
	booktitle = {Foundations Of Software Science And Computational Structures},
	publisher = {Springer}
},

@misc{atkey_relational_2010,
	author = {Robert Atkey},
	file = {:/home/bernardy/Papers/Relational Parametricity for Higher Kinds-2010.pdf:pdf},
	booktitle = {Identities},
	title = {{Relational Parametricity for Higher Kinds}},
	year = {2010}
},

@inproceedings{atkey_relationally_2014,
	author = {Robert Atkey and Neil Ghani and Patricia Johann},
	title = {A relationally parametric model of dependent type theory},
	booktitle = {The 41st Annual {ACM} {SIGPLAN-SIGACT} Symposium on Principles of
               Programming Languages, {POPL} '14, San Diego, CA, USA, January 20-21,
               2014},
	pages = {503--516},
	year = {2014},
	crossref = {DBLP:conf/popl/2014},
	url = {http://doi.acm.org/10.1145/2535838.2535852},
	doi = {10.1145/2535838.2535852},
	timestamp = {Thu, 09 Jan 2014 08:32:32 +0100},
	biburl = {http://dblp.uni-trier.de/rec/bib/conf/popl/AtkeyGJ14},
	bibsource = {dblp computer science bibliography, http://dblp.org}
},

@inproceedings{atkey_syntax_2018,
	author = {Robert Atkey},
	title = {Syntax and Semantics of Quantitative Type Theory},
	booktitle = {Proceedings of the 33rd Annual {ACM/IEEE} Symposium on Logic in Computer
               Science, {LICS} 2018, Oxford, UK, July 09-12, 2018},
	pages = {56--65},
	year = {2018},
	crossref = {DBLP:conf/lics/2018},
	url = {https://doi.org/10.1145/3209108.3209189},
	doi = {10.1145/3209108.3209189},
	timestamp = {Wed, 21 Nov 2018 12:44:18 +0100},
	biburl = {https://dblp.org/rec/conf/lics/Atkey18.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@InProceedings{atkey_linear_2019,
	author = {Robert Atkey and James Wood},
	title = {Linear metatheory via linear algebra},
	booktitle = {25th International Conference on Types for Proofs and Programs},
	year = {2019}
},

@inproceedings{atkey_syntax_????,
	author = {Robert Atkey},
	title = {Syntax For Free: Representing Syntax with Binding using Parametricity}
},

@inproceedings{augustsson_cayenne_1998,
	author = {Lennart Augustsson},
	file = {:/home/bernardy/Papers/Cayenne---a language with dependent types-1998.pdf:pdf},
	title = {Cayenne --- a language with dependent types},
	booktitle = {ICFP '98: Proceedings of the third ACM SIGPLAN international conference on Functional Programming},
	year = {1998},
	isbn = {1-58113-024-4},
	pages = {239--250},
	location = {Baltimore, Maryland, United States},
	doi = {http://doi.acm.org/10.1145/289423.289451},
	publisher = {ACM},
	address = {New York, NY, USA}
},

@book{austern_generic_1998,
	author = {Matthew Austern},
	title = {Generic programming and the {STL:} using and extending the C++ Standard Template Library},
	isbn = {0201309564},
	url = {http://portal.acm.org/citation.cfm?id=288771},
	publisher = {{Addison-Wesley} Longman Publishing Co., Inc.},
	year = {1998},
	keywords = {concept}
},

@book{awodey_category_2010,
	author = {Steve Awodey},
	title = {Category theory},
	isbn = {0199587361},
	year = {2010},
	publisher = {Oxford Univ Press}
},

@inproceedings{axelsson_feldspar_2010,
	author = {Emil Axelsson and Koen Claessen and Gergely D{\'e}vai and Zolt{\'a}n Horv{\'a}th and Karin Keijzer and Bo Lyckeg{\aa}rd and Anders Persson and Mary Sheeran and Josef Svenningsson and Andr{\'a}s Vajda},
	title = {Feldspar: A domain specific language for digital signal processing algorithms},
	booktitle = {Formal Methods and Models for Codesign (MEMOCODE)},
	pages = {169--178},
	year = {2010},
	organization = {IEEE}
},

@unpublished{azero_optimal_1998,
	author = {Pablo R. Azero and S. Doaitse Swierstra},
	type = {manuscript},
	title = {Optimal Pretty Printing Combinators},
	year = {1998},
	note = {Submitted to ICFP 1998}
},

@inproceedings{baars_typed_2009,
	author = {Arthur Baars and Doaitse Swierstra and Marcos Viera},
	address = {New York, {NY,} {USA}},
	title = {Typed Transformations of Typed Abstract Syntax},
	booktitle = {{TLDI} '09: fourth {ACM} {SIGPLAN} Workshop on Types in Language Design and Implementation},
	year = {2009}
},

@article{backhouse_generic_1999,
	author = {R. Backhouse and P. Jansson and J. Jeuring and L. Meertens},
	title = {Generic programming -- An introduction},
	journal = {Lecture notes in Computer Science},
	year = {1999},
	pages = {28–115}
},

@inproceedings{bagge_axiom-based_2008,
	author = {Anya Helene Bagge and Valentin David and Magne Haveraaen},
	address = {Nashville, {TN,} {USA}},
	title = {Axiom-based testing for {{C++}}},
	isbn = {978-1-60558-220-7},
	url = {http://portal.acm.org/citation.cfm?id=1449814.1449829},
	doi = {10.1145/1449814.1449829},
	abstract = {Axioms, known from program specification, allow program functionality to be described as rules or equations. The draft C++0x standard introduces axioms as part of the new concept feature. We will demonstrate a tool that uses these features for automated unit testing.},
	booktitle = {Companion to the 23rd {ACM} {SIGPLAN} conference on Object-oriented programming systems languages and applications},
	publisher = {{ACM}},
	year = {2008},
	keywords = {axioms, c++, c++0x, concepts, generative programming, mouldable programming, program transformation, specifications, test generation, unit testing},
	pages = {721--722}
},

@article{bahlke_psg_1986,
	author = {Rolf Bahlke and Gregor Snelting},
	title = {The {PSG} system: from formal language definitions to interactive programming environments},
	volume = {8},
	shorttitle = {The {PSG} system},
	url = {http://portal.acm.org/citation.cfm?id=6465.20890},
	doi = {10.1145/6465.20890},
	abstract = {The {PSG} programming system generator developed at the Technical University of Darmstadt produces interactive, language-specific programming environments from formal language definitions. All language-dependent parts of the environment are generated from an entirely nonprocedural specification of the language's syntax, context conditions, and dynamic semantics. The generated environment consists of a language-based editor, supporting systematic program development by named program fragments, an interpreter, and a fragment library system. The major component of the environment is a full-screen editor, which allows both structure and text editing. In structure mode the editor guarantees prevention of both syntactic and semantic errors, whereas in textual mode it guarantees their immediate recognition. {PSG} editors employ a novel algorithm for incremental semantic analysis which is based on unification. The algorithm will immediately detect semantic errors even in incomplete program fragments. The dynamic semantics of the language are defined in denotational style using a functional language based on the lambda calculus. Program fragments are compiled to terms of the functional language which are executed by an interpreter. The {PSG} generator has been used to produce environments for Pascal, {ALGOL} 60, {MODULA-2,} and the formal language definition language itself.},
	number = {4},
	journal = {{ACM} Trans. Program. Lang. Syst.},
	year = {1986},
	pages = {547--576}
},

@article{baker_lively_1992,
	author = {Henry G. Baker},
	title = {Lively linear Lisp: "look ma, no garbage!"},
	journal = {{SIGPLAN} Notices},
	volume = {27},
	number = {8},
	pages = {89--98},
	year = {1992},
	url = {http://doi.acm.org/10.1145/142137.142162},
	doi = {10.1145/142137.142162},
	timestamp = {Thu, 06 Feb 2003 12:29:48 +0100},
	biburl = {http://dblp.uni-trier.de/rec/bib/journals/sigplan/Baker92d},
	bibsource = {dblp computer science bibliography, http://dblp.org}
},

@inproceedings{baker_berkeley_1998,
	author = {Collin F. Baker and Charles J. Fillmore and John B. Lowe},
	title = {The Berkeley FrameNet Project},
	booktitle = {Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics - Volume 1},
	series = {ACL '98},
	year = {1998},
	location = {Montreal, Quebec, Canada},
	pages = {86--90},
	numpages = {5},
	publisher = {Association for Computational Linguistics},
	address = {Stroudsburg, PA, USA}
},

@inproceedings{ballesteros_training_2016,
	author = {Miguel Ballesteros and Yoav Goldberg and Chris Dyer and Noah A. Smith},
	title = {Training with Exploration Improves a Greedy Stack {LSTM} Parser},
	booktitle = {Proceedings of the 2016 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2016, Austin, Texas, USA, November 1-4,
               2016},
	pages = {2005--2010},
	year = {2016},
	crossref = {DBLP:conf/emnlp/2016},
	url = {http://aclweb.org/anthology/D/D16/D16-1211.pdf},
	timestamp = {Fri, 04 Nov 2016 14:45:31 +0100},
	biburl = {http://dblp.org/rec/bib/conf/emnlp/BallesterosGDS16},
	bibsource = {dblp computer science bibliography, http://dblp.org}
},

@article{ballesteros_greedy_2017,
	author = {Miguel Ballesteros and Chris Dyer and Yoav Goldberg and Noah A. Smith},
	title = {Greedy Transition-Based Dependency Parsing with Stack LSTMs},
	journal = {Computational Linguistics},
	volume = {43},
	number = {2},
	pages = {311--347},
	year = {2017},
	url = {https://doi.org/10.1162/COLI_a_00285},
	doi = {10.1162/COLI_a_00285},
	timestamp = {Tue, 26 Sep 2017 19:10:50 +0200},
	biburl = {http://dblp.org/rec/bib/journals/coling/BallesterosDGS17},
	bibsource = {dblp computer science bibliography, http://dblp.org}
},

@inproceedings{bamman_distributed_2014,
	author = {David Bamman and Chris Dyer and Noah A. Smith},
	title = {Distributed {{Representations}} of {{Geographically Situated Language}}},
	booktitle = {Proceedings of the 52nd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 2: {{Short Papers}})},
	year = {2014},
	month = {jun},
	pages = {828--834},
	publisher = {{Association for Computational Linguistics}},
	address = {{Baltimore, Maryland}},
	doi = {10.3115/v1/P14-2134}
},

@article{bamman_gender_2014,
	author = {David Bamman and Jacob Eisenstein and Tyler Schnoebelen},
	title = {Gender Identity and Lexical Variation in Social Media},
	year = {2014},
	volume = {18},
	pages = {135--160},
	issn = {1467-9841},
	doi = {10.1111/josl.12080},
	abstract = {We present a study of the relationship between gender, linguistic style, and social networks, using a novel corpus of 14,000 Twitter users. Prior quantitative work on gender often treats this social variable as a female/male binary; we argue for a more nuanced approach. By clustering Twitter users, we find a natural decomposition of the dataset into various styles and topical interests. Many clusters have strong gender orientations, but their use of linguistic resources sometimes directly conflicts with the population-level language statistics. We view these clusters as a more accurate reflection of the multifaceted nature of gendered language styles. Previous corpus-based work has also had little to say about individuals whose linguistic styles defy population-level gender patterns. To identify such individuals, we train a statistical classifier, and measure the classifier confidence for each individual in the dataset. Examining individuals whose language does not match the classifier's model for their gender, we find that they have social networks that include significantly fewer same-gender social connections and that, in general, social network homophily is correlated with the use of same-gender language markers. Pairing computational methods and social theory thus offers a new perspective on how gender emerges as individuals position themselves relative to audiences, topics, and mainstream gender norms.},
	annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/josl.12080},
	copyright = {\textcopyright{} 2014 John Wiley \& Sons Ltd},
	journal = {Journal of Sociolinguistics},
	keywords = {computational methods,computer-mediated communication,Gender,social media,social networks,style},
	language = {en},
	number = {2}
},

@article{barber_dual_1996,
	author = {Andrew Barber and Gordon Plotkin},
	title = {Dual intuitionistic linear logic},
	journal = {LFCS Report Series-Laboratory for Foundations of Computer Science ECS LFCS},
	year = {1996},
	publisher = {University of Edinburgh, Department of Computer Science, Laboratory for Foundations of Computer Science},
	see = {:hyland_full_1993}
},

@article{barendregt_introduction_1991,
	author = {Hendrik Pieter Barendregt},
	file = {:/home/bernardy/Papers/Introduction to generalized type systems-1991.pdf:pdf},
	title = {{Introduction to generalized type systems}},
	url = {http://cs.anu.edu.au/student/comp3610/lectures/12-SystemF/intro-to-generalised-type-systems.pdf},
	journal = {Journal of Functional Programming},
	volume = {1},
	number = {2},
	pages = {125--154},
	year = {1991}
},

@article{barendregt_lambda_1992,
	author = {Hendrik Pieter Barendregt},
	file = {:/home/bernardy/Papers/Lambda calculi with types-1992.pdf:pdf},
	title = {Lambda calculi with types},
	doi = {10.1.1.26.4391},
	volume = {2},
	journal = {Handbook of logic in computer science},
	year = {1992},
	pages = {117–309}
},

@inproceedings{barendsen_conventional_1993,
	author = {Erik Barendsen and Sjaak Smetsers},
	title = {Conventional and uniqueness typing in graph rewrite systems},
	booktitle = {Foundations of Software Technology and Theoretical Computer Science},
	pages = {41--51},
	year = {1993},
	organization = {Springer}
},

@article{barendsen_uniqueness_1996,
	author = {Erik Barendsen and Sjaak Smetsers and  others},
	title = {Uniqueness typing for functional languages with graph rewriting semantics},
	journal = {Mathematical Structures in Computer Science},
	volume = {6},
	number = {6},
	pages = {579--612},
	year = {1996}
},

@INPROCEEDINGS{barker_continuations_2004,
	author = {Chris Barker and Chung-chieh Shan},
	title = {Continuations in natural language},
	booktitle = {in Proceedings of the fourth ACM SIGPLAN workshop on continuations, Hayo Thielecke},
	year = {2004},
	pages = {55--64}
},

@book{barr_category_1999,
	author = {Michael Barr and Charles Wells},
	edition = {third},
	title = {Category Theory for Computing Science},
	isbn = {0133238091},
	publisher = {Prentice Hall},
	year = {1999}
},

@incollection{barras_implicit_2008,
	author = {Bruno Barras and Bruno Bernardo},
	file = {:/home/bernardy/Papers/The Implicit Calculus of Constructions as a Programming Language with Dependent Types-2008.pdf:pdf},
	title = {The Implicit Calculus of Constructions as a Programming Language with Dependent Types},
	url = {http://www.springerlink.com/index/M84H82904546L265.pdf},
	doi = {10.1007/978-3-540-78499-9_26},
	abstract = {In this paper, we show how Miquel’s Implicit Calculus of Constructions {(ICC)} can be used as a programming language featuring
dependent types. Since this system has an undecidable type-checking, we introduce a more verbose variant, called {ICC*} which fixes this issue. Datatypes and program specifications are enriched with logical assertions (such as preconditions,
postconditions, invariants) and programs are decorated with proofs of those assertions. The point of using {ICC*} rather than the Calculus of Constructions (the core formalism of the Coq proof assistant) is that all of the static information
(types and proof objects) is transparent, in the sense that it does not affect the computational behavior. This is concretized
by a built-in extraction procedure that removes this static information. We also illustrate the main features of {ICC*} on classical examples of dependently typed programs.},
	booktitle = {Foundations of Software Science and Computational Structures},
	publisher = {Springer},
	year = {2008},
	pages = {365--379}
},

@article{barwise_generalised_1981,
	author = {J. Barwise and R. Cooper},
	Journal = {Linguistics and Philosophy},
	Pages = {159--219},
	Title = {Generalised Quantifiers and Natural Language},
	Volume = {4},
	Year = {1981}
},

@article{bastien_theano_2012,
	author = {Fr{\'e}d{\'e}ric Bastien and Pascal Lamblin and Razvan Pascanu and James Bergstra and Ian Goodfellow and Arnaud Bergeron and Nicolas Bouchard and David Warde-Farley and Yoshua Bengio},
	title = {Theano: new features and speed improvements},
	journal = {arXiv preprint arXiv:1211.5590},
	year = {2012}
},

@incollection{batory_program_2007,
	author = {Don Batory},
	file = {:/home/bernardy/Papers/Program Refactoring, Program Synthesis, and Model-Driven Development-2007.pdf:pdf},
	title = {Program Refactoring, Program Synthesis, and {Model-Driven} Development},
	url = {http://www.springerlink.com/index/c0916633k2q4911x.pdf},
	doi = {10.1007/978-3-540-71229-9_11},
	abstract = {Program refactoring, feature-based and aspect-oriented software synthesis, and model-driven development are disjoint research areas. However, they are all architectural metaprogramming technologies as they treat programs as values and use functions (a.k.a. transformations) to map programs to other programs. In this paper, I explore their underlying connections by reviewing recent advances in each area from an architectural metaprogramming perspective. I conjecture how these areas can converge and outline a theory that may unify them.},
	booktitle = {Compiler Construction},
	year = {2007},
	keywords = {calculus, program},
	pages = {156--171},
	annote = {{\textless}p{\textgreater}* Conjectures that refactoring, synthesis and model-driven development will converge (but {NOT} \&quot;how\&quot; as the abstract says) * Review of these areas in the light of the conjecture{\textless}/p{\textgreater}}
},

@article{bauer_what_2019,
	author = {Andrej Bauer},
	title = {What is algebraic about algebraic effects and handlers?},
	url = {http://arxiv.org/abs/1807.05923},
	abstract = {This note recapitulates and expands the contents of a tutorial on the mathematical theory of algebraic effects and handlers which I gave at the Dagstuhl seminar 18172 "Algebraic effect handlers go mainstream". It is targeted roughly at the level of a doctoral student with some amount of mathematical training, or at anyone already familiar with algebraic effects and handlers as programming concepts who would like to know what they have to do with algebra. We draw an uninterrupted line of thought between algebra and computational effects. We begin on the mathematical side of things, by reviewing the classic notions of universal algebra: signatures, algebraic theories, and their models. We then generalize and adapt the theory so that it applies to computational effects. In the last step we replace traditional mathematical notation with one that is closer to programming languages.},
	urldate = {2020-09-08},
	journal = {arXiv:1807.05923 [cs]},
	month = {mar},
	year = {2019},
	note = {arXiv: 1807.05923},
	keywords = {08A70, Computer Science - Logic in Computer Science, Computer Science - Programming Languages}
},

@article{baumgartner_pushshift_2020,
	author = {Jason Baumgartner and Savvas Zannettou and Brian Keegan and Megan Squire and Jeremy Blackburn},
	title = {The {{Pushshift Reddit Dataset}}},
	year = {2020},
	month = {jan},
	abstract = {Social media data has become crucial to the advancement of scientific understanding. However, even though it has become ubiquitous, just collecting large-scale social media data involves a high degree of engineering skill set and computational resources. In fact, research is often times gated by data engineering problems that must be overcome before analysis can proceed. This has resulted recognition of datasets as meaningful research contributions in and of themselves.},
	archiveprefix = {arXiv},
	eprint = {2001.08435},
	eprinttype = {arxiv},
	journal = {arXiv:2001.08435 [cs]},
	keywords = {Computer Science - Computers and Society,Computer Science - Social and Information Networks},
	language = {en},
	primaryclass = {cs}
},

@techreport{becker_working_2007,
	author = {Pete Becker},
	title = {Working Draft, Standard for Programming Language {\textbackslash}{\textbackslash}cpp},
	year = {2007},
	keywords = {sibylle, wgp08}
},

@article{bekki_representing_2014,
	author = {D. Bekki},
	title = {Representing Anaphora with Dependent Types},
	journal = {{LACL 2014, LNCS 8535}},
	OPTvolume = {},
	OPTnumber = {},
	OPTpages = {},
	year = {2014}
},

@incollection{bekki_context-passing_2017,
	author = {Daisuke Bekki and Koji Mineshima},
	title = {Context-passing and underspecification in dependent type semantics},
	booktitle = {Modern Perspectives in Type-Theoretical Semantics},
	editor = {Chatzikyriakidis, Stergios and Luo, Zhaohui},
	pages = {11--41},
	year = {2017},
	publisher = {Springer}
},

@article{bellantoni_new_1992,
	author = {Spephen Bellantoni and Stephen Cook},
	title = {A new recursion-theoretic characterization of the polytime functions},
	journal = {Computational complexity},
	volume = {2},
	number = {2},
	pages = {97--110},
	year = {1992},
	publisher = {Springer}
},

@Article{bellin_-calculus_1994,
	author = {Gianluigi Bellin and Philip J. Scott},
	title = {On the π-calculus and Linear Logic},
	journal = {Theoretical Computer Science},
	year = {1994},
	volume = {135},
	number = {1},
	pages = {11--65}
},

@inproceedings{beltagy_montague_2013,
	author = {Islam Beltagy and Cuong Chau and Gemma Boleda and Dan Garrette and Katrin Erk and Raymond J. Mooney},
	editor = {Mona T. Diab and
               Timothy Baldwin and
               Marco Baroni},
	title = {Montague Meets Markov: Deep Semantics with Probabilistic Logical Form},
	booktitle = {Proceedings of the Second Joint Conference on Lexical and Computational
               Semantics, *SEM 2013, June 13-14, 2013, Atlanta, Georgia, {USA}},
	pages = {11--21},
	publisher = {Association for Computational Linguistics},
	year = {2013},
	url = {https://www.aclweb.org/anthology/S13-1002/},
	timestamp = {Fri, 13 Sep 2019 13:08:46 +0200},
	biburl = {https://dblp.org/rec/conf/starsem/BeltagyCBGEM13.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@ARTICLE{bengio_neural_2003,
	author = {Yoshua Bengio and Réjean Ducharme and Pascal Vincent and Christian Jauvin},
	title = {A Neural Probabilistic Language Model},
	journal = {JOURNAL OF MACHINE LEARNING RESEARCH},
	year = {2003},
	volume = {3},
	pages = {1137--1155}
},

@article{benke_universes_2003,
	author = {Marcin Benke and Peter Dybjer and Patrik Jansson},
	title = {Universes for generic programs and proofs in dependent type theory},
	volume = {10},
	url = {http://portal.acm.org/citation.cfm?id=985801},
	abstract = {We show how to write generic programs and proofs in {Martin-Löf} type theory. To this end we consider several extensions of {Martin-Löf's} logical framework for dependent types. Each extension has a universe of codes (signatures) for inductively defined sets with generic formation, introduction, elimination, and equality rules. These extensions are modeled on Dybjer and Setzer's finitely axiomatized theories of inductive-recursive definitions, which also have universes of codes for sets, and generic formation, introduction, elimination, and equality rules. Here we consider several smaller universes of interest for generic programming and universal algebra. We formalize one-sorted and many-sorted term algebras, as well as iterated, generalized, parameterized, and indexed inductive definitions. We also show how to extend the techniques of generic programming to these universes. Furthermore, we give generic proofs of reflexivity and substitutivity of a generic equality test: Most of the definitions in the paper have been implemented using the proof assistant Alfa for dependent type theory.},
	number = {4},
	journal = {Nordic Journal of Computing},
	year = {2003},
	keywords = {algebraic specifications, dependent types, generic programming, inductive definitions, martin-löf type theory, polytypic programming},
	pages = {265--289}
},

@inproceedings{bentivogli_fifth_2009,
	author = {Luisa Bentivogli and Peter Clark and Ido Dagan and Danilo Giampiccolo},
	title = {The Fifth {PASCAL} Recognizing Textual Entailment Challenge.},
	booktitle = {TAC},
	year = {2009},
	see = {:giampiccolo_fourth_2008}
},

@incollection{benton_term_1993,
	author = {Nick Benton and Gavin Bierman and Valeria De Paiva and Martin Hyland},
	title = {A term calculus for intuitionistic linear logic},
	booktitle = {Typed Lambda Calculi and Applications},
	pages = {75--90},
	year = {1993},
	publisher = {Springer}
},

@phdthesis{berardi_type_1989,
	author = {Stepfano Berardi},
	title = {Type Dependence and Constructive Mathematics},
	school = {Dipartimento di Informatica, Torino},
	year = {1989}
},

@incollection{berger_normalization_1998,
	author = {Ulrich Berger and Matthias Eberl and Helmut Schwichtenberg},
	title = {Normalization by evaluation},
	booktitle = {Prospects for Hardware Foundations},
	pages = {117--137},
	year = {1998},
	publisher = {Springer}
},

@article{berger_refined_2002,
	author = {U. Berger and W. Buchholz and H. Schwichtenberg},
	title = {Refined program extraction from classical proofs},
	journal = {Annals of Pure and Applied Logic},
	volume = {114},
	number = {1-3},
	pages = {3--25},
	issn = {0168-0072},
	year = {2002},
	publisher = {Elsevier}
},

@phdthesis{bernardy_integrating_2000,
	author = {Jean-Philippe Bernardy},
	title = {Integrating Genericity into {Java}},
	school = {Unversité Libre de Bruxelles},
	type = {Master Thesis},
	year = {2000}
},

@phdthesis{bernardy_introducing_2000,
	author = {Jean-Philippe Bernardy},
	title = {Introducing genericity into {Java}},
	school = {Université Libre de Bruxelles},
	type = {Master's Thesis},
	year = {2000}
},

@inproceedings{bernardy_reviving_2002,
	author = {Jean-Philippe Bernardy},
	address = {Oxford, {UK}},
	title = {Reviving Pacbase {COBOL-Generated} Code},
	doi = {http://doi.ieeecomputersociety.org/10.1109/CMPSAC.2002.1045091},
	abstract = {We have migrated a large scale application from Pacbase to {COBOL.} The technique is to apply, in an iterative fashion, a set of small transformation patterns on Pacbase {COBOL-output.} Thus, equivalence with the Pacbase code is easily verified.},
	booktitle = {{COMPSAC} 2002 Proceedings},
	publisher = {IEEE Computer Society},
	year = {2002},
	pages = {741--743}
},

@inproceedings{bernardy_comparison_2008,
	author = {Jean-Philippe Bernardy and Patrik Jansson and Marcin Zalewski and Sibylle Schupp and Andreas Priesnitz},
	address = {Victoria, {BC,} Canada},
	title = {A comparison of {C++} concepts and {Haskell} type classes},
	isbn = {978-1-60558-060-9},
	url = {http://dx.doi.org/10.1145/1411318.1411324},
	abstract = {Earlier studies have introduced a list of high-level evaluation criteria to assess how well a language supports generic programming. Since each language that meets all criteria is considered generic, those criteria are not fine-grained enough to differentiate between languages for generic programming. We refine these criteria into a taxonomy that captures differences between type classes in Haskell and concepts in C++, and discuss which differences are incidental and which ones are due to other language features. The taxonomy allows for an improved understanding of language support for generic programming, and the comparison is useful for the ongoing discussions among language designers and users of both languages.},
	booktitle = {{WGP} '08: Proceedings of the {ACM} {SIGPLAN} workshop on Generic programming},
	publisher = {{ACM}},
	year = {2008},
	keywords = {self},
	pages = {37--48}
},

@inproceedings{bernardy_editor_2008,
	author = {Jean-Philippe Bernardy},
	address = {Victoria, {BC,} Canada},
	title = {Yi: an editor in {{Haskell}} for {{Haskell}}},
	isbn = {978-1-60558-064-7},
	shorttitle = {Yi},
	url = {http://portal.acm.org/citation.cfm?id=1411286.1411294},
	doi = {10.1145/1411286.1411294},
	abstract = {Yi is a text editor written in Haskell and extensible in Haskell. We take advantage of Haskell's expressive power to define embedded {DSLs} that form the foundation of the editor. In turn, these {DSLs} provide a flexible mechanism to create extended versions of the editor. Yi also provides some support for editing Haskell code.},
	booktitle = {Proceedings of the first {ACM} {SIGPLAN} symposium on Haskell},
	publisher = {{ACM}},
	year = {2008},
	keywords = {editor, functional programming},
	pages = {61--62}
},

@inproceedings{bernardy_lazy_2009,
	author = {Jean-Philippe Bernardy},
	address = {Edinburgh, Scotland},
	title = {Lazy functional incremental parsing},
	isbn = {978-1-60558-508-6},
	url = {http://portal.acm.org/citation.cfm?id=1596638.1596645},
	doi = {10.1145/1596638.1596645},
	abstract = {Structured documents are commonly edited using a free-form editor. Even though every string is an acceptable input, it makes sense to maintain a structured representation of the edited document. The structured representation has a number of uses: structural navigation (and optional structural editing), structure highlighting, etc. The construction of the structure must be done incrementally to be efficient: the time to process an edit operation should be proportional to the size of the change, and (ideally) independent of the total size of the document. We show that combining lazy evaluation and caching of intermediate (partial) results enables incremental parsing. We build a complete incremental parsing library for interactive systems with support for error-correction.},
	booktitle = {Proceedings of the 2nd {ACM} {SIGPLAN} symposium on Haskell},
	publisher = {{ACM}},
	year = {2009},
	keywords = {dynamic programming, editor, haskell, incremental computing, lazy evaluation, parsing, polish representation},
	pages = {49--60},
	see = {cites:wagner_efficient_1998;cites:ghezzi_incremental_1979}
},

@phdthesis{bernardy_software_2009,
	author = {Jean-Philippe Bernardy},
	title = {Software engineering using functional programming},
	school = {Chalmers Tekniska Högskola},
	type = {Licenciate Thesis},
	year = {2009}
},

@misc{bernardy_proof_2010,
	author = {Jean-Philippe Bernardy},
	title = {A proof of the Abstraction theorem for pure type systems (unary case)},
	url = {http://www.cse.chalmers.se/~bernardy/ParDep/html/Theorem.html},
	year = {2010},
	howpublished = {\url{http://www.cse.chalmers.se/~bernardy/ParDep/html/Theorem.html}}
},

@unpublished{bernardy_abstraction_2010,
	author = {Jean-Philippe Bernardy and Patrik Jansson and Ross Paterson},
	file = {:/home/bernardy/Papers/An abstraction theorem for pure type systems-2010.pdf:pdf},
	type = {manuscript},
	title = {An abstraction theorem for pure type systems},
	url = {http://www.cse.chalmers.se/~bernardy/ParDep/abstraction-pts.pdf},
	year = {2010},
	note = {Available from \url{http://www.cse.chalmers.se/~bernardy/ParDep/abstraction-pts.pdf}},
	see = {machine_proof:bernardy_proof_2010}
},

@misc{bernardy_derivation_2010,
	author = {Jean-Philippe Bernardy},
	title = {Derivation Trees Haskell Package},
	url = {http://hackage.haskell.org/packages/archive/derivation-trees/},
	abstract = {A library to typeset derivation trees via Laurent Mehats metapost package.
  Also contains a module to ease the generation of trees for (coloured) pure type systems.},
	year = {2010}
},

@article{bernardy_generic_2010,
	author = {Jean-Philippe Bernardy and Patrik Jansson and Marcin Zalewski and Sibylle Schupp},
	title = {Generic programming with {C++} concepts and {Haskell}
                  type classes --- a comparison},
	journal = {Journal of Functional Programming},
	volume = {20},
	number = {3--4},
	pages = {271--302},
	year = {2010},
	doi = {10.1017/S095679681000016X},
	COMMENTURL = {http://dx.doi.org/10.1017/S095679681000016X},
	abstract = {Earlier studies have introduced a list of high-level
                  evaluation criteria to assess how well a language
                  supports generic programming. Languages that meet
                  all criteria include Haskell because of its type
                  classes and C++ with the concept feature. We refine
                  these criteria into a taxonomy that captures
                  commonalities and differences between type classes
                  in Haskell and concepts in C++ and discuss which
                  differences are incidental and which ones are due to
                  other language features. The taxonomy allows for an
                  improved understanding of language support for
                  generic programming, and the comparison is useful
                  for the ongoing discussions among language designers
                  and users of both languages.}
},

@misc{bernardy_lightweight_2010,
	author = {Jean-Philippe Bernardy},
	title = {Lightweight Free Theorems: Agda Library},
	url = {http://wiki.portal.chalmers.se/agda/agda.php?n=Libraries.LightweightFreeTheorems},
	year = {2010},
	howpublished = {\url{http://wiki.portal.chalmers.se/agda/agda.php?n=Libraries.LightweightFreeTheorems}}
},

@inproceedings{bernardy_parametricity_2010,
	author = {Jean-Philippe Bernardy and Patrik Jansson and Ross Paterson},
	address = {Baltimore, Maryland},
	title = {Parametricity and Dependent Types},
	booktitle = {Proceedings of the 15th {ACM} {SIGPLAN} international conference on Functional programming},
	publisher = {{ACM}},
	doi = {10.1145/1863543.1863592},
	pages = {345--356},
	year = {2010}
},

@inproceedings{bernardy_testing_2010,
	author = {Jean-Philippe Bernardy and Patrik Jansson and Koen Claessen},
	affiliation = {Chalmers University of Technology},
	series = {Lecture Notes in Computer Science},
	title = {Testing Polymorphic Properties},
	editor = {Gordon, Andrew},
	volume = {6012},
	pages = {125--144},
	doi = {10.1007/978-3-642-11957-6_8},
	documenturl = {http://www.cse.chalmers.se/~bernardy/PolyTest.pdf},
	abstract = {This paper is concerned with testing properties of
                  polymorphic functions. The problem is that testing
                  can only be performed on specific monomorphic
                  instances, whereas parametrically polymorphic
                  functions are expected to work for any type. We
                  present a schema for constructing a monomorphic
                  instance for a polymorphic property, such that
                  correctness of that single instance implies
                  correctness for all other instances. We also give a
                  formal definition of the class of polymorphic
                  properties the schema can be used for. Compared to
                  the standard method of testing such properties, our
                  schema leads to a significant reduction of necessary
                  test cases.},
	booktitle = {European Symposium on Programming},
	publisher = {Springer},
	year = {2010},
	keywords = {Programvaruteknik}
},

@phdthesis{bernardy_theory_2011,
	author = {Jean-Philippe Bernardy},
	title = {A theory of parametric polymorphism and an application},
	school = {Chalmers Tekniska Högskola},
	type = {PhD Thesis},
	year = {2011}
},

@inproceedings{bernardy_realizability_2011,
	author = {Jean-Philippe Bernardy and Marc Lasson},
	title = {Realizability and Parametricity in {P}ure {T}ype {S}ystems},
	year = {2011},
	series = {Lecture Notes in Computer Science},
	editor = {Martin Hofmann},
	volume = {6604},
	pages = {108--122},
	booktitle = {Foundations Of Software Science And Computational Structures},
	publisher = {Springer}
},

@inproceedings{bernardy_computational_2012,
	author = {Jean-Philippe Bernardy and Guilhem Moulin},
	title = {A Computational Interpretation of Parametricity},
	year = {2012},
	booktitle = {LICS},
	publisher = {IEEE Computer Society}
},

@misc{bernardy_computational_extended_2012,
	author = {Jean-Philippe Bernardy and Guilhem Moulin},
	forcedkey = {bernardy_computational_extended_2012},
	title = {A Computational Interpretation of Parametricity: Extended Version},
	year = {2012},
	howpublished = {Available at \url{http://publications.lib.chalmers.se/cpl/record/index.xsql?pubid=153094}}
},

@Article{bernardy_proofs_2012,
	author = {Jean-Philippe Bernardy and Patrik Jansson and Ross Paterson},
	title = {Proofs for Free --- Parametricity for Dependent
                  Types},
	journal = {Journal of Functional Programming},
	doi = {10.1017/S0956796812000056},
	year = {2012},
	volume = {22},
	number = {02},
	pages = {107--152},
	COMMENTurl = {https://publications.lib.chalmers.se/cpl/record/index.xsql?pubid=135303},
	authoraccess = {http://journals.cambridge.org/repo_A85iFiOy}
},

@inproceedings{bernardy_efficient_2013,
	author = {Jean-Philippe Bernardy and Koen Claessen},
	title = {Efficient Divide-and-Conquer Parsing of Practical Context-Free Languages},
	year = {2013},
	booktitle = {Proceedings of the 18th {ACM} {SIGPLAN} international conference on Functional Programming},
	pages = {111--122}
},

@inproceedings{bernardy_names_2013,
	author = {Jean-Philippe Bernardy and Nicolas Pouillard},
	title = {Names For Free --- Polymorphic Views of Names and Binders},
	year = {2013},
	booktitle = {Proceedings of the 6th {ACM} {SIGPLAN} symposium on {Haskell}},
	publisher = {ACM},
	pages = {13--24}
},

@inproceedings{bernardy_type-theory_2013,
	author = {Jean-Philippe Bernardy and Guilhem Moulin},
	title = {Type-Theory in Color},
	year = {2013},
	booktitle = {Proceedings of the 18th {ACM} {SIGPLAN} international conference on Functional Programming},
	pages = {61--72}
},

@misc{bernardy_compiling_2014,
	author = {Jean-Philippe Bernardy and Dan Rosén and Nick Smallbone},
	title = {Compiling Linear Logic Using Continuations},
	note = {\HREF{Draft Available online}{http://www.cse.chalmers.se/~danr/compiling_linear_logic_using_continuations.pdf}},
	year = {2014}
},

@misc{bernardy_linear_2014,
	author = {Jean-Philippe Bernardy and Josef Svenningsson},
	title = {Linear Logic: I See What It Means!},
	note = {\HREF{Draft available online}{http://www.cse.chalmers.se/~bernardy/LL-ISWIM.pdf}},
	year = {2014}
},

@misc{bernardy_prettiest_2014,
	author = {Jean-Philippe Bernardy},
	title = {The Prettiest Printer},
	year = {2014},
	howpublished = {\HREF{Blog Entry}{http://www.cse.chalmers.se/~bernardy/prettiest.html}}
},

@inproceedings{bernardy_presheaf_2015,
	author = {Jean-Philippe Bernardy and Thierry Coquand and Guilhem Moulin},
	title = {A presheaf model of parametric type theory},
	year = {2015},
	booktitle = {MFPS}
},

@article{bernardy_certified_2015,
	author = {Jean-Philippe Bernardy and Patrik Jansson},
	title = {Certified Context-Free Parsing},
	year = {2015},
	journal = {Logical Methods in Computer Science},
	note = {\HREF{Accepted 2015-12-22, available online}{http://arxiv.org/abs/1601.07724}}
},

@misc{bernardy_composable_2015,
	author = {Jean-Philippe Bernardy and Víctor {López Juan} and Josef Svenningsson},
	title = {Composable Efficient Array Computations Using Linear Types},
	note = {Submitted to ICFP 2015. \HREF{Draft available online}{http://www.cse.chalmers.se/~josefs/publications/vectorcomp.pdf}},
	year = {2015}
},

@misc{bernardy_controlled_2015,
	author = {Jean-Philippe Bernardy and Josef Svenningsson},
	title = {Controlled Array Fusion using Linear Types},
	note = {Submitted to ESOP 2015. \HREF{Draft available online}{http://www.cse.chalmers.se/~bernardy/LL-Fusion.pdf}},
	year = {2015}
},

@article{bernardy_efficient_2015,
	author = {Jean-Philippe Bernardy and Koen Claessen},
	title = {Efficient Parallel and Incremental Parsing of Practical Context-Free Languages},
	volume = {25},
	year = {2015},
	journal = {Journal of Functional Programming},
	issn = {1469-7653},
	doi = {10.1017/S0956796815000131},
	COMMENTURL = {http://journals.cambridge.org/article_S0956796815000131},
	COMMENTnote = {\HREF{preprint available online}{http://www.cse.chalmers.se/~bernardy/PP.pdf} }
},

@misc{bernardy_duality_2015,
	author = {Jean-Philippe Bernardy and Josef Svenningsson},
	title = {On the Duality of Streams},
	note = {\HREF{Latest version available online}{https://github.com/jyp/organ/blob/master/Organ.lhs}},
	year = {2015}
},

@inproceedings{bernardy_type-theoretical_2017,
	author = {Jean-Philippe Bernardy and Stergios Chatzikyriakidis},
	title = {A Type-Theoretical system for the {FraCaS} test suite: Grammatical Framework meets Coq},
	shorttitle = {A {Type}-{Theoretical} system for the {FraCaS} test suite},
	url = {https://www.aclweb.org/anthology/W17-6801},
	urldate = {2021-03-01},
	booktitle = {{IWCS} 2017 - 12th {International} {Conference} on {Computational} {Semantics} - {Long} papers},
	year = {2017}
},

@article{bernardy_functional_2017,
	author = {Jean-Philippe Bernardy},
	title = {Functional Pearl: a pretty but not greedy printer},
	journal = {Proceedings of the ACM on Programming Languages},
	note = {\HREF{Updated version available on the author's homepage}{http://jyp.github.io/pdf/Prettiest.pdf}},
	volume = {1},
	issue = {ICFP},
	year = {2017}
},

@inproceedings{bernardy_modelling_2017,
	author = {Jean-Philippe Bernardy and Charalambos Themistocleous},
	title = {Modelling prosodic structure using Artificial Neural Networks},
	booktitle = {ExLing 2017: 8th Tutorial and Research Workshop on Experimental Linguistics},
	year = {2017}
},

@article{bernardy_using_2017,
	author = {Jean-Philippe Bernardy and Shalom Lappin},
	title = {Using Deep Neural Networks to Learn Syntactic Agreement},
	journal = {Linguistic Issues In Language Technology},
	volume = {15},
	number = {2},
	pages = {15},
	year = {2017},
	issn = {1945-3604}
},

@inproceedings{bernardy_compositional_2018,
	author = {Jean-Philippe Bernardy and Rasmus Blanck and Stergios Chatzikyriakidis and Shalom Lappin},
	address = {Santa Fe, New Mexico, USA},
	Title = {A Compositional {Bayesian} Semantics for Natural Language},
	url = {https://www.aclweb.org/anthology/W18-4101},
	abstract = {We propose a compositional Bayesian semantics that interprets declarative sentences in a natural language by assigning them probability conditions. These are conditional probabilities that estimate the likelihood that a competent speaker would endorse an assertion, given certain hypotheses. Our semantics is implemented in a functional programming language. It estimates the marginal probability of a sentence through Markov Chain Monte Carlo (MCMC) sampling of objects in vector space models satisfying specified hypotheses. We apply our semantics to examples with several predicates and generalised quantifiers, including higher-order quantifiers. It captures the vagueness of predication (both gradable and non-gradable), without positing a precise boundary for classifier application. We present a basic account of semantic learning based on our semantic system. We compare our proposal to other current theories of probabilistic semantics, and we show that it offers several important advantages over these accounts.},
	urldate = {2021-03-01},
	booktitle = {Proceedings of the {First} {International} {Workshop} on {Language} {Cognition} and {Computational} {Models}},
	publisher = {Association for Computational Linguistics},
	month = {aug},
	year = {2018},
	pages = {1--10}
},

@article{bernardy_corpus_2018,
	author = {Jean-Philippe Bernardy and Stergios Chatzikyriakidis},
	title = {A corpus of precise natural textual entailment problems},
	journal = {https://arxiv.org/abs/1812.05813},
	year = {2018}
},

@article{bernardy_can_2018,
	author = {Jean-Philippe Bernardy},
	title = {Can RNNs Learn Nested Recursion?},
	journal = {Linguistic Issues in Language Technology},
	volume = {16},
	issue = {1},
	year = {2018}
},

@article{bernardy_linear_2018,
	author = {Jean-Philippe Bernardy and Arnaud Spiwack and Mathieu Boespflug and Ryan Newton and Simon {Peyton Jones}},
	title = {Linear Haskell: practical linearity in a higher-order polymorphic language},
	year = {2018},
	journal = {Proceedings of the ACM on Programming Languages},
	volume = {2},
	issue = {POPL}
},

@misc{bernardy_influence_2018,
	author = {Jean-Philippe Bernardy and Shalom Lappin},
	title = {The Influence of Context on Sentence Acceptability Judgements},
	booktitle = {Proceedings of the ACL},
	url = {http://aclweb.org/anthology/P18-2073},
	year = {2018}
},

@inproceedings{bernardy_wide-coverage_2019,
	author = {Jean-Philippe Bernardy and Stergios Chatzikyriakidis},
	address = {Turku, Finland},
	title = {A Wide-Coverage Symbolic Natural Language Inference System},
	url = {https://www.aclweb.org/anthology/W19-6131},
	abstract = {We present a system for Natural Language Inference which uses a dynamic semantics converter from abstract syntax trees to Coq types. It combines the fine-grainedness of a dynamic semantics system with the powerfulness of a state-of-the-art proof assistant, like Coq. We evaluate the system on all sections of the FraCaS test suite, excluding section 6. This is the first system that does a complete run on the anaphora and ellipsis sections of the FraCaS. It has a better overall accuracy than any previous system.},
	urldate = {2021-03-01},
	booktitle = {Proceedings of the 22nd {Nordic} {Conference} on {Computational} {Linguistics}},
	publisher = {Linköping University Electronic Press},
	month = {sep},
	year = {2019},
	pages = {298--303}
},

@inproceedings{bernardy_predicates_2019,
	author = {Jean-Philippe Bernardy and Rasmus Blanck and Stergios Chatzikyriakidis and Shalom Lappin and Aleksandre Maskharashvili},
	address = {Turku, Finland},
	title = {Predicates as Boxes in Bayesian Semantics for Natural Language},
	url = {https://www.aclweb.org/anthology/W19-6137},
	abstract = {In this paper, we present a Bayesian approach to natural language semantics. Our main focus is on the inference task in an environment where judgments require probabilistic reasoning. We treat nouns, verbs, adjectives, etc. as unary predicates, and we model them as boxes in a bounded domain. We apply Bayesian learning to satisfy constraints expressed as premises. In this way we construct a model, by specifying boxes for the predicates. The probability of the hypothesis (the conclusion) is evaluated against the model that incorporates the premises as constraints.},
	urldate = {2021-03-01},
	booktitle = {Proceedings of the 22nd {Nordic} {Conference} on {Computational} {Linguistics}},
	publisher = {Linköping University Electronic Press},
	month = {sep},
	year = {2019},
	pages = {333--337}
},

@inproceedings{bernardy_two_2019,
	author = {Jean-Philippe Bernardy and Aleksandre Maskharashvili},
	title = {Two experiments for embedding Wordnet hierarchy into vector spaces},
	year = {2019},
	booktitle = {Proceedings of the 10th Global {WordNet} Conference},
	publisher = {Oficyna Wydawnicza Politechniki Wrocławskiej}
},

@inproceedings{bernardy_what_2019,
	author = {Jean-Philippe Bernardy and Stergios Chatzikyriakidis},
	title = {What Kind of Natural Language Inference are NLP Systems Learning: Is this Enough?},
	booktitle = {Proceedings of the 13th International Conference on Agents and Artificial Intelligence},
	year = {2019}
},

@inproceedings{bernardy_bayesian_2019,
	author = {Jean-Philippe Bernardy and Rasmus Blanck and Stergios Chatzikyriakidis and Shalom Lappin and Aleksandre Maskharashvili},
	address = {Minneapolis, Minnesota},
	Title = {{Bayesian} Inference Semantics: A Modelling System and A Test Suite},
	shorttitle = {Bayesian {Inference} {Semantics}},
	url = {https://www.aclweb.org/anthology/S19-1029},
	doi = {10.18653/v1/S19-1029},
	abstract = {We present BIS, a Bayesian Inference Semantics, for probabilistic reasoning in natural language. The current system is based on the framework of Bernardy et al. (2018), but departs from it in important respects. BIS makes use of Bayesian learning for inferring a hypothesis from premises. This involves estimating the probability of the hypothesis, given the data supplied by the premises of an argument. It uses a syntactic parser to generate typed syntactic structures that serve as input to a model generation system. Sentences are interpreted compositionally to probabilistic programs, and the corresponding truth values are estimated using sampling methods. BIS successfully deals with various probabilistic semantic phenomena, including frequency adverbs, generalised quantifiers, generics, and vague predicates. It performs well on a number of interesting probabilistic reasoning tasks. It also sustains most classically valid inferences (instantiation, de Morgan's laws, etc.). To test BIS we have built an experimental test suite with examples of a range of probabilistic and classical inference patterns.},
	urldate = {2021-03-01},
	booktitle = {Proceedings of the {Eighth} {Joint} {Conference} on {Lexical} and {Computational} {Semantics} (*{SEM} 2019)},
	publisher = {Association for Computational Linguistics},
	month = {jun},
	year = {2019},
	pages = {263--272}
},

@article{bernardy_computational_2020,
	author = {Jean-Philippe Bernardy and Stergios Chatzikyriakidis and Aleksandre Maskharashvili},
	title = {A Computational Treatment of Anaphora and its Algorithmic Implementation},
	journal = {Journal of Logic, Language and Information},
	volume = {},
	number = {},
	pages = {},
	year = {2020},
	publisher = {Springer}
},

@misc{bernardy_computational_extended_2020,
	author = {Jean-Philippe Bernardy and Stergios Chatzikyriakidis and Aleksandre Maskharashvili},
	title = {A Computational Treatment of Anaphora and its Algorithmic Implementation: Extended Version},
	note = {Available on the first author's homepage: \url{https://jyp.github.io/pdf/phoroi.pdf} or online \url{https://bit.ly/2xQ4G2M}},
	year = {2020},
	forcedkey = {bernardy_computational_extended_2020}
},

@article{bernardy_logic_2020,
	author = {Jean-Philippe Bernardy and Rasmus Blanck and Aleksandre Maskharashvili},
	title = {A LOGIC WITH MEASURABLE SPACES FOR NATURAL LANGUAGE SEMANTICS},
	journal = {Applied Mathematics, Informatics And Mechanics},
	issue = {Special issue dedicated to Shalva Pkhakadze},
	year = {2020}
},

@inproceedings{bernardy_improving_2020,
	author = {Jean-Philippe Bernardy and Stergios Chatzikyriakidis},
	title = {Improving the precision of natural textual entailment problem datasets},
	booktitle = {Proceedings of the Language Resources and Evaluation Conference, 2020},
	year = {2020}
},

@inproceedings{bernardy_applied_2021,
	author = {Jean-Philippe Bernardy and Stergios Chatzikyriakidis},
	title = {Applied Temporal Analysis: A Complete Run of the FraCaS Test Suite},
	booktitle = {{IWCS} 2021 - 14th {International} {Conference} on {Computational} {Semantics} - {Long} papers},
	year = {2021}
},

@inproceedings{bernardy_can_2021,
	author = {Jean-Philippe Bernardy and Adam Ek and Vladislav Maraev},
	title = {Can the Transformer Learn Nested Recursion with Symbol Masking?},
	booktitle = {Findings of the ACL 2021},
	year = {2021}
},

@inproceedings{bernardy_evaluating_2021,
	author = {Jean-Philippe Bernardy and Arnaud Spiwack},
	title = {Evaluating Linear Functions to Symmetric Monoidal Categories},
	booktitle = {Proceedings of the 14th ACM SIGPLAN International Haskell Symposium (Haskell '21), August 26--27, 2021, Virtual Event, Republic of Korea},
	isbn = {978-1-4503-8615-9/21/08},
	pages = {17--33},
	year = {2021},
	doi = {10.1145/3471874.3472980},
	publisher = {ACM}
},

@article{berry_chemical_1992,
	author = {G{\'e}rard Berry and G{\'e}rard Boudol},
	title = {The chemical abstract machine},
	journal = {Theoretical computer science},
	volume = {96},
	number = {1},
	pages = {217--248},
	year = {1992},
	publisher = {Elsevier}
},

@book{bertot_interactive_2004,
	author = {Y. Bertot and P. Castéran and G. Huet and Christine {Paulin-Mohring}},
	file = {:/home/bernardy/Papers/Interactive theorem proving and program development Coq'Art the calculus of inductive constructions-2004.pdf:pdf},
	title = {Interactive theorem proving and program development: {Coq'Art:} the calculus of inductive constructions},
	shorttitle = {Interactive theorem proving and program development},
	publisher = {{Springer-Verlag} New York Inc},
	year = {2004},
	see = {:bertot_interactive_2013}
},

@book{bertot_interactive_2013,
	author = {Yves Bertot and Pierre Cast{\'e}ran},
	title = {Interactive theorem proving and program development: Coq?Art: the calculus of inductive constructions},
	year = {2013},
	publisher = {Springer Science \& Business Media}
},

@article{bhattamishra_practical_2020,
	author = {Satwik Bhattamishra and Kabir Ahuja and Navin Goyal},
	title = {On the Practical Ability of Recurrent Neural Networks to Recognize Hierarchical Languages},
	journal = {arXiv preprint arXiv:2011.03965},
	note = {Unpublished?},
	year = {2020}
},

@incollection{bierman_upgradej_2008,
	author = {Gavin Bierman and Matthew Parkinson and James Noble},
	title = {{UpgradeJ:} Incremental Typechecking for Class Upgrades},
	url = {http://dx.doi.org/10.1007/978-3-540-70592-5_11},
	abstract = {One of the problems facing developers is the constant evolution of components that are used to build applications. This evolution is typical of any multi-person or multi-site software project. How can we program in this environment? More precisely, how can language design address such evolution? In this paper we attack two significant issues that arise from constant component evolution: we propose language-level extensions that permit multiple, co-existing versions of classes and the ability to dynamically upgrade from one version of a class to another, whilst still maintaining type safety guarantees and requiring only lightweight extensions to the runtime infrastructure. We show how our extensions, whilst intuitive, provide a great deal of power by giving a number of examples. Given the subtlety of the problem, we formalize a core fragment of our language and prove a number of important safety properties.},
	booktitle = {{ECOOP} 2008 â {Object-Oriented} Programming},
	year = {2008},
	keywords = {evolution},
	pages = {235--259}
},

@book{bird_introduction_1986,
	author = {Richard Bird},
	title = {An introduction to the theory of lists},
	year = {1986},
	publisher = {Programming Research Group, Oxford University Computing Laboratory}
},

@book{bird_algebra_1997,
	author = {Richard Bird and Oege {de Moor}},
	title = {Algebra of programming},
	isbn = {{013507245X}},
	url = {http://portal.acm.org/citation.cfm?id=248932},
	publisher = {{Prentice-Hall,} Inc.},
	year = {1997},
	keywords = {aop}
},

@article{bird_generalised_1999,
	author = {Richard Bird and Ross Paterson},
	file = {:/home/bernardy/Papers/Generalised folds for nested datatypes-1999.pdf:pdf},
	title = {Generalised folds for nested datatypes},
	volume = {11},
	url = {http://dx.doi.org/10.1007/s001650050047},
	abstract = {Nested datatypes generalise regular datatypes in much the same way that context-free languages generalise regular ones. Although the categorical semantics of nested types turns out to be similar to the regular case, the fold functions are more limited because they can only describe natural transformations. Practical considerations therefore dictate the introduction of a generalised fold function in which this limitation can be overcome. In the paper we show how to construct generalised folds systematically for each nested datatype, and show that they possess a uniqueness property analogous to that of ordinary folds. As a consequence, generalised folds satisfy fusion properties similar to those developed for regular datatypes. Such properties form the core of an effective calculational theory of inductive datatypes.},
	number = {2},
	journal = {Formal Aspects of Computing},
	year = {1999},
	keywords = {aop},
	pages = {200--222}
},

@article{bird_bruijn_1999,
	author = {Richard Bird and Ross Paterson},
	file = {:/home/bernardy/Papers/de Bruijn Notation as a Nested Datatype-1999.pdf:pdf},
	title = {{de Bruijn} Notation as a Nested Datatype},
	journal = {Journal of Functional Programming},
	volume = {9},
	number = {1},
	pages = {77--91},
	year = {1999},
	URL = {http://dx.doi.org/10.1017/S0956796899003366},
	publisher = {Cambridge Univ Press}
},

@article{birkedal_categorical_2005,
	author = {Lars Birkedal and Rasmus E. Møgelberg},
	file = {:/home/bernardy/Papers/Categorical models for Abadi and Plotkin's logic for parametricity-2005.pdf:pdf},
	title = {Categorical models for Abadi and Plotkin's logic for parametricity},
	volume = {15},
	url = {http://portal.acm.org/citation.cfm?id=1089909},
	abstract = {We propose a new category-theoretic formulation of relational parametricity based on a logic for reasoning about parametricity given by Abadi and Plotkin {(Plotkin} \& Abadi 1993). The logic can be used to reason about parametric models, such that we may prove consequences of parametricity that to our knowledge have not been proved before for existing category-theoretic notions of relational parametricity. We provide examples of parametric models and describe a way of constructing parametric models from given models of the second-order lambda calculus.},
	number = {4},
	journal = {Mathematical. Structures in Comp. Sci.},
	year = {2005},
	pages = {709--772}
},

@article{birkedal_realizability_2009,
	author = {Lars Birkedal and K. Støvring and J. Thamsborg},
	title = {Realizability semantics of parametric polymorphism, general references, and recursive types},
	journal = {Foundations of Software Science and Computational Structures},
	pages = {456--470},
	year = {2009},
	publisher = {Springer}
},

@inproceedings{bizzoni_deep_2017,
	author = {Yuri Bizzoni and Stergios Chatzikyriakidis and Mehdi Ghanimifard},
	title = {``{D}eep" Learning: Detecting Metaphoricity in Adjective-Noun Pairs},
	booktitle = {Proceedings of the Workshop on Stylistic Variation},
	pages = {43--52},
	year = {2017}
},

@inproceedings{blondal_deriving_2018,
	author = {Baldur Bl\"{o}ndal and Andres L\"{o}h and Ryan Scott},
	title = {Deriving via: Or, How to Turn Hand-Written Instances into an Anti-Pattern},
	year = {2018},
	isbn = {9781450358354},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3242744.3242746},
	doi = {10.1145/3242744.3242746},
	booktitle = {Proceedings of the 11th ACM SIGPLAN International Symposium on Haskell},
	pages = {55–67},
	numpages = {13},
	keywords = {type classes, Haskell, instances, functional programming, deriving},
	location = {St. Louis, MO, USA},
	series = {Haskell 2018}
},

@book{blackburn_representation_2005,
	author = {Patrick Blackburn and Johan Bos},
	address = {Chicago},
	series = {Studies in {Computational} {Linguistics}},
	title = {Representation and {Inference} for {Natural} {Language}: {A} {First} {Course} in {Computational} {Semantics}},
	isbn = {978-1-57586-496-9},
	url = {https://press.uchicago.edu/ucp/books/book/distributed/R/bo3685980.html},
	abstract = {How can computers distinguish the coherent from the unintelligible, recognize new information in a sentence, or draw inferences from a natural language passage? Computational semantics is an exciting new field that seeks answers to these questions, and this volume is the first textbook wholly devoted to this growing subdiscipline.  The book explains the underlying theoretical issues and fundamental techniques for computing semantic representations for fragments of natural language. This volume will be an essential text for computer scientists, linguists, and anyone interested in the development of computational semantics.},
	urldate = {2021-03-02},
	publisher = {University of Chicago Press},
	year = {2005}
},

@InProceedings{blackburn_?separate_2006,
	author = {P. Blackburn and J. Bos and M. Kohlhase and H. de Nivelle},
	title = {?Separate Performative? Account of the German Right Dislocation,},
	booktitle = {Proc. of  Sinn und Bedeutung 10.},
	year = {2006},
	OPTeditor = {},
	OPTpages = {},
	OPTorganization = {},
	OPTpublisher = {},
	address = {},
	OPTmonth = {},
	OPTnote = {}
},

@article{blelloch_programming_1996,
	author = {Guy E. Blelloch},
	title = {Programming parallel algorithms},
	journal = {Communications of the {ACM}},
	issue_date = {March 1996},
	volume = {39},
	number = {3},
	month = {mar},
	year = {1996},
	issn = {0001-0782},
	pages = {85--97},
	numpages = {13},
	url = {http://doi.acm.org/10.1145/227234.227246},
	doi = {10.1145/227234.227246},
	acmid = {227246},
	publisher = {ACM},
	address = {New York, NY, USA}
},

@article{boisseau_what_2018,
	author = {Guillaume Boisseau and Jeremy Gibbons},
	title = {What You Needa Know about Yoneda: Profunctor Optics and the Yoneda Lemma (Functional Pearl)},
	year = {2018},
	issue_date = {September 2018},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {2},
	number = {ICFP},
	url = {https://doi.org/10.1145/3236779},
	doi = {10.1145/3236779},
	abstract = {Profunctor optics are a neat and composable representation of bidirectional data accessors, including lenses, and their dual, prisms. The profunctor representation exploits higher-order functions and higher-kinded type constructor classes, but the relationship between this and the familiar representation in terms of "getter" and "setter" functions is not at all obvious. We derive the profunctor representation from the concrete representation, making the relationship clear. It turns out to be a fairly direct application of the Yoneda Lemma, arguably the most important result in category theory. We hope this derivation aids understanding of the profunctor representation. Conversely, it might also serve to provide some insight into the Yoneda Lemma.},
	journal = {Proc. ACM Program. Lang.},
	month = {jul},
	articleno = {84},
	numpages = {27},
	keywords = {Lens, prism, profunctors, optic, Yoneda Lemma, composable references}
},

@misc{boisseau_understanding_2020,
	author = {Guillaume Boisseau},
	title = {Understanding Profunctor Optics: a representation theorem},
	year = {2020},
	eprint = {2001.11816},
	archivePrefix = {arXiv},
	primaryClass = {cs.PL}
},

@article{boldini_formalizing_2000,
	author = {P. Boldini},
	title = {Formalizing Contexts in Intuitionistic Type Theory},
	journal = {Fundamenta Informaticae},
	volume = {4},
	number = {2},
	OPTpages = {},
	year = {2000},
	OPTpublisher = {}
},

@article{bordes_learning_2016,
	author = {Antoine Bordes and Y-Lan Boureau and Jason Weston},
	title = {Learning end-to-end goal-oriented dialog},
	journal = {arXiv preprint arXiv:1605.07683},
	year = {2016}
},

@article{borgstrom_measure_2013,
	author = {Johannes Borgstr\"om and Andrew D. Gordon and Michael Greenberg and James Margetson and Jurgen Van Gael},
	title = {Measure Transformer Semantics for {Bayesian} Machine Learning},
	journal = {Logical Methods in Computer Science},
	volume = {9},
	pages = {1--39},
	year = {2013}
},

@inproceedings{bos_recognising_2005,
	author = {Johan Bos and Katja Markert},
	address = {Vancouver, British Columbia, Canada},
	title = {Recognising textual entailment with logical inference},
	url = {https://www.aclweb.org/anthology/H05-1079},
	urldate = {2021-03-01},
	booktitle = {Proceedings of {Human} {Language} {Technology} {Conference} and {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	month = {oct},
	year = {2005},
	pages = {628--635}
},

@inproceedings{bos_wide-coverage_2008,
	author = {Johan Bos},
	title = {Wide-coverage semantic analysis with boxer},
	booktitle = {Proceedings of the 2008 Conference on Semantics in Text Processing},
	pages = {277--286},
	year = {2008},
	organization = {Association for Computational Linguistics}
},

@article{boudol_semantics_2000,
	author = {Gérard Boudol},
	file = {:/home/bernardy/Papers/On the semantics of the call-by-name CPS transform-2000.pdf:pdf},
	title = {On the semantics of the call-by-name {CPS} transform},
	volume = {234},
	url = {http://portal.acm.org/citation.cfm?id=331681},
	number = {1-2},
	journal = {Theor. Comput. Sci.},
	year = {2000},
	keywords = {böhm-out technique, continuation-passing-style transforms, lévy-longo trees, \&lgr;-calculus},
	pages = {309--321}
},

@incollection{bove_formalising_2006,
	author = {Ana Bove and Thierry Coquand},
	title = {Formalising Bitonic Sort in Type Theory},
	url = {http://dx.doi.org/10.1007/11617990_6},
	abstract = {We discuss two complete formalisations of bitonic sort in constructive type theory. Bitonic sort is one of the fastest sorting
algorithms where the sequence of comparisons is not data-dependent. In addition, it is a general recursive algorithm. In the
formalisation we face two main problems: only structural recursion is allowed in type theory, and a formal proof of the correctness
of the algorithm needs to consider quite a number of cases. In our first formalisation we define bitonic sort over dependently-typed
binary trees with information in the leaves and we make use of the 0-1-principle to prove that the algorithm sorts inputs
of arbitrary types. In our second formalisation we use notions from linear orders, lattice theory and monoids. The correctness
proof is directly performed for any ordered set and not only for Boolean values.},
	booktitle = {Types for Proofs and Programs},
	year = {2006},
	pages = {82--97}
},

@InProceedings{bove_dependent_2009,
	author = {A. Bove and P. Dybjer},
	title = {Dependent Types at Work},
	booktitle = {Language Engineering and Rigorous Software Development
                  International LerNet ALFA Summer School},
	pages = {57--99},
	year = {2009},
	editor = {A. Bove and L. Barbosa and A. Pardo and J. Sousa Pinto},
	volume = {5520},
	series = {LNCS},
	publisher = {Springer}
},

@InProceedings{bowman_large_2015,
	author = {Samuel R Bowman and Gabor Angeli and Christopher Potts and Christopher D Manning},
	title = {A large annotated corpus for learning natural language inference},
	pages = {632-642},
	booktitle = {Proceedings of EMNLP},
	year = {2015}
},

@article{bowman_noninterference_2015,
	author = {William J Bowman and Amal Ahmed},
	title = {Noninterference for free},
	journal = {ACM SIGPLAN Notices},
	volume = {50},
	number = {9},
	pages = {101--113},
	year = {2015},
	publisher = {ACM}
},

@article{bowman_fast_2016,
	author = {Samuel R Bowman and Jon Gauthier and Abhinav Rastogi and Raghav Gupta and Christopher D Manning and Christopher Potts},
	title = {A fast unified model for parsing and sentence understanding},
	journal = {arXiv preprint arXiv:1603.06021},
	year = {2016}
},

@incollection{brady_inductive_2004,
	author = {Edwin Brady and Conor McBride and James McKinna},
	file = {:/home/bernardy/Papers/Inductive Families Need Not Store Their Indices-2004.pdf:pdf},
	affiliation = {Department of Computer Science, University of Durham},
	title = {Inductive Families Need Not Store Their Indices},
	booktitle = {Types for Proofs and Programs},
	series = {Lecture Notes in Computer Science},
	editor = {Berardi, Stefano and Coppo, Mario and Damiani, Ferruccio},
	publisher = {Springer},
	isbn = {},
	pages = {115--129},
	volume = {3085},
	doi = {10.1007/978-3-540-24849-1_8},
	year = {2004}
},

@inproceedings{brady_lightweight_2008,
	author = {Edwin Brady and Christoph A. Herrmann and Kevin Hammond},
	title = {Lightweight Invariants with Full Dependent Types},
	booktitle = {Trends in Functional Programming},
	year = {2008},
	pages = {161-177},
	bibsource = {DBLP, http://dblp.uni-trier.de}
},

@incollection{brady_resource-safe_2012,
	author = {Edwin Brady and Kevin Hammond},
	title = {Resource-Safe systems programming with embedded domain specific languages},
	booktitle = {Practical Aspects of Declarative Languages},
	pages = {242--257},
	year = {2012},
	publisher = {Springer}
},

@article{brady_idris_2013,
	author = {Edwin Brady},
	title = {Idris, a general-purpose dependently typed programming language:
               Design and implementation},
	journal = {J. Funct. Program.},
	volume = {23},
	number = {5},
	year = {2013},
	pages = {552-593},
	ee = {http://dx.doi.org/10.1017/S095679681300018X},
	bibsource = {DBLP, http://dblp.uni-trier.de}
},

@misc{brady_idris_2020,
	author = {Edwin Brady},
	title = {Idris 2: Quantitative Type Theory in Action},
	url = {https://www.type-driven.org.uk/edwinb/papers/idris2.pdf},
	year = {2020}
},

@article{breazu-tannen_extensional_1988,
	author = {V. Breazu-Tannen and T. Coquand},
	title = {Extensional models for polymorphism},
	journal = {Theoretical Computer Science},
	volume = {59},
	number = {1-2},
	pages = {85--114},
	year = {1988},
	publisher = {Elsevier}
},

@inproceedings{breitholtz_can_2008,
	author = {Ellen Breitholtz and Jessica Villing},
	title = {Can aristotelian enthymemes decrease the cognitive load of a dialogue system user},
	booktitle = {Proceedings of the 12th Workshop on the Semantics and Pragmatics of Dialogue (SemDial 2008,?LonDial?)},
	pages = {94--100},
	year = {2008}
},

@article{breitholtz_enthymemes_2014,
	author = {Ellen Breitholtz},
	title = {Enthymemes in Dialogue: A micro-rhetorical approach},
	year = {2014}
},

@article{brooks_markov_1998,
	author = {Stephen P. Brooks},
	ISSN = {00390526, 14679884},
	journal = {Journal of the Royal Statistical Society. Series D (The Statistician)},
	number = {1},
	pages = {69--100},
	publisher = {[Royal Statistical Society, Wiley]},
	title = {Markov Chain Monte Carlo Method and Its Application},
	volume = {47},
	year = {1998}
},

@InProceedings{brunel_core_2014,
	author = {Aloïs Brunel and Marco Gaboardi and Damiano Mazza and Steve Zdancewic},
	title = {A Core Quantitative Coeffect Calculus},
	booktitle = {Programming Languages and Systems - 23rd European
                  Symposium on Programming, {ESOP} 2014, Held as Part of the
                  European Joint Conferences on Theory and Practice of
                  Software, {ETAPS} 2014, Grenoble, France, April 5-13, 2014,
                  Proceedings},
	pages = {351--370},
	year = {2014},
	crossref = {DBLP:conf/esop/2014},
	doi = {10.1007/978-3-642-54833-8_19},
	timestamp = {Fri, 19 May 2017 01:25:18 +0200},
	biburl = {https://dblp.org/rec/bib/conf/esop/BrunelGMZ14},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@article{buckley_taxonomy_2005,
	author = {Jim Buckley and Tom Mens and Matthias Zenger and Awais Rashid and GÃ¼nter Kniesel},
	title = {Towards a taxonomy of software change},
	volume = {17},
	url = {http://dx.doi.org/10.1002/smr.319},
	abstract = {Previous taxonomies of software change have focused on the purpose of the change (i.e., the why) rather than the underlying mechanisms. This paper proposes a taxonomy of software change based on characterizing the mechanisms of change and the factors that influence these mechanisms. The ultimate goal of this taxonomy is to provide a framework that positions concrete tools, formalisms and methods within the domain of software evolution. Such a framework would considerably ease comparison between the various mechanisms of change. It would also allow practitioners to identify and evaluate the relevant tools, methods and formalisms for a particular change scenario. As an initial step towards this taxonomy, the paper presents a framework that can be used to characterize software change support tools and to identify the factors that impact on the use of these tools. The framework is evaluated by applying it to three different change support tools and by comparing these tools based on this analysis. Copyright Â© 2005 John Wiley \& Sons, Ltd.},
	number = {5},
	journal = {Journal of Software Maintenance and Evolution: Research and Practice},
	year = {2005},
	keywords = {evolution},
	pages = {309--332}
},

@inproceedings{burckhardt_two_2011,
	author = {Sebastian Burckhardt and Daan Leijen and Caitlin Sadowski and Jaeheon Yi and Thomas Ball},
	title = {Two for the price of one: A model for parallel and incremental computation},
	booktitle = {Proceedings of the 2011 {ACM} international conference on Object oriented programming systems languages and applications},
	pages = {427--444},
	year = {2011},
	organization = {{ACM}}
},

@inproceedings{burger_discriminating_2011,
	author = {John D. Burger and John Henderson and George Kim and Guido Zarrella},
	title = {Discriminating {{Gender}} on {{Twitter}}},
	booktitle = {Proceedings of the 2011 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
	year = {2011},
	month = {jul},
	pages = {1301--1309},
	publisher = {{Association for Computational Linguistics}},
	address = {{Edinburgh, Scotland, UK.}}
},

@book{buss_handbook_1998,
	author = {Samuel R. Buss},
	title = {Handbook of proof theory},
	year = {1998},
	publisher = {Elsevier},
	see = {chapter:troelstra_handbook_1998}
},

@article{bhm_automatic_1985,
	author = {Corrado Böhm and Alessandro Berarducci},
	title = {Automatic synthesis of typed Lambda-programs on term algebras},
	volume = {39},
	number = {2-3},
	journal = {Theoretical Computer Science},
	year = {1985},
	pages = {135--154}
},

@phdthesis{bhme_free_2007,
	author = {Sascha Böhme},
	title = {Free theorems for sublanguages of {Haskell}},
	school = {Technische Universität Dresden},
	type = {Master's Thesis},
	year = {2007},
	note = {Tool currently available (2010) at \url{http://www-ps.iai.uni-bonn.de/cgi-bin/free-theorems-webui.cgi}}
},

@inproceedings{caires_concurrent_2012,
	author = {Luís Caires and Frank Pfenning and Bernardo Toninho},
	title = {Towards concurrent type theory},
	booktitle = {Proceedings of the 8th ACM SIGPLAN workshop on Types in language design and implementation},
	pages = {1--12},
	year = {2012},
	organization = {ACM}
},

@misc{caires_linear_????,
	author = {Luís Caires and Frank Pfenning and Bernardo Toninho},
	file = {:/home/bernardy/Papers/Linear logic propositions as session types-????.pdf:pdf},
	title = {Linear logic propositions as session types},
	journal = {Mathematical Structures in Computer Science},
	note = {Submitted}
},

@book{cann_semantics_2009,
	author = {Ronnie Cann and Ruth Kempson and Eleni Gregoromichelaki},
	year = {2009},
	month = {05},
	pages = {},
	title = {Semantics: An Introduction to Meaning in Language},
	isbn = {9780521819626}
},

@article{cardelli_understanding_1985,
	author = {Luca Cardelli and Peter Wegner},
	file = {:/home/bernardy/Papers/On understanding types, data abstraction, and polymorphism-1985.pdf:pdf},
	title = {On understanding types, data abstraction, and polymorphism},
	volume = {17},
	issn = {0360-0300},
	doi = {10.1145/6041.6042},
	number = {4},
	journal = {{ACM} Computing Surveys},
	month = {12},
	year = {1985},
	pages = {471--523}
},

@article{cardone_history_2006,
	author = {F. Cardone and J. R. Hindley and N. {MRRS}},
	title = {History of lambda-calculus and combinatory logic},
	volume = {5},
	journal = {Handbook of the History of Logic},
	year = {2006}
},

@phdthesis{carlsson_fudgets_1998,
	author = {M. Carlsson and T. Hallgren},
	file = {:/home/bernardy/Papers/Fudgets Purely Functional Processes with Applications to Graphical User Interfaces-1998.ps:ps},
	type = {{PhD} Thesis},
	title = {Fudgets: Purely Functional Processes with Applications to Graphical User Interfaces},
	school = {Chalmers Tekniska Högskola},
	year = {1998}
},

@inproceedings{carlsson_monads_2002,
	author = {Magnus Carlsson},
	address = {Pittsburgh, {PA,} {USA}},
	title = {Monads for incremental computing},
	isbn = {1-58113-487-8},
	url = {http://portal.acm.org/citation.cfm?id=581482},
	doi = {10.1145/581478.581482},
	abstract = {This paper presents a monadic approach to incremental computation, suitable for purely functional languages such as Haskell. A program that uses incremental computation is able to perform an incremental amount of computation to accommodate for changes in input data. Recently, Acar, Blelloch and Harper presented a small Standard {ML} library that supports efficient, high-level incremental computations [1]. Here, we present a monadic variant of that library, written in Haskell extended with first-class references. By using monads, not only are we able to provide a purely functional interface to the library, the types also enforce "correct usage" without having to resort to any type-system extension. We also find optimization opportunities based on standard monadic {combinators.This} is an exercise in putting to work monad transformers with environments, references, and continuations.},
	booktitle = {Proceedings of the seventh {ACM} {SIGPLAN} international conference on Functional Programming},
	publisher = {{ACM}},
	year = {2002},
	pages = {26--35}
},

@article{cartling_implicit_2008,
	author = {Bo Cartling},
	title = {On the implicit acquisition of a context-free grammar by a simple recurrent neural network},
	journal = {Neurocomputing},
	volume = {71},
	number = {7},
	pages = {1527--1537},
	year = {2008},
	publisher = {Elsevier}
},

@article{celentano_incremental_1978,
	author = {A. Celentano},
	title = {Incremental {LR} parsers},
	volume = {10},
	number = {4},
	journal = {Acta Informatica},
	year = {1978},
	pages = {307--321}
},

@article{cer_semeval-2017_2017,
	author = {Daniel Cer and Mona Diab and Eneko Agirre and Inigo Lopez-Gazpio and Lucia Specia},
	title = {SemEval-2017 Task 1: Semantic Textual Similarity-Multilingual and Cross-lingual Focused Evaluation},
	journal = {arXiv preprint arXiv:1708.00055},
	year = {2017}
},

@inproceedings{cervesato_linear_1996,
	author = {I. Cervesato and F. Pfenning},
	title = {A linear logical framework},
	booktitle = {Logic in Computer Science, 1996. LICS'96. Proceedings., Eleventh Annual IEEE Symposium on},
	pages = {264--275},
	year = {1996},
	organization = {IEEE}
},

@article{chakravarty_associated_2005,
	author = {Manuel Chakravarty and Gabriele Keller and Simon {Peyton Jones}},
	title = {Associated type synonyms},
	volume = {40},
	issn = {0362-1340},
	url = {http://dx.doi.org/10.1145/1090189.1086397},
	number = {9},
	journal = {{SIGPLAN} Not.},
	year = {2005},
	keywords = {typeclass},
	pages = {241--253}
},

@inproceedings{chakravarty_associated_2005-1,
	author = {Manuel Chakravarty and Gabriele Keller and Simon {Peyton Jones} and Simon Marlow},
	forcedkey = {chakravarty_associated_2005-1},
	title = {Associated types with class},
	isbn = {{158113830X}},
	url = {http://dx.doi.org/10.1145/1040305.1040306},
	booktitle = {{POPL} '05: Proceedings of the 32nd {ACM} {SIGPLAN-SIGACT} sysposium on Principles of programming languages},
	publisher = {{ACM} Press},
	year = {2005},
	keywords = {typeclass},
	pages = {1--13}
},

@inproceedings{chakravarty_data_2007,
	author = {Manuel Chakravarty and Roman Leshchinskiy and Simon {Peyton Jones} and Gabriele Keller and Simon Marlow},
	title = {Data Parallel Haskell: a status report},
	booktitle = {Proceedings of the 2007 workshop on Declarative aspects of multicore programming},
	pages = {10--18},
	year = {2007},
	organization = {ACM}
},

@inproceedings{chakravarty_accelerating_2011,
	author = {Manuel MT Chakravarty and Gabriele Keller and Sean Lee and Trevor L McDonell and Vinod Grover},
	title = {Accelerating Haskell array codes with multicore GPUs},
	booktitle = {Proceedings of the sixth workshop on Declarative aspects of multicore programming},
	pages = {3--14},
	year = {2011},
	organization = {ACM}
},

@article{charlow_monadic_2015,
	author = {Simon Charlow},
	title = {Monadic dynamic semantics for anaphora},
	journal = {Ohio State Dynamic Semantics Workshop},
	year = {2015}
},

@inproceedings{charlow_modular_2017,
	author = {Simon Charlow},
	title = {A modular theory of pronouns and binding},
	booktitle = {Logic and Engineering of Natural Language Semantics (LENLS) 14},
	publisher = {Springer},
	year = {2017}
},

@inproceedings{chatzikyriakidis_adjectives_2013,
	author = {Stergios Chatzikyriakidis and Zhaohui Luo},
	title = {Adjectives in a modern type-theoretical setting},
	booktitle = {Formal Grammar},
	pages = {159--174},
	year = {2013},
	organization = {Springer}
},

@InProceedings{chatzikyriakidis_adverbs_2014,
	author = {S. Chatzikyriakidis},
	title = {Adverbs in a modern type theory},
	booktitle = {Proceedings of LACL2014. LNCS 8535 },
	year = {2014},
	editor = {Asher, N. and Soloviev, S.},
	pages = {44-56},
	OPTorganization = {},
	OPTpublisher = {Springer},
	address = {},
	OPTmonth = {Toulouse},
	OPTnote = {}
},

@article{chatzikyriakidis_natural_2014,
	author = {Stergios Chatzikyriakidis and Zhaohui Luo},
	title = {Natural language inference in Coq},
	journal = {Journal of Logic, Language and Information},
	volume = {23},
	number = {4},
	pages = {441--480},
	year = {2014},
	publisher = {Springer}
},

@Article{chatzikyriakidis_adjectival_2017,
	author = {Stergios Chatzikyriakidis and Zhaohui Luo},
	title = {Adjectival and Adverbial Modification: The View from Modern Type Theories},
	journal = {Journal of Logic, Language and Information},
	year = {2017},
	volume = {26},
	number = {1},
	pages = {45--88}
},

@InProceedings{chatzikyriakidis_overview_2017,
	author = {Stergios Chatzikyriakidis and Robin Cooper and Simon Dobnik and Staffan Larsson},
	title = {An overview of Natural Language Inference Data Collection: The way forward?},
	booktitle = {Proceedings of the Computing Natural Language Inference Workshop},
	year = {2017},
	url = {http://aclweb.org/anthology/W17-7203}
},

@incollection{chatzikyriakidis_interpretation_2017,
	author = {S. Chatzikyriakidis and Z. Luo},
	title = {On the interpretation of common nouns: Types versus predicates},
	booktitle = {Modern Perspectives in Type-Theoretical Semantics},
	pages = {43--70},
	year = {2017},
	publisher = {Springer}
},

@article{chatzikyriakidis_type_2017,
	author = {Stergios Chatzikyriakidis and Mathieu Lafourcade and Lionel Ramadier and Manel Zarrouk},
	title = {Type theories and lexical networks: Using serious games as the basis for multi-Sorted typed systems},
	journal = {Journal of Language Modelling},
	volume = {5},
	number = {2},
	pages = {229--272},
	year = {2017}
},

@inproceedings{chaudhuri_classical_2010,
	author = {Kaustuv Chaudhuri},
	title = {Classical and intuitionistic subexponential logics are equally expressive},
	booktitle = {Computer Science Logic},
	pages = {185--199},
	year = {2010},
	organization = {Springer}
},

@inproceedings{chen_combining_2005,
	author = {Chiyan Chen and Hongwei Xi},
	title = {Combining programming with theorem proving},
	booktitle = {ICFP},
	year = {2005},
	pages = {66-77},
	bibsource = {DBLP, http://dblp.uni-trier.de}
},

@article{chen_enhancing_2016,
	author = {Qian Chen and Xiaodan Zhu and Zhenhua Ling and Si Wei and Hui Jiang},
	title = {Enhancing and combining sequential and tree LSTM for natural language inference},
	journal = {arXiv preprint arXiv:1609.06038},
	year = {2016}
},

@InProceedings{chen_enhanced_2017,
	author = {Qian Chen and Xiaodan Zhu and Zhen-Hua Ling and Si Wei and Hui Jiang and Diana Inkpen},
	title = {Enhanced LSTM for Natural Language Inference},
	booktitle = {Proceedings of the 55th Annual Meeting of the Association for      Computational Linguistics (Volume 1: Long Papers)    },
	year = {2017},
	publisher = {Association for Computational Linguistics},
	pages = {1657--1668}
},

@article{chen_natural_2017,
	author = {Qian Chen and Xiaodan Zhu and Zhen{-}Hua Ling and Diana Inkpen and Si Wei},
	title = {Natural Language Inference with External Knowledge},
	journal = {CoRR},
	volume = {abs/1711.04289},
	year = {2017},
	url = {http://arxiv.org/abs/1711.04289},
	archivePrefix = {arXiv}
},

@misc{chen_quora_????,
	author = {Zihan Chen and Hongbo Zhang and Xiaoji Zhang and Leqi Zhao},
	title = {Quora Question Pairs}
},

@book{chierchia_dynamics_1995,
	author = {Gennaro Chierchia},
	year = {1995},
	title = {Dynamics of Meaning: Anaphora, Presupposition, and the Theory of Grammar},
	publisher = {University of Chicago Press}
},

@inproceedings{chlipala_parametric_2008,
	author = {Adam Chlipala},
	file = {:/home/bernardy/Papers/Parametric higher-order abstract syntax for mechanized semantics-2008.pdf:pdf},
	title = {Parametric higher-order abstract syntax for mechanized semantics},
	booktitle = {Proceedings of the 13th {ACM} {SIGPLAN} international conference on Functional Programming},
	year = {2008},
	isbn = {978-1-59593-919-7},
	location = {Victoria, BC, Canada},
	pages = {143--156},
	numpages = {14},
	doi = {10.1145/1411204.1411226},
	acmid = {1411226},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {compiler verification, dependent types, interactive proof assistants, type-theoretic semantics}
},

@inproceedings{chlipala_effective_2009,
	author = {Adam Chlipala and Gregory Malecha and Greg Morrisett and Avraham Shinnar and Ryan Wisnesky},
	file = {:/home/bernardy/Papers/Effective interactive proofs for higher-order imperative programs-2009.pdf:pdf},
	title = {Effective interactive proofs for higher-order imperative programs},
	booktitle = {Proceedings of the 14th {ACM} {SIGPLAN} international conference on Functional Programming},
	series = {ICFP '09},
	year = {2009},
	isbn = {978-1-60558-332-7},
	location = {Edinburgh, Scotland},
	pages = {79--90},
	numpages = {12},
	url = {http://doi.acm.org/10.1145/1596550.1596565},
	doi = {http://doi.acm.org/10.1145/1596550.1596565},
	acmid = {1596565},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {dependent types, functional programming, interactive proof assistants, separation logic}
},

@INPROCEEDINGS{cho_learning_2014,
	author = {Kyunghyun Cho and Bart van Merri{\"{e}}nboer and {\c C}aglar G{\"{u}}l{\c c}ehre and Dzmitry Bahdanau and Fethi Bougares and Holger Schwenk and Yoshua Bengio},
	month = {oct},
	title = {Learning Phrase Representations using {RNN} Encoder--Decoder for Statistical Machine Translation},
	booktitle = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
	year = {2014},
	pages = {1724--1734},
	publisher = {Association for Computational Linguistics},
	address = {Doha, Qatar},
	url = {http://www.aclweb.org/anthology/D14-1179}
},

@misc{chollet_keras_2015,
	author = {Fran\c{c}ois Chollet and  others},
	title = {Keras},
	year = {2015},
	publisher = {GitHub},
	howpublished = {\url{https://github.com/keras-team/keras}}
},

@book{chomsky_syntactic_1957,
	author = {Noam Chomsky},
	title = {Syntactic Structures},
	year = {1957},
	publisher = {Mouton de Gruyter}
},

@article{chomsky_certain_1959,
	author = {N. Chomsky},
	title = {On certain formal properties of grammars},
	journal = {Information and control},
	volume = {2},
	number = {2},
	pages = {137--167},
	year = {1959},
	publisher = {Elsevier}
},

@book{chomsky_lectures_1981,
	author = {Noam Chomsky},
	address = {Dordrecht},
	series = {Studies in {Generative} {Grammar}},
	title = {Lectures on {Government} and {Binding}: {The} {Pisa} {Lectures}},
	number = {9},
	publisher = {Foris Publications},
	year = {1981}
},

@misc{chomsky_purpose_2012,
	author = {Noam Chomsky},
	title = {The purpose of education},
	year = {2012},
	note = {Talk at the Learning Without Frontiers Conference, Jan 25th 2012}
},

@incollection{christiansen_easycheck_2008,
	author = {Jan Christiansen and Sebastian Fischer},
	series = {Lecture Notes in Computer Science},
	title = {{EasyCheck} — Test Data for Free},
	volume = {4989},
	url = {http://dx.doi.org/10.1007/978-3-540-78969-7_23},
	abstract = {We present a lightweight, automated tool for specification-based testing of declarative programs written in the functional
logic programming language Curry and emphasize the usefulness of logic features in its implementation and use. Free variables,
nondeterminism and encapsulated search turn out to be elegant and powerful means to express test-data generation.},
	booktitle = {Functional and Logic Programming},
	publisher = {Springer},
	year = {2008},
	pages = {322--336}
},

@article{church_set_1933,
	author = {Alonzo Church},
	series = {Second Series},
	title = {A Set of Postulates For the Foundation of Logic},
	volume = {34},
	issn = {{0003486X}},
	url = {http://www.jstor.org/stable/1968702},
	number = {4},
	journal = {The Annals of Mathematics},
	month = {oct},
	year = {1933},
	note = {{ArticleType:} primary\_article / Full publication date: Oct., 1933 / Copyright © 1933 Annals of Mathematics},
	pages = {839--864}
},

@article{church_formulation_1940,
	author = {Alonzo Church},
	file = {:/home/bernardy/Papers/A formulation of the simple theory of types-1940.pdf:pdf},
	title = {{A formulation of the simple theory of types}},
	journal = {Journal of symbolic logic},
	volume = {5},
	number = {2},
	pages = {56--68},
	issn = {0022-4812},
	year = {1940},
	publisher = {JSTOR}
},

@article{chytil_parallel_1991,
	author = {Michal Chytil and Maxime Crochemore and Burkhard Monien and Wojciech Rytter},
	title = {On the parallel recognition of unambiguous context-free languages},
	journal = {Theoretical Computer Science},
	volume = {81},
	number = {2},
	pages = {311--316},
	year = {1991},
	publisher = {Elsevier}
},

@inproceedings{ciot_gender_2013,
	author = {Morgane Ciot and Morgan Sonderegger and Derek Ruths},
	title = {Gender {{Inference}} of {{Twitter Users}} in {{Non}}-{{English Contexts}}},
	booktitle = {Proceedings of the 2013 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
	year = {2013},
	month = {oct},
	pages = {1136--1145},
	publisher = {{Association for Computational Linguistics}},
	address = {{Seattle, Washington, USA}}
},

@article{claessen_poor_1999,
	author = {Koen Claessen},
	file = {:/home/bernardy/Papers/A poor man's concurrency monad-1999.pdf:pdf},
	title = {A poor man's concurrency monad},
	volume = {9},
	url = {http://portal.acm.org/citation.cfm?id=968592.968596},
	abstract = {Without adding any primitives to the language, we define a concurrency monad transformer in Haskell. This allows us to add a limited form of concurrency to any existing monad. The atomic actions of the new monad are lifted actions of the underlying monad. Some extra operations, such as fork, to initiate new processes, are provided. We discuss the implementation, and use some examples to illustrate the usefulness of this construction.},
	number = {3},
	journal = {J. Funct. Program.},
	year = {1999},
	pages = {313--323}
},

@inproceedings{claessen_observable_1999,
	author = {Koen Claessen and David Sands},
	editor = {P. S. Thiagarajan and
               Roland H. C. Yap},
	title = {Observable Sharing for Functional Circuit Description},
	booktitle = {Advances in Computing Science - ASIAN'99, 5th Asian Computing Science
               Conference, Phuket, Thailand, December 10-12, 1999, Proceedings},
	series = {Lecture Notes in Computer Science},
	volume = {1742},
	pages = {62--73},
	publisher = {Springer},
	year = {1999},
	url = {https://doi.org/10.1007/3-540-46674-6\_7},
	doi = {10.1007/3-540-46674-6\_7},
	timestamp = {Tue, 14 May 2019 10:00:53 +0200},
	biburl = {https://dblp.org/rec/conf/asian/ClaessenS99.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@inproceedings{claessen_quickcheck_2000,
	author = {Koen Claessen and John Hughes},
	file = {:/home/bernardy/Papers/QuickCheck a lightweight tool for random testing of Haskell programs-2000.pdf:pdf},
	title = {{QuickCheck:} a lightweight tool for random testing of {Haskell} programs},
	isbn = {1-58113-202-6},
	shorttitle = {{QuickCheck}},
	doi = {10.1145/351240.351266},
	abstract = {Quick Check is a tool which aids the Haskell programmer in formulating and testing properties of programs. Properties are described as Haskell functions, and can be automatically tested on random input, but it is also possible to define custom test data generators. We present a number of case studies, in which the tool was successfully used, and also point out some pitfalls to avoid. Random testing is especially suitable for functional programs because properties can be stated at a fine grain. When a function is built from separately tested components, then random testing suffices to obtain good coverage of the definition under test.},
	booktitle = {Proceedings of the fifth {ACM} {SIGPLAN} international conference on Functional Programming},
	publisher = {{ACM}},
	year = {2000},
	pages = {268--279}
},

@article{claessen_parallel_2004,
	author = {Koen Claessen},
	file = {:/home/bernardy/Papers/Parallel Parsing Processes-2004.ps:ps},
	title = {Parallel Parsing Processes},
	volume = {14},
	number = {6},
	journal = {Journal of Functional Programming},
	year = {2004},
	pages = {741--757}
},

@inproceedings{claessen_expressive_2012,
	author = {Koen Claessen and Mary Sheeran and Bo Joel Svensson},
	title = {Expressive array constructs in an embedded GPU kernel programming language},
	booktitle = {Proceedings of the 7th workshop on Declarative aspects and applications of multicore programming},
	pages = {21--30},
	year = {2012},
	organization = {ACM}
},

@inproceedings{claessen_splittable_2013,
	author = {Koen Claessen and Micha{\l} H Pa{\l}ka},
	title = {Splittable pseudorandom number generators using cryptographic hashing},
	booktitle = {Proceedings of the 2013 ACM SIGPLAN symposium on Haskell},
	pages = {47--58},
	year = {2013},
	organization = {ACM}
},

@book{clark_using_1996,
	author = {Herbert H. Clark},
	title = {Using {{Language}}},
	year = {1996},
	month = {may},
	publisher = {{Cambridge University Press}},
	abstract = {Herbert Clark argues that language use is more than the sum of a speaker speaking and a listener listening. It is the joint action that emerges when speakers and listeners, writers and readers perform their individual actions in coordination, as ensembles. In contrast to work within the cognitive sciences, which has seen language use as an individual process, and to work within the social sciences, which has seen it as a social process, the author argues strongly that language use embodies both individual and social processes.},
	isbn = {978-0-521-56745-9},
	keywords = {common ground,Language Arts \& Disciplines / Linguistics / General,Language Arts \& Disciplines / Vocabulary},
	language = {en}
},

@book{clark_linguistic_2011,
	author = {A. Clark and S. Lappin},
	Address = {Chichester, West Sussex, and Malden, MA},
	Publisher = {Wiley-Blackwell},
	Title = {Linguistic Nativism and the Poverty of the Stimulus},
	Year = {2011}
},

@book{cocke_programming_1969,
	author = {J. Cocke},
	title = {Programming languages and their compilers: Preliminary notes},
	year = {1969},
	publisher = {Courant Institute of Mathematical Sciences, New York University}
},

@article{cockett_proof_1997,
	author = {J Robin B Cockett and Robert AG Seely},
	file = {:/home/bernardy/Papers/Proof theory for full intuitionistic linear logic, bilinear logic, and mix categories-1997.pdf:pdf},
	title = {Proof theory for full intuitionistic linear logic, bilinear logic, and mix categories},
	journal = {Theory and Applications of categories},
	volume = {3},
	number = {5},
	pages = {85--131},
	year = {1997}
},

@article{cohen_views_2010,
	author = {Julien Cohen and Rémi Douence},
	file = {:/home/bernardy/Papers/Views, Program Transformations, and the Evolutivity Problem-2010.pdf:pdf},
	title = {Views, Program Transformations, and the Evolutivity Problem},
	journal = {CoRR},
	volume = {abs/1005.1213},
	year = {2010},
	ee = {http://arxiv.org/abs/1005.1213},
	bibsource = {DBLP, http://dblp.uni-trier.de}
},

@techreport{collobert_torch_2002,
	author = {Ronan Collobert and Samy Bengio and Johnny Mari{\'e}thoz},
	title = {Torch: a modular machine learning software library},
	year = {2002},
	institution = {Idiap}
},

@inproceedings{collobert_torch7_2011,
	author = {Ronan Collobert and Koray Kavukcuoglu and Cl{\'e}ment Farabet},
	title = {Torch7: A matlab-like environment for machine learning},
	booktitle = {BigLearn, NIPS workshop},
	number = {EPFL-CONF-192376},
	year = {2011}
},

@InProceedings{conneau_xnli_2018,
	author = {Alexis Conneau and Ruty Rinott and Guillaume Lample and Adina Williams and Samuel R. Bowman and Holger Schwenk and Veselin Stoyanov},
	title = {XNLI: Evaluating Cross-lingual Sentence Representations},
	booktitle = {Proceedings of the 2018 Conference on Empirical Methods 
               in Natural Language Processing},
	year = {2018},
	publisher = {Association for Computational Linguistics},
	location = {Brussels, Belgium}
},

@unpublished{conor_lets_????,
	author = {{McBride} Conor},
	file = {:/home/bernardy/Papers/Let's see how things unfold-????.pdf:pdf},
	title = {Let's see how things unfold},
	url = {http://strictlypositive.org/ObsCoin.pdf}
},

@article{conradi_version_1998,
	author = {Reidar Conradi and Bernhard Westfechtel},
	title = {Version models for software configuration management},
	volume = {30},
	issn = {0360-0300},
	url = {http://dx.doi.org/10.1145/280277.280280},
	number = {2},
	journal = {{ACM} Comput. Surv.},
	month = {jun},
	year = {1998},
	keywords = {vc},
	pages = {232--282}
},

@article{cooper_interpretation_1979,
	author = {Robin Cooper},
	title = {The interpretation of pronouns},
	journal = {Syntax and Semantics},
	volume = {10},
	year = {1979},
	editor = {F. Heny and H. Schnelle},
	address = {New York},
	pages = {535--561}
},

@TechReport{cooper_using_1996,
	author = {R. Cooper and D. Crouch and J. {van Eijck} and C. Fox and J. van Genabith and J. Jaspars and H. Kamp and D. Milward and M. Pinkal and M. Poesio and S. Pulman},
	title = {Using the framework.},
	type = {Technical Report {LRE 62-051r}},
	year = {1996},
	institution = {The FraCaS consortium},
	abstract = {There are two major levels of processing that are significant in the use of a computational semantic framework: semantic composition for the construction of meanings; and inference either for the exploitation of those meanings, or to assist in determining contextually sensitive aspects of meaning. The first chapter of this deliverable outlines the semantic competences that are either required by --- or would improve the performance of --- a variety of different commercially relevant applications. Semantic composition and meaning construction is a core competence required by all applications, and inference is central to many. The second chapter takes the form of a manual describing the use of a program library and educational/research tool providing a concrete computational framework bringing together different types of semantic composition. The third chapter presents an inference test suite for evaluating the inferential competence of different NLP systems and semantic theories. Provid...},
	number = {LRE 62-051 D-16},
	note = {\url{ftp://ftp.cogsci.ed.ac.uk/pub/FRACAS/del16.ps.gz}.}
},

@incollection{cooper_probabilistic_2014,
	author = {R. Cooper and S. Dobnik and S. Lappin and S. Larsson},
	Address = {Gothenburg, Sweden},
	Booktitle = {Proceedings of the EACL 2014 Workshop on Type Theory and Natural Language Semantics (TTNLS)},
	Pages = {72--79},
	Publisher = {Association of Computational Linguistics},
	Title = {A Probabilistic Rich Type Theory for Semantic Interpretation},
	Year = {2014}
},

@inproceedings{cooper_probabilistic_2015,
	author = {Robin Cooper and Simon Dobnik and Shalom Lappin and Staffan Larsson},
	title = {Probabilistic type theory and natural language semantics},
	url = {https://www.aclweb.org/anthology/2015.lilt-10.4},
	abstract = {Type theory has played an important role in specifying the formal connection between syntactic structure and semantic interpretation within the history of formal semantics. In recent years rich type theories developed for the semantics of programming languages have become influential in the semantics of natural language. The use of probabilistic reasoning to model human learning and cognition has become an increasingly important part of cognitive science. In this paper we offer a probabilistic formulation of a rich type theory, Type Theory with Records (TTR), and we illustrate how this framework can be used to approach the problem of semantic learning. Our probabilistic version of TTR is intended to provide an interface between the cognitive process of classifying situations according to the types that they instantiate, and the compositional semantics of natural language.},
	urldate = {2021-03-01},
	booktitle = {Linguistic {Issues} in {Language} {Technology}, {Volume} 10, 2015},
	publisher = {CSLI Publications},
	year = {2015}
},

@article{cooper_type_2015,
	author = {Robin Cooper and Jonathan Ginzburg},
	title = {Type theory with records for natural language semantics},
	journal = {Handbook of Contemporary Semantic Theory, The},
	pages = {375--407},
	publisher = {Wiley Online Library},
	year = {2015},
	see = {:cooper_adapting_2017}
},

@incollection{cooper_adapting_2017,
	author = {Robin Cooper},
	editor = {Chatzikyriakidis, Stergios and Luo, Zhaohui},
	title = {Adapting Type Theory with Records for Natural Language Semantics},
	booktitle = {Modern Perspectives in Type-Theoretical Semantics},
	year = {2017},
	publisher = {Springer International Publishing},
	pages = {71--94},
	isbn = {978-3-319-50422-3},
	doi = {10.1007/978-3-319-50422-3_4},
	url = {http://dx.doi.org/10.1007/978-3-319-50422-3_4}
},

@inproceedings{coquand_analysis_1986,
	author = {Thierry Coquand},
	file = {:/home/bernardy/Papers/An Analysis of Girard's Paradox-1986.ps:ps},
	title = {An Analysis of {Girard}'s Paradox},
	booktitle = {Logic in computer science},
	publisher = {IEEE Computer Society},
	year = {1986},
	pages = {227--236}
},

@techreport{coquand_calculus_1986,
	author = {Thierry Coquand and Gérard Huet},
	file = {:/home/bernardy/Papers/The calculus of constructions-1986.pdf:pdf},
	publisher = {Institut National de Recherche en Informatique et en Automatique},
	institution = {INRIA},
	title = {The calculus of constructions},
	year = {1986},
	see = {used:barras_implicit_2008;used:paulin-mohring_extracting_1989;used:pfenning_inductively_1990;used:harper_type_1989}
},

@conference{coquand_pattern_1992,
	author = {Thierry Coquand},
	title = {Pattern Matching with Dependent Types},
	booktitle = {Proceedings of the Workshop on Types for Proofs and Programs},
	pages = {66--79},
	year = {1992}
},

@article{coquand_simple_2009,
	author = {Thierry Coquand and Yoshiki Kinoshita and Bengt Nordström and Makoto Takeyama},
	title = {A simple type-theoretic language: Mini-TT},
	year = {2009}
},

@incollection{coquand_decision_2011,
	author = {Thierry Coquand and Vincent Siles},
	title = {A decision procedure for regular expression equivalence in type theory},
	booktitle = {Certified Programs and Proofs},
	pages = {119--134},
	year = {2011},
	publisher = {Springer}
},

@book{cormen_introduction_2001,
	author = {Thomas H Cormen and Charles E Leiserson and Ronald L Rivest and Clifford Stein},
	title = {Introduction to algorithms, second ed.},
	year = {2001},
	publisher = {MIT press}
},

@inproceedings{coutts_stream_2007,
	author = {Duncan Coutts and Roman Leshchinskiy and Don Stewart},
	title = {Stream fusion: From lists to streams to nothing at all},
	booktitle = {Haskell},
	pages = {315--326},
	year = {2007},
	organization = {ACM}
},

@incollection{cresswell_semantics_1976,
	author = {Max J Cresswell},
	title = {The semantics of degree},
	booktitle = {Montague grammar},
	pages = {261--292},
	year = {1976},
	publisher = {Elsevier}
},

@misc{czerwinski_polynominal_2008,
	author = {Reiner Czerwinski},
	file = {:/home/bernardy/Papers/A Polynominal Time Algorithm for Graph Isomorphism-2008.pdf:pdf},
	title = {A Polynominal Time Algorithm for Graph Isomorphism},
	url = {http://arxiv.org/abs/0711.2010},
	arxivId = {0711.2010},
	abstract = {Algorithms testing two graphs for isomorphism known as yet have exponential worst case complexity. In this paper we propose a new algorithm that has polynomial complexity and constructively supplies the evidence that the graph isomorphism lies in P.},
	year = {2008},
	keywords = {algorithm, graph, isomorphism, polynomial},
	howpublished = {\url{http://arxiv.org/abs/0711.2010}}
},

@incollection{dagan_pascal_2006,
	author = {Ido Dagan and Oren Glickman and Bernardo Magnini},
	title = {The {PASCAL} recognising textual entailment challenge},
	booktitle = {Machine learning challenges. Evaluating predictive uncertainty, visual object classification, and recognising tectual entailment},
	pages = {177--190},
	year = {2006},
	isbn = {978-3-540-33428-6},
	editor = {Quiñonero-Candela, Joaquin and Dagan, Ido and Magnini, Bernardo and d’Alché-Buc, Florence},
	keywords = {Information Extraction, Machine Translation, News Story, Question Answering, Reading Comprehension},
	doi = {10.1007/11736790_9},
	abstract = {This paper describes the PASCAL Network of Excellence first Recognising Textual Entailment (RTE-1) Challenge benchmark. The RTE task is defined as recognizing, given two text fragments, whether the meaning of one text can be inferred (entailed) from the other. This application-independent task is suggested as capturing major inferences about the variability of semantic expression which are commonly needed across multiple applications. The Challenge has raised noticeable attention in the research community, attracting 17 submissions from diverse groups, suggesting the generic relevance of the task.},
	publisher = {Springer}
},

@article{dagan_recognizing_2009,
	author = {Ido Dagan and Bill Dolan and Bernado Magnini and Dan Roth},
	Journal = {Natural Language Engineering},
	Pages = {1--17},
	Title = {Recognizing Textual Entailment: Rational, Evaluation and Approaches},
	Volume = {15},
	Issue = {4},
	Year = {2009}
},

@inproceedings{dagand_transporting_2012,
	author = {Pierre-Evariste Dagand and Conor McBride},
	title = {Transporting Functions across Ornaments},
	booktitle = {Proceedings of the 17th {ACM} {SIGPLAN} international conference on Functional Programming},
	series = {ICFP '12},
	year = {2012},
	publisher = {ACM},
	address = {New York, NY, USA}
},

@inproceedings{danielsson_fast_2006,
	author = {Nils Anders Danielsson and John Hughes and Patrik Jansson and Jeremy Gibbons},
	title = {Fast and loose reasoning is morally correct},
	booktitle = {Conference record of the 33rd {ACM} {SIGPLAN-SIGACT} symposium on Principles of programming languages},
	url = {http://portal.acm.org/citation.cfm?id=1111320.1111056},
	doi = {10.1145/1111320.1111056},
	abstract = {Functional programmers often reason about programs as if they were written in a total language, expecting the results to carry over to non-total (partial) languages. We justify such {reasoning.Two} languages are defined, one total and one partial, with identical syntax. The semantics of the partial language includes partial and infinite values, and all types are lifted, including the function spaces. A partial equivalence relation {(PER)} is then defined, the domain of which is the total subset of the partial language. For types not containing function spaces the {PER} relates equal values, and functions are related if they map related values to related {values.It} is proved that if two closed terms have the same semantics in the total language, then they have related semantics in the partial language. It is also shown that the {PER} gives rise to a bicartesian closed category which can be used to reason about values in the domain of the relation.},
	year = {2006},
	keywords = {equational reasoning, inductive and coinductive types, lifted types, non-strict and strict languages, partial and infinite values, partial and total languages},
	acmid = {1111056},
	pages = {206--217}
},

@inproceedings{danielsson_formalisation_2007,
	author = {Nils Anders Danielsson},
	title = {A formalisation of a dependently typed language as an inductive-recursive family},
	booktitle = {Proceedings of the 2006 international conference on Types for proofs and programs},
	series = {TYPES'06},
	year = {2007},
	isbn = {3-540-74463-0, 978-3-540-74463-4},
	location = {Nottingham, UK},
	pages = {93--109},
	numpages = {17},
	url = {http://portal.acm.org/citation.cfm?id=1789277.1789284},
	acmid = {1789284},
	publisher = {Springer-Verlag},
	address = {Berlin, Heidelberg}
},

@inproceedings{danielsson_total_2010,
	author = {Nils Anders Danielsson},
	title = {Total parser combinators},
	booktitle = {Proceedings of the 15th {ACM} {SIGPLAN} international conference on Functional Programming},
	series = {ICFP '10},
	year = {2010},
	isbn = {978-1-60558-794-3},
	location = {Baltimore, Maryland, USA},
	pages = {285--296},
	numpages = {12},
	url = {http://doi.acm.org/10.1145/1863543.1863585},
	doi = {http://doi.acm.org/10.1145/1863543.1863585},
	acmid = {1863585},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {dependent types, mixed induction and coinduction, parser combinators, productivity, termination}
},

@misc{danielsson_agda_2011,
	author = {Nils Anders Danielsson and  {The Agda Team}},
	title = {The {Agda} standard library},
	url = {http://www.cs.nott.ac.uk/~nad/repos/lib/},
	year = {2011}
},

@misc{danielsson_agda_2013,
	author = {Nils Anders Danielsson and  {The Agda Team}},
	title = {The {Agda} standard library, version 0.7},
	url = {http://wiki.portal.chalmers.se/agda/pmwiki.php?n=Libraries.StandardLibrary},
	year = {2013},
	see = {version:danielsson_agda_2011}
},

@inproceedings{daniyar_sensala_2018,
	author = { Daniyar and Lebedeva Itegulov},
	title = {{S}ensala: a Dynamic Semantics System for Natural Language Processing},
	booktitle = {Proceedings of the 27th International Conference on Computational Linguistics: System Demonstrations},
	month = {aug},
	year = {2018},
	address = {Santa Fe, New Mexico},
	publisher = {Association for Computational Linguistics},
	url = {https://www.aclweb.org/anthology/C18-2027},
	pages = {123--127},
	abstract = {Here we describe Sensala , an open source framework for the semantic interpretation of natural language that provides the logical meaning of a given text. The framework{'}s theory is based on a lambda calculus with exception handling and uses contexts, continuations, events and dependent types to handle a wide range of complex linguistic phenomena, such as donkey anaphora, verb phrase anaphora, propositional anaphora, presuppositions and implicatures.}
},

@misc{danvy_three_1991,
	author = {O Danvy},
	title = {Three steps for the {CPS} transformation},
	url = {http://citeseer.ist.psu.edu/294520.html},
	abstract = {Transforming a \#-term into continuation-passing style {(CPS)} might seem mystical at first, but in fact it can be characterized by three separate aspects: . The values of all intermediate applications are given a name. . The evaluation of these applications is sequentialized based on a traversal of their syntax tree. This traversal mimics the reduction strategy. . The resulting term is equipped with a continuation --- a \#-abstraction whose application to intermediate values yields the final ...},
	year = {1991},
	keywords = {cps}
},

@inproceedings{danvy_defunctionalization_2001,
	author = {Olivier Danvy and Lasse R. Nielsen},
	address = {Florence, Italy},
	title = {Defunctionalization at work},
	isbn = {{1-58113-388-X}},
	url = {http://portal.acm.org/citation.cfm?id=773184.773202},
	doi = {10.1145/773184.773202},
	abstract = {Reynolds's defunctionalization technique is a whole-program transformation from higher-order to first-order functional programs. We study practical applications of this transformation and uncover new connections between seemingly unrelated higher-order and first-order specifications and between their correctness proofs. Defunctionalization therefore appearsboth as a springboard for rev ealing new connections and as a bridge for transferring existing results between the first-order world and the higher-order world.},
	booktitle = {Proceedings of the 3rd {ACM} {SIGPLAN} international conference on Principles and practice of declarative programming},
	publisher = {{ACM}},
	year = {2001},
	keywords = {church encoding, closure conversion, continuation-passing style (cps), continuations, cps transformation, defunctionalization, direct-style transformation, first-order programs, higher-order programs, lambda-lifting, ml, regular expressions, scheme, supercombinator conversion, syntactic theories},
	pages = {162--174}
},

@misc{danvy_representing_????,
	author = {Olivier Danvy and Andrzej Filinski},
	title = {Representing control: a study of the {CPS} transformation},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.46.84},
	abstract = {This paper investigates the transformation of v-terms into continuation-passing style {(CPS).} We show that by appropriate j-expansion of Fischer and Plotkin's two-pass equational specification of the {CPS} transform, we can obtain a static and context-free separation of the result terms into \&quot;essential \&quot; and \&quot;administrative \&quot; constructs. Interpreting the former as syntax builders and the latter as directly executable code, we obtain a simple and efficient one-pass transformation algorithm, easily extended to conditional expressions, recursive definitions, and similar constructs. This new transformation algorithm leads to a simpler proof of Plotkin's simulation and indifference results. We go on to show how {CPS-based} control operators similar to, but more general than, Scheme's call/cc can be naturally accommodated by the new transformation algorithm. To demonstrate the expressive power of these operators, we use them to present an equivalent but even more concise formulation of the efficient {CPS} transformation algorithm. Finally, we relate the fundamental ideas underlying this derivation to similar concepts from other works on program manipulation; we derive a one-pass {CPS} transformation of n-terms; and we outline some promising areas for future research.},
	keywords = {cps},
	howpublished = {\url{http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.46.84}}
},

@inproceedings{dart_concepts_1991,
	author = {Susan Dart and Peter Feiler},
	title = {Concepts in Configuration Management Systems},
	url = {http://citeseer.ist.psu.edu/dart90concepts.html},
	abstract = {: There has been considerable progress con- 1.1 Definition of Configuration Management cerning support for software configuration management Software {CM} is a discipline for controlling the evolution {(CM)} in environments and tools. This paper's intent is to of software systems. Classic discussions about {CM} are highlight the user concepts provided by existing {CM} sys- given in texts such as [3] and [4]. A standard definition tems. These are shown as a spectrum. In the spectrum, taken from {IEEE...}},
	booktitle = {Proceedings of the 3rd International Workshop on Software Configuration Management},
	year = {1991},
	keywords = {vc},
	pages = {1--18}
},

@inproceedings{das_learning_1992,
	author = {Sreerupa Das and C Lee Giles and Guo-Zheng Sun},
	title = {Learning context-free grammars: Capabilities and limitations of a recurrent neural network with an external stack memory},
	booktitle = {Proceedings of The Fourteenth Annual Conference of Cognitive Science Society. Indiana University},
	pages = {14},
	year = {1992}
},

@book{davey_introduction_2002,
	author = {Brian A. Davey and Hilary A. Priestley},
	title = {Introduction to lattices and order},
	isbn = {0521784514, 9780521784511},
	publisher = {Cambridge University Press},
	year = {2002}
},

@article{day_logical_1999,
	author = {Nancy A. Day and John Launchbury and Jeff Lewis},
	file = {:/home/bernardy/Papers/Logical abstractions in Haskell-1999.pdf:pdf},
	title = {Logical abstractions in {Haskell}},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.37.2140},
	doi = {10.1.1.37.2140},
	journal = {In Proceedings of the 1999 Haskell Workshop},
	year = {1999}
},

@inproceedings{devito_liszt_2011,
	author = {Zachary DeVito and Niels Joubert and Francisco Palacios and Stephen Oakley and Montserrat Medina and Mike Barrientos and Erich Elsen and Frank Ham and Alex Aiken and Karthik Duraisamy and  others},
	title = {Liszt: a domain specific language for building portable mesh-based PDE solvers},
	booktitle = {Proceedings of 2011 International Conference for High Performance Computing, Networking, Storage and Analysis},
	pages = {9},
	year = {2011},
	organization = {ACM}
},

@article{dean_mapreduce_2008,
	author = {Jeffrey Dean and Sanjay Ghemawat},
	title = {MapReduce: simplified data processing on large clusters},
	journal = {Communications of the ACM},
	volume = {51},
	number = {1},
	pages = {107--113},
	year = {2008},
	publisher = {ACM}
},

@incollection{deb_multi-objective_2016,
	author = {Kalyanmoy Deb and Karthik Sindhya and Jussi Hakanen},
	title = {Multi-objective optimization},
	booktitle = {Decision Sciences: Theory and Practice},
	pages = {145--184},
	year = {2016},
	publisher = {CRC Press}
},

@article{degano_efficient_1988,
	author = {Pierpaolo Degano and Stefano Mannucci and Bruno Mojana},
	title = {Efficient incremental {LR} parsing for syntax-directed editors},
	volume = {10},
	url = {http://portal.acm.org/citation.cfm?doid=44501.214503},
	doi = {10.1145/44501.214503},
	abstract = {A technique for generating parsers which is an extension to {LR} techniques and is based on parsing table splitting, is presented. Then this technique is slightly extended to support incremental syntax analysis. Given a context-free grammar and a set {“IC”} of nonterminals devised to be incremental, a set of subtables is generated to drive the analysis of program fragments derivable from nonterminals in {IC.} The proposed technique generates parsing tables which are considerably smaller than the standard ones, even when incrementality is not exploited. Thus, these tables may be stored as arrays permitting faster access and accurate error handling. Furthermore, our tables are suitable for generating syntax-directed editors which provide a full analytic mode. The efficiency of the analytic component of a syntax-directed editor obtained in this way and its easy integration with the generative component stress the advantages of incremental program writing.},
	number = {3},
	journal = {{ACM} Trans. Program. Lang. Syst.},
	year = {1988},
	pages = {345--373}
},

@article{devlin_bert_2018,
	author = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
	title = {Bert: Pre-training of deep bidirectional transformers for language understanding},
	journal = {arXiv preprint arXiv:1810.04805},
	year = {2018}
},

@phdthesis{dogan_javascript_2009,
	author = {Deniz Dogan},
	type = {{MSc} Thesis},
	title = {A {JavaScript} Mode for Yi},
	school = {Chalmers University of Technology},
	year = {2009}
},

@inproceedings{dolan_fun_2013,
	author = {Stephen Dolan},
	title = {Fun with Semirings: A Functional Pearl on the Abuse
                  of Linear Algebra},
	booktitle = {Proceedings of the 18th {ACM} {SIGPLAN} International
                  Conference on Functional Programming},
	series = {ICFP '13},
	year = {2013},
	isbn = {978-1-4503-2326-0},
	location = {Boston, Massachusetts, USA},
	pages = {101--110},
	numpages = {10},
	doi = {10.1145/2500365.2500613},
	acmid = {2500613},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {closed semirings, linear systems, shortest paths,
                  transitive closure}
},

@book{domingos_markov_2009,
	author = {Pedro M. Domingos and Daniel Lowd},
	title = {Markov Logic: An Interface Layer for Artificial Intelligence},
	series = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
	publisher = {Morgan {\&} Claypool Publishers},
	year = {2009},
	url = {https://doi.org/10.2200/S00206ED1V01Y200907AIM007},
	doi = {10.2200/S00206ED1V01Y200907AIM007},
	timestamp = {Tue, 16 May 2017 14:24:20 +0200},
	biburl = {https://dblp.org/rec/series/synthesis/2009Domingos.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@book{dowty_introduction_1981,
	author = {D. R. Dowty and R. E. Wall and S. Peters},
	Address = {Dordrecht},
	Publisher = {D. Reidel},
	Title = {Introduction to {Montague} Semantics},
	Year = {1981}
},

@book{dowty_word_2012,
	author = {David R Dowty},
	title = {Word meaning and Montague grammar: The semantics of verbs and times in generative semantics and in Montague's PTQ},
	volume = {7},
	year = {2012},
	publisher = {Springer Science \& Business Media}
},

@article{dybjer_inductive_1994,
	author = {Peter Dybjer},
	title = {Inductive families},
	volume = {6},
	url = {http://dx.doi.org/10.1007/BF01211308},
	doi = {10.1007/BF01211308},
	abstract = {A general formulation of inductive and recursive definitions in {Martin-Löf's} type theory is presented. It extends Backhouse's {‘Do-It-Yourself} Type Theory’ to include inductive definitions of families of sets and definitions of functions by recursion on the way elements of such sets are generated. The formulation is in natural deduction and is intended to be a natural generalisation to type theory of {Martin-Löf's} theory of iterated inductive definitions in predicate logic.},
	number = {4},
	journal = {Formal Aspects of Computing},
	month = {jul},
	year = {1994},
	pages = {440--465}
},

@inproceedings{dyer_transition-based_2015,
	author = {Chris Dyer and Miguel Ballesteros and Wang Ling and Austin Matthews and Noah A. Smith},
	title = {Transition-Based Dependency Parsing with Stack Long Short-Term Memory},
	booktitle = {Proceedings of the 53rd Annual Meeting of the Association for Computational
               Linguistics and the 7th International Joint Conference on Natural
               Language Processing of the Asian Federation of Natural Language Processing,
               {ACL} 2015, July 26-31, 2015, Beijing, China, Volume 1: Long Papers},
	pages = {334--343},
	year = {2015},
	crossref = {DBLP:conf/acl/2015-1},
	url = {http://aclweb.org/anthology/P/P15/P15-1033.pdf},
	timestamp = {Sun, 02 Aug 2015 19:26:07 +0200},
	biburl = {http://dblp.org/rec/bib/conf/acl/DyerBLMS15},
	bibsource = {dblp computer science bibliography, http://dblp.org}
},

@article{earley_efficient_1970,
	author = {J. Earley},
	title = {An efficient context-free parsing algorithm},
	journal = {Communications of the ACM},
	volume = {13},
	number = {2},
	pages = {94--102},
	year = {1970},
	publisher = {ACM}
},

@inproceedings{ebadi_differential_2015,
	author = {Hamid Ebadi and David Sands and Gerardo Schneider},
	title = {Differential Privacy: Now it's Getting Personal},
	booktitle = {Proceedings of the 42nd Annual {ACM} {SIGPLAN-SIGACT} Symposium on
               Principles of Programming Languages, {POPL} 2015, Mumbai, India, January
               15-17, 2015},
	pages = {69--81},
	year = {2015},
	crossref = {DBLP:conf/popl/2015},
	url = {https://doi.org/10.1145/2676726.2677005},
	doi = {10.1145/2676726.2677005},
	timestamp = {Tue, 09 Apr 2019 15:20:10 +0200},
	biburl = {https://dblp.org/rec/conf/popl/EbadiSS15.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@article{edgington_philosophical_2001,
	author = {Dorothy Edgington},
	volume = {7},
	doi = {10.1017/S1352325201704028},
	pages = {371--378},
	journal = {Legal Theory},
	year = {2001},
	title = {The Philosophical Problem of Vagueness},
	number = {4}
},

@incollection{egli_stoic_1979,
	author = {Urs Egli},
	editor = {Rainer B\"auerle and Urs Egli and Arnim von Stechow},
	booktitle = {Semantics From Different Points of View},
	publisher = {Springer Verlag},
	title = {The Stoic Concept of Anaphora},
	pages = {266--283},
	year = {1979}
},

@InProceedings{eisenberg_visible_2016,
	author = {Richard A. Eisenberg and Stephanie Weirich and Hamidhasan Ahmed},
	Title = {Visible Type Application},
	Booktitle = {European Symposium on Programming (ESOP)},
	Year = {2016},
	Publisher = {Springer-Verlag},
	Series = {LNCS},
	Owner = {rae},
	Timestamp = {2016.01.24}
},

@inproceedings{eisenstein_latent_2010,
	author = {Jacob Eisenstein and Brendan O'Connor and Noah A. Smith and Eric P. Xing},
	title = {A {{Latent Variable Model}} for {{Geographic Lexical Variation}}},
	booktitle = {Proceedings of the 2010 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
	year = {2010},
	month = {oct},
	pages = {1277--1287},
	publisher = {{Association for Computational Linguistics}},
	address = {{Cambridge, MA}}
},

@inproceedings{ek_language_2019,
	author = {Adam Ek and Jean-Philippe Bernardy and Shalom Lappin},
	title = {Language Modeling with Syntactic and Semantic Representation for Sentence Acceptability Predictions},
	year = {2019},
	booktitle = {Proceedings of the 22nd Nordic Conference on Computational Linguistics},
	publisher = {ACL}
},

@inproceedings{ek_composing_2020,
	author = {Adam Ek and Jean-Philippe Bernardy},
	title = {Composing Byte-Pair Encodings for Morphological Sequence Classification},
	booktitle = {Proceedings of the Fourth Workshop on Universal Dependencies},
	year = {2020}
},

@inproceedings{ek_punctuation_2020,
	author = {Adam Ek and Jean-Philippe Bernardy},
	title = {How does Punctuation Affect Neural Models in Natural Language Inference},
	booktitle = {Proceedings of the conference on Probability and Meaning},
	year = {2020}
},

@inproceedings{ek_much_2020,
	author = {Adam Ek and Jean-Philippe Bernardy},
	title = {How much of enhanced UD is contained in UD?},
	booktitle = {Proceedings of the 16th International Conference on Parsing Technologies and the IWPT 2020 Shared Task on Parsing into Enhanced Universal Dependencies},
	year = {2020}
},

@inproceedings{ek_can_2021,
	author = {Adam Ek and Jean-Philippe Bernardy and Stergios Chatzikyriakidis},
	title = {Can argument-predicate relationships be extracted from UD trees?},
	booktitle = {Proceedings of the Joint 15th Linguistic Annotation Workshop (LAW) and 3rd Designing Meaning Representations (DMR)},
	year = {2021}
},

@inproceedings{ek_training_2021,
	author = {Adam Ek and Jean-Philippe Bernardy},
	title = {Training Strategies for Neural Multilingual Morphological Inflection},
	booktitle = {Proceedings of the 18th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology},
	year = {2021}
},

@article{elazar_amnesic_2020,
	author = {Yanai Elazar and Shauli Ravfogel and Alon Jacovi and Yoav Goldberg},
	title = {Amnesic {{Probing}}: {{Behavioral Explanation}} with {{Amnesic Counterfactuals}}},
	shorttitle = {Amnesic {{Probing}}},
	year = {2020},
	month = {dec},
	abstract = {A growing body of work makes use of probing in order to investigate the working of neural models, often considered black boxes. Recently, an ongoing debate emerged surrounding the limitations of the probing paradigm. In this work, we point out the inability to infer behavioral conclusions from probing results, and offer an alternative method which focuses on how the information is being used, rather than on what information is encoded. Our method, Amnesic Probing, follows the intuition that the utility of a property for a given task can be assessed by measuring the influence of a causal intervention which removes it from the representation. Equipped with this new analysis tool, we can ask questions that were not possible before, e.g. is part-of-speech information important for word prediction? We perform a series of analyses on BERT to answer these types of questions. Our findings demonstrate that conventional probing performance is not correlated to task importance, and we call for increased scrutiny of claims that draw behavioral or causal conclusions from probing results.},
	archiveprefix = {arXiv},
	eprint = {2006.00995},
	eprinttype = {arxiv},
	journal = {arXiv:2006.00995 [cs]},
	keywords = {Computer Science - Computation and Language},
	language = {en},
	primaryclass = {cs}
},

@phdthesis{eliasson_precision-preserving_2011,
	author = {Andreas Eliasson},
	type = {{MSc} Thesis},
	title = {A precision-preserving summary-based points-to
                  analysis in LLVM},
	school = {Chalmers University of Technology},
	year = {2011}
},

@inproceedings{elliott_functional_1997,
	author = {Conal Elliott and Paul Hudak},
	file = {:/home/bernardy/Papers/Functional reactive animation-1997.pdf:pdf},
	address = {Amsterdam, The Netherlands},
	title = {Functional reactive animation},
	isbn = {0-89791-918-1},
	url = {http://portal.acm.org/citation.cfm?id=258948.258973&type=series},
	doi = {10.1145/258948.258973},
	abstract = {Fran {(Functional} Reactive Animation) is a collection of data types and functions for composing richly interactive, multimedia animations. The key ideas in Fran are its notions of behaviors and events. Behaviors are time-varying, reactive values, while events are sets of arbitrarily complex conditions, carrying possibly rich information. Most traditional values can be treated as behaviors, and when images are thus treated, they become animations. Although these notions are captured as data types rather than a programming language, we provide them with a denotational semantics, including a proper treatment of real time, to guide reasoning and implementation. A method to effectively and efficiently perform event detection using interval analysis is also described, which relies on the partial information structure on the domain of event times. Fran has been implemented in Hugs, yielding surprisingly good performance for an interpreter-based system. Several examples are given, including the ability to describe physical phenomena involving gravity, springs, velocity, acceleration, etc. using ordinary differential equations.},
	booktitle = {Proceedings of the second {ACM} {SIGPLAN} international conference on Functional Programming},
	publisher = {{ACM}},
	year = {1997},
	pages = {263--273}
},

@article{elliott_compiling_2017,
	author = {Conal Elliott},
	title = {Compiling to categories},
	journal = {Proc. {ACM} Program. Lang.},
	volume = {1},
	number = {{ICFP}},
	pages = {27:1--27:27},
	year = {2017},
	url = {https://doi.org/10.1145/3110271},
	doi = {10.1145/3110271},
	timestamp = {Thu, 16 Apr 2020 13:51:45 +0200},
	biburl = {https://dblp.org/rec/journals/pacmpl/Elliott17a.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@article{elliott_simple_2018,
	author = {Conal Elliott},
	title = {The simple essence of automatic differentiation},
	journal = {Proc. {ACM} Program. Lang.},
	volume = {2},
	number = {{ICFP}},
	pages = {70:1--70:29},
	year = {2018},
	url = {https://doi.org/10.1145/3236765},
	doi = {10.1145/3236765},
	timestamp = {Thu, 16 Apr 2020 13:51:51 +0200},
	biburl = {https://dblp.org/rec/journals/pacmpl/Elliott18.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@article{elman_distributed_1991,
	author = {Jeffrey L Elman},
	title = {Distributed representations, simple recurrent networks, and grammatical structure},
	journal = {Machine learning},
	volume = {7},
	number = {2-3},
	pages = {195--225},
	year = {1991},
	publisher = {Springer}
},

@InProceedings{emerson_semantic_2017,
	author = {Guy Emerson and Ann Copestake},
	title = {Semantic Composition via Probabilistic Model Theory},
	booktitle = {IWCS 2017 - 12th International Conference on Computational Semantics - Long papers},
	year = {2017},
	url = {http://aclweb.org/anthology/W17-6806}
},

@article{emerson_variational_2017,
	author = {Guy Emerson and Ann Copestake},
	title = {Variational Inference for Logical Inference},
	url = {http://arxiv.org/abs/1709.00224},
	abstract = {Functional Distributional Semantics is a framework that aims to learn, from text, semantic representations which can be interpreted in terms of truth. Here we make two contributions to this framework. The first is to show how a type of logical inference can be performed by evaluating conditional probabilities. The second is to make these calculations tractable by means of a variational approximation. This approximation also enables faster convergence during training, allowing us to close the gap with state-of-the-art vector space models when evaluating on semantic similarity. We demonstrate promising performance on two tasks.},
	urldate = {2021-03-01},
	journal = {arXiv:1709.00224 [cs]},
	month = {sep},
	year = {2017},
	note = {arXiv: 1709.00224},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Conference on Logic and Machine Learning in Natural Language (LaML)}
},

@InProceedings{emoto_generate_2012,
	author = {Kento Emoto and Sebastian Fischer and Zhenjiang Hu},
	title = {Generate, Test, and Aggregate --- A Calculation-based Framework for Systematic Parallel Programming with MapReduce},
	booktitle = {Proceedings of the 22nd European Symposium on Programming (ESOP 2012)},
	publisher = {Springer Verlag},
	year = {2012},
	note = {available at: \url{http://sebfisch.github.com/research/pub/Emoto+ESOP12.pdf}}
},

@inproceedings{epstein_haskell_2011,
	author = {Jeff Epstein and Andrew P. Black and Simon Peyton-Jones},
	title = {Towards Haskell in the Cloud},
	year = {2011},
	isbn = {9781450308601},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2034675.2034690},
	doi = {10.1145/2034675.2034690},
	booktitle = {Proceedings of the 4th ACM Symposium on Haskell},
	pages = {118–129},
	numpages = {12},
	keywords = {message-passing, haskell, erlang},
	location = {Tokyo, Japan},
	series = {Haskell ’11}
},

@inproceedings{erdmann_design_2017,
	author = {M Erdmann and M Rieger and B Fischer and R Fischer},
	title = {Design and Execution of make-like, distributed Analyses based on Spotify's Pipelining Package Luigi},
	booktitle = {J. Phys. Conf. Ser.},
	volume = {898},
	number = {arXiv: 1706.00955},
	pages = {072047},
	year = {2017}
},

@article{erwig_functional_2006,
	author = {Martin Erwig and Steve Kollmansberger},
	title = {Functional Pearls: Probabilistic functional programming in Haskell},
	journal = {J. Funct. Program.},
	volume = {16},
	number = {1},
	pages = {21--34},
	year = {2006},
	url = {https://doi.org/10.1017/S0956796805005721},
	doi = {10.1017/S0956796805005721},
	timestamp = {Sat, 27 May 2017 14:24:34 +0200},
	biburl = {http://dblp.org/rec/bib/journals/jfp/ErwigK06},
	bibsource = {dblp computer science bibliography, http://dblp.org}
},

@article{eshghi_bootstrapping_2017,
	author = {Arash Eshghi and Igor Shalyminov and Oliver Lemon},
	title = {Bootstrapping incremental dialogue systems from minimal data: the generalisation power of dialogue grammars},
	journal = {arXiv preprint arXiv:1709.07858},
	year = {2017}
},

@article{evans_pronouns_1980,
	author = {Gareth Evans},
	title = {Pronouns},
	journal = {Linguistic inquiry},
	volume = {11},
	number = {2},
	pages = {337--362},
	year = {1980},
	publisher = {JSTOR}
},

@inproceedings{fegaras_revisiting_1996,
	author = {Leonidas Fegaras and Tim Sheard},
	address = {St. Petersburg Beach, Florida, United States},
	title = {Revisiting catamorphisms over datatypes with embedded functions (or, programs from outer space)},
	isbn = {0-89791-769-3},
	url = {http://portal.acm.org/citation.cfm?id=237792},
	doi = {10.1145/237721.237792},
	abstract = {Note: {OCR} errors may be found in this Reference List extracted from the full text article. {ACM} has opted to expose the complete List rather than only correct and linked references.},
	booktitle = {Proceedings of the 23rd {ACM} {SIGPLAN-SIGACT} symposium on Principles of programming languages},
	publisher = {{ACM}},
	year = {1996},
	pages = {284--294}
},

@inproceedings{feng_visual_2010,
	author = {Yansong Feng and Mirella Lapata},
	title = {Visual {{Information}} in {{Semantic Representation}}},
	year = {2010},
	month = {jul},
	pages = {91--99},
	abstract = {The question of how meaning might be acquired by young children and represented by adult speakers of a language is one of the most debated topics in cognitive science. Existing semantic representation models are primarily amodal based on information provided by the linguistic input despite ample evidence indicating that the cognitive system is also sensitive to perceptual information. In this work we exploit the vast resource of images and associated documents available on the web and develop a model of multimodal meaning representation which is based on the linguistic and visual context. Experimental results show that a closer correspondence to human data can be obtained by taking the visual modality into account.}
},

@article{fernando_semantics_2015,
	author = {Tim Fernando},
	title = {The semantics of tense and aspect},
	journal = {The Handbook of Contemporary Semantic Theory},
	pages = {203--236},
	year = {2015},
	publisher = {Wiley Online Library}
},

@misc{ferriss_scientific_????,
	author = {Tim Ferriss},
	title = {Scientific Speed Reading: How to Read 300\% Faster in 20 Minutes},
	url = {http://www.fourhourworkweek.com/blog/2009/07/30/speed-reading-and-accelerated-learning/},
	howpublished = {\url{http://www.fourhourworkweek.com/blog/2009/07/30/speed-reading-and-accelerated-learning/}}
},

@incollection{firsov_certified_2013,
	author = {Denis Firsov and Tarmo Uustalu},
	title = {Certified Parsing of Regular Languages},
	booktitle = {Certified Programs and Proofs},
	pages = {98--113},
	year = {2013},
	publisher = {Springer}
},

@article{firsov_certified_2014,
	author = {Denis Firsov and Tarmo Uustalu},
	title = {Certified {CYK} parsing of context-free languages},
	journal = {J. Log. Algebr. Meth. Program.},
	volume = {83},
	number = {5-6},
	pages = {459--468},
	year = {2014},
	url = {http://dx.doi.org/10.1016/j.jlamp.2014.09.002},
	doi = {10.1016/j.jlamp.2014.09.002},
	timestamp = {Wed, 19 Nov 2014 15:03:06 +0100},
	biburl = {http://dblp.uni-trier.de/rec/bib/journals/jlp/FirsovU14},
	bibsource = {dblp computer science bibliography, http://dblp.org}
},

@inproceedings{fischer_play_2010,
	author = {Sebastian Fischer and Frank Huch and Thomas Wilke},
	file = {:/home/bernardy/Papers/A Play on Regular Expressions-2010.pdf:pdf},
	booktitle = {ICFP},
	publisher = {ACM},
	title = {{A Play on Regular Expressions}},
	year = {2010}
},

@article{fokkinga_datatype_1996,
	author = {Maarten M. Fokkinga},
	title = {Datatype Laws Without Signatures},
	volume = {6},
	url = {http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=4131224},
	doi = {10.1017/S0960129500000852},
	number = {01},
	journal = {Mathematical Structures in Computer Science},
	year = {1996},
	pages = {1--32}
},

@inbook{forsberg_bnfc_2012,
	author = {Markus Forsberg and Aarne Ranta},
	chapter = {Appendix A},
	pages = {175--192},
	title = {BNFC Quick reference},
	booktitle = {Implementing Programming Languages},
	publisher = {College Publications},
	year = {2012}
},

@misc{foster_harmony_2005,
	author = {Nathan Foster},
	title = {Harmony: A Generic Synchronization Framework for Heterogeneous, Replicated Data},
	year = {2005},
	keywords = {bibtex-import, vc},
	annote = {{{\textless}p{\textgreater}(private-note)Poster} at {DB-IR} Day.{\textless}/p{\textgreater}}
},

@book{fox_foundations_2005,
	author = {Chris Fox and Shalom Lappin},
	title = {Foundations of Intensional Semantics},
	publisher = {Blackwell},
	year = {2005}
},

@incollection{frandsen_dynamic_1995,
	author = {Gudmund Frandsen and Thore Husfeldt and Peter Miltersen and Theis Rauhe and Søren Skyum},
	title = {Dynamic algorithms for the Dyck languages},
	url = {http://dx.doi.org/10.1007/3-540-60220-8_54},
	abstract = {We study Dynamic Membership problems for the Dyck languages, the class of strings of properly balanced parentheses. We also study the Dynamic Word problem for the free group. We present deterministic algorithms and data structures which maintain a string under replacements of symbols, insertions, and deletions of symbols, and language membership queries. Updates and queries are handled in polylogarithmic time. We also give both Las Vegas- and Monte Carlo-type randomised algorithms to achieve better running times, and present lower bounds on the complexity for variants of the problems.},
	booktitle = {Algorithms and Data Structures},
	year = {1995},
	pages = {98--108}
},

@incollection{frank_one_1999,
	author = {Andrew Frank},
	title = {One Step up the Abstraction Ladder: Combining Algebras - From Functional Pieces to a Whole},
	url = {http://dx.doi.org/10.1007/3-540-48384-5_7},
	abstract = {A fundamental scientific question today is how to construct complex systems from simple parts. Science today seems mostly to analyze limited pieces of the puzzle; the combination of these pieces to form a whole is left for later or others. The lack of efficient methods to deal with the combination problem is likely the main reason. How to combine individual results is a dominant question in cognitive science or geography, where phenomena are studied from individuals and at different scales, but the results cannot be brought together. This paper proposes to use parameterized algebras much the same way that we use functional abstraction (procedures in programming languages) to create abstract building blocks which can be combined later. Algebras group operations (which are functional abstractions) and can be combined to construct more complex algebras. Algebras operate therefore at a higher level of abstraction. A table shows the parallels between procedural abstraction and the abstraction by parameterized algebras. This paper shows how algebras can be combined to form more complex pieces and compares the steps to the combination of procedures in programming. The novel contribution is to parameterize algebras and make them thus ready for reuse. The method is first explained with the familiar construction of vector space and then applied to a larger example, namely the description of geometric operations for {GIS,} as proposed in the current draft standard document {ISO} 15046 Part 7: Spatial Schema. It is shown how operations can be grouped, reused, and combined, and useful larger systems built from the pieces. The paper compares the method to combine algebras â which are independent of an implementation â with the current use of object-orientation in programming languages (and in the {UML} notation often used for specification). The widely usedâ structuralâ (or subset) polymorphism is justified by implementation considerations, but not appropriate for theory development and abstract specifications for standardization. Parametric polymorphism used for algebras avoids the contravariance of function types (which its semantically confusing consequences). Algebraic methods relate cleanly to the mathematical category theory and the method translates directly to modern functional programming or Java.},
	booktitle = {Spatial Information Theory. Cognitive and Computational Foundations of Geographic Information Science},
	year = {1999},
	keywords = {aop},
	pages = {751}
},

@article{gardenfors_induction_1990,
	author = {Peter G\"ardenfors},
	title = {Induction, Conceptual Spaces and {AI}},
	journal = {Philosophy of Science},
	volume = {57},
	number = {1},
	pages = {78--95},
	year = {1990}
},

@inproceedings{gaboardi_linear_2013,
	author = {Marco Gaboardi and Andreas Haeberlen and Justin Hsu and Arjun Narayan and Benjamin C. Pierce},
	title = {Linear dependent types for differential privacy},
	booktitle = {The 40th Annual {ACM} {SIGPLAN-SIGACT} Symposium on Principles of
               Programming Languages, {POPL} '13, Rome, Italy - January 23 - 25,
               2013},
	pages = {357--370},
	year = {2013},
	crossref = {DBLP:conf/popl/2013},
	url = {https://doi.org/10.1145/2429069.2429113},
	doi = {10.1145/2429069.2429113},
	timestamp = {Sat, 19 Oct 2019 20:03:00 +0200},
	biburl = {https://dblp.org/rec/bib/conf/popl/GaboardiHHNP13},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@inproceedings{gaboardi_combining_2016,
	author = {Marco Gaboardi and Shin{-}ya Katsumata and Dominic A. Orchard and Flavien Breuvart and Tarmo Uustalu},
	title = {Combining effects and coeffects via grading},
	booktitle = {Proceedings of the 21st {ACM} {SIGPLAN} International Conference on
               Functional Programming, {ICFP} 2016, Nara, Japan, September 18-22,
               2016},
	pages = {476--489},
	year = {2016},
	crossref = {DBLP:conf/icfp/2016},
	url = {https://doi.org/10.1145/2951913.2951939},
	doi = {10.1145/2951913.2951939},
	timestamp = {Sun, 02 Jun 2019 21:13:13 +0200},
	biburl = {https://dblp.org/rec/conf/icfp/GaboardiKOBU16.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@article{gallier_girards_1989,
	author = {Jean H Gallier},
	title = {On {Girard}'s ``{Candidats de Reductibilité}''},
	year = {1989}
},

@inproceedings{gan_type_2015,
	author = {Edward Gan and Jesse A. Tov and Greg Morrisett},
	title = {Type Classes for Lightweight Substructural Types},
	booktitle = {Proceedings Third International Workshop on Linearity, {LINEARITY}
               2014, Vienna, Austria, 13th July, 2014.},
	pages = {34--48},
	year = {2015},
	url = {http://dx.doi.org/10.4204/EPTCS.176.4},
	doi = {10.4204/EPTCS.176.4},
	timestamp = {Fri, 10 Apr 2015 15:54:52 +0200},
	biburl = {http://dblp.uni-trier.de/rec/bib/journals/corr/GanTM15},
	bibsource = {dblp computer science bibliography, http://dblp.org}
},

@article{gandy_axiom_1956,
	author = {R. O. Gandy},
	title = {On the Axiom of {Extensionality–Part} I},
	volume = {21},
	number = {1},
	journal = {The Journal of Symbolic Logic},
	year = {1956},
	pages = {36–48}
},

@InProceedings{ganea_hyperbolic_2018,
	author = {Octavian Ganea and Gary Becigneul and Thomas Hofmann},
	title = {Hyperbolic Entailment Cones for Learning Hierarchical Embeddings},
	booktitle = {Proceedings of the 35th International Conference on Machine Learning},
	pages = {1646--1655},
	year = {2018},
	editor = {Dy, Jennifer and Krause, Andreas},
	volume = {80},
	series = {Proceedings of Machine Learning Research},
	address = {Stockholmsmässan, Stockholm Sweden},
	month = {10--15 Jul},
	publisher = {PMLR},
	abstract = {Learning graph representations via low-dimensional embeddings that preserve relevant network properties is an important class of problems in machine learning. We here present a novel method to embed directed acyclic graphs. Following prior work, we first advocate for using hyperbolic spaces which provably model tree-like structures better than Euclidean geometry. Second, we view hierarchical relations as partial orders defined using a family of nested geodesically convex cones. We prove that these entailment cones admit an optimal shape with a closed form expression both in the Euclidean and hyperbolic spaces, and they canonically define the embedding learning process. Experiments show significant improvements of our method over strong recent baselines both in terms of representational capacity and generalization.}
},

@inproceedings{ganitkevitch_ppdb_2015,
	author = {Ellie Ganitkevitch and Pushpendre Pavlick and Juri Rastogi and Benjamin Van Durme and Chris Callison-Burch},
	title = {{PPDB 2.0}: Better paraphrase ranking, fine-grained entailment relations, word embeddings, and style classification},
	booktitle = {Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers)},
	year = {2015},
	month = {July 26--31},
	pages = {425--430},
	address = {Beijing, China},
	organization = {Association for Computational Linguistics}
},

@book{gantmacher_theory_1959,
	author = {Felix Ruvimovich Gantmacher},
	title = {The Theory of Matrices},
	year = {1959},
	publisher = {AMS Chelsea publishing}
},

@incollection{ganzinger_system_1999,
	author = {Harald Ganzinger and Frank Pfenning and Carsten Schürmann},
	file = {:/home/bernardy/Papers/System Description Twelf  A Meta-Logical Framework for Deductive Systems-1999.pdf:pdf},
	affiliation = {Carnegie Mellon University Department of Computer Science USA},
	title = {System Description: Twelf — A Meta-Logical Framework for Deductive Systems},
	booktitle = {Automated Deduction — CADE-16},
	series = {Lecture Notes in Computer Science},
	publisher = {Springer},
	isbn = {},
	pages = {679-679},
	volume = {1632},
	url = {http://dx.doi.org/10.1007/3-540-48660-7_14},
	note = {10.1007/3-540-48660-7_14},
	abstract = {Twelf is a meta-logical framework for the specification, implementation, and meta-theory of deductive systems from the theory of programming languages and logics. It relies on the LF type theory and the judgments-as-types methodology for specification [HHP93], a constraint logic programming interpreter for implementation [Pfe91], and the meta-logic M2 for reasoning about object languages encoded in LF [SP98]. It is a significant extension and complete reimplementation of the Elf system [Pfe94].  Twelf is written in Standard ML and runs under SML of New Jersey and MLWorks on Unix and Window platforms. The current version (1.2) is distributed with a complete manual, example suites, a tutorial in the form of on-line lecture notes [Pfe], and an Emacs interface. Source and binary distributions are accessible via the Twelf home page http://www.cs.cmu.edu/~twelf.},
	year = {1999}
},

@inproceedings{garcia_comparative_2003,
	author = {Ronald Garcia and Jaakko Jarvi and Andrew Lumsdaine and Jeremy Siek and Jeremiah Willcock},
	title = {A comparative study of language support for generic programming},
	url = {http://dx.doi.org/http://doi.acm.org/10.1145/949305.949317},
	booktitle = {Proceedings of the 18th {ACM} {SIGPLAN} conference on Object-oriented programing, systems, languages, and applications},
	publisher = {{ACM} Press},
	year = {2003},
	keywords = {sibylle, wgp08},
	pages = {115--134},
	see = {version:garcia_extended_2007}
},

@article{garcia_extended_2007,
	author = {Ronald Garcia and Jaakko Jarvi and Andrew Lumsdaine and Jeremy Siek and Jeremiah Willcock},
	file = {:/home/bernardy/Papers/An extended comparative study of language support for generic programming-2007.pdf:pdf},
	title = {An extended comparative study of language support for generic programming},
	volume = {17},
	issn = {0956-7968},
	doi = {10.1017/S0956796806006198},
	url = {http://www.journals.cambridge.org/abstract\_S0956796806006198},
	number = {2},
	journal = {Journal of Functional Programming},
	month = {mar},
	year = {2007},
	keywords = {concept, typeclass},
	pages = {145--205}
},

@Book{geach_reference_1962,
	author = {Peter Thomas Geach},
	title = {Reference and Generality},
	publisher = {Cornell University Press},
	year = {1962}
},

@article{gers_lstm_2001,
	author = {Felix A Gers and E Schmidhuber},
	title = {LSTM recurrent networks learn simple context-free and context-sensitive languages},
	journal = {IEEE Transactions on Neural Networks},
	volume = {12},
	number = {6},
	pages = {1333--1340},
	year = {2001},
	publisher = {IEEE}
},

@phdthesis{geuvers_interpretation_1988,
	author = {Herman Geuvers},
	title = {The interpretation of Logics in Type Systems},
	school = {Catholic University of Nijmegen},
	type = {Master's Thesis},
	year = {1988}
},

@phdthesis{geuvers_logics_1993,
	author = {Herman Geuvers},
	title = {Logics and type systems},
	school = {Catholic University of Nijmegen},
	year = {1993}
},

@article{geuvers_pure_2010,
	author = {Herman Geuvers and Robbert Krebbers and James McKinna and Freek Wiedijk},
	file = {:/home/bernardy/Papers/Pure Type Systems without Explicit Contexts-2010.pdf:pdf},
	title = {Pure Type Systems without Explicit Contexts},
	year = {2010}
},

@article{ghezzi_incremental_1979,
	author = {Carlo Ghezzi and Dino Mandrioli},
	title = {Incremental Parsing},
	volume = {1},
	url = {http://portal.acm.org/citation.cfm?id=357062.357066},
	doi = {10.1145/357062.357066},
	abstract = {An incremental parser is a device which is able to perform syntax analysis in an incremental way, avoiding complete reparsing of a program after each modification. The incremental parser presented extends the conventional {LR} parsing algorithm and its performance is compared with that of a conventional parser. Suggestions for an implementation and possible extensions to other parsing methods are also discussed.},
	number = {1},
	journal = {{ACM} Trans. Program. Lang. Syst.},
	year = {1979},
	pages = {58--70}
},

@article{ghezzi_augmenting_1980,
	author = {C. Ghezzi and D. Mandrioli},
	title = {Augmenting Parsers to Support Incrementality},
	volume = {27},
	number = {3},
	journal = {Journal of the {ACM} {(JACM)}},
	year = {1980},
	pages = {564--579}
},

@inproceedings{ghica_bounded_2014,
	author = {Dan R. Ghica and Alex I. Smith},
	title = {Bounded Linear Types in a Resource Semiring},
	booktitle = {Programming Languages and Systems - 23rd European Symposium on Programming,
               {ESOP} 2014, Held as Part of the European Joint Conferences on Theory
               and Practice of Software, {ETAPS} 2014, Grenoble, France, April 5-13,
               2014, Proceedings},
	pages = {331--350},
	year = {2014},
	url = {http://dx.doi.org/10.1007/978-3-642-54833-8_18},
	doi = {10.1007/978-3-642-54833-8_18},
	timestamp = {Sun, 23 Mar 2014 10:48:25 +0100},
	biburl = {http://dblp.uni-trier.de/rec/bib/conf/esop/GhicaS14},
	bibsource = {dblp computer science bibliography, http://dblp.org}
},

@inproceedings{giampiccolo_fourth_2008,
	author = {Danilo Giampiccolo and Hoa Trang Dang and Bernardo Magnini and Ido Dagan and Elena Cabrio and William B. Dolan},
	title = {The Fourth {PASCAL} Recognizing Textual Entailment Challenge},
	booktitle = {TAC},
	year = {2008}
},

@article{gibbons_third_1996,
	author = {Jeremy Gibbons},
	title = {The third homomorphism theorem},
	journal = {Journal of Functional Programming},
	volume = {6},
	number = {4},
	pages = {657--665},
	year = {1996}
},

@inproceedings{gibbons_essence_2006,
	author = {Jeremy Gibbons and Bruno Oliveira and Conor Mcbride and Tarmo Uustalu},
	title = {The Essence of the Iterator Pattern},
	url = {http://www.comlab.ox.ac.uk/jeremy.gibbons/publications/iterator-msfp.pdf},
	abstract = {The Iterator pattern gives a clean interface for element-by-element access to a collection. Imperative iterations using the pattern have two simultaneous aspects: mapping and accumulating. Various functional iterations model one or other of these, but not both simultaneously. We argue that {McBride} and Paterson's idioms, and in particular the corresponding traverse operator, do exactly this, and therefore capture the essence of the Iterator pattern. We present some axioms for traversal, and illustrate with a simple example, the repmin problem.},
	booktitle = {{Mathematically-Structured} Functional Programming, Kuressaare, Estonia},
	month = {jul},
	year = {2006},
	keywords = {aop}
},

@incollection{gibbons_datatype-generic_2007,
	author = {Jeremy Gibbons},
	file = {:/home/bernardy/Papers/Datatype-Generic Programming-2007.pdf:pdf},
	title = {{Datatype-Generic} Programming},
	url = {http://dx.doi.org/10.1007/978-3-540-76786-2_1},
	abstract = {Generic programming aims to increase the flexibility of programming languages, by expanding the possibilities for parametrization â ideally, without also expanding the possibilities for uncaught errors. The term means different things to different people: parametric polymorphism, data abstraction, meta-programming, and so on. We use it to mean polytypism, that is, parametrization by the shape of data structures rather than their contents. To avoid confusion with other uses, we have coined the qualified term datatype-generic programming for this purpose. In these lecture notes, we expand on the definition of datatype-generic programming, and present some examples of datatype-generic programs. We also explore the connection with design patterns in object-oriented programming; in particular, we argue that certain design patterns are just higher-order datatype-generic programs.},
	booktitle = {{Datatype-Generic} Programming},
	year = {2007},
	keywords = {concept, typeclass},
	pages = {1--71}
},

@inproceedings{gibbons_parametric_2009,
	author = {Jeremy Gibbons and Ross Paterson},
	address = {Edinburgh, Scotland},
	title = {Parametric datatype-genericity},
	isbn = {978-1-60558-510-9},
	url = {http://portal.acm.org/citation.cfm?id=1596626},
	doi = {10.1145/1596614.1596626},
	abstract = {Datatype-generic programs are programs that are parametrized by a datatype or type functor: whereas polymorphic programs abstract from the "integers" in "lists of integers",datatype-generic programs abstract from the "lists of". There are two main styles of datatype-generic programming: the Algebra of Programming approach, characterized by structured recursion operators arising from initial algebras and final coalgebras, and the Generic Haskell approach, characterized by case analysis over the structure of a datatype. We show that the former enjoys a kind of higher-order naturality, relating the behaviours of generic functions at different types; in contrast, the latter is ad{\textasciitilde}hoc, with no coherence required or provided between the various clauses of a definition. Moreover, the naturality properties arise "for free", simply from the parametrized types of the generic functions: we present a higher-order parametricity theorem for datatype-generic operators.},
	booktitle = {Proceedings of the 2009 {ACM} {SIGPLAN} workshop on Generic programming},
	publisher = {{ACM}},
	year = {2009},
	keywords = {folds, free theorems, functional programming, generic programming, higher-order functions, higher-order natural transformations, parametricity, unfolds},
	pages = {85--93}
},

@article{gibbons_essence_2009,
	author = {Jeremy Gibbons and Bruno C. D. S. Oliveira},
	file = {:/home/bernardy/Papers/The essence of the Iterator pattern-2009.pdf:pdf},
	doi = {10.1017/S0956796809007291},
	issn = {0956-7968},
	journal = {Journal of Functional Programming},
	keywords = {design pattern,fold,idiom,iterator,map,monad,traversal},
	month = {jun},
	number = {3-4},
	pages = {377},
	title = {{The essence of the Iterator pattern}},
	url = {http://www.journals.cambridge.org/abstract\_S0956796809007291},
	volume = {19},
	year = {2009},
	see = {version:gibbons_essence_2006}
},

@article{giegerich_efficient_2003,
	author = {R Giegerich and S Kurtz and J Stoye},
	file = {:/home/bernardy/Papers/Efficient implementation of lazy suffix trees-2003.pdf:pdf},
	doi = {10.1002/spe.535},
	issn = {0038-0644},
	journal = {Software: Practice and Experience},
	keywords = {lazy evaluation,space-efficient implementation,string matching,suffix tree},
	month = {sep},
	number = {11},
	pages = {1035--1049},
	title = {{Efficient implementation of lazy suffix trees}},
	url = {http://doi.wiley.com/10.1002/spe.535},
	volume = {33},
	year = {2003}
},

@InProceedings{gilio_transitive_2015,
	author = {Angelo Gilio and Niki Pfeifer and Giuseppe Sanfilippo},
	editor = {Destercke, S{\'e}bastien and Denoeux, Thierry},
	title = {Transitive Reasoning with Imprecise Probabilities},
	booktitle = {Symbolic and Quantitative Approaches to Reasoning with Uncertainty},
	year = {2015},
	publisher = {Springer International Publishing},
	address = {Cham},
	pages = {95--105},
	isbn = {978-3-319-20807-7}
},

@inproceedings{gill_short_1993,
	author = {Andrew Gill and John Launchbury and Simon {Peyton Jones}},
	file = {:/home/bernardy/Papers/A short cut to deforestation-1993.pdf:pdf},
	address = {Copenhagen, Denmark},
	title = {A short cut to deforestation},
	isbn = {{0-89791-595-X}},
	url = {http://portal.acm.org/citation.cfm?id=165180.165214},
	doi = {10.1145/165180.165214},
	abstract = {Note: {OCR} errors may be found in this Reference List extracted from the full text article. {ACM} has opted to expose the complete List rather than only correct and linked references.},
	booktitle = {Proceedings of the conference on Functional programming languages and computer architecture},
	publisher = {{ACM}},
	year = {1993},
	pages = {223--232}
},

@inproceedings{gill_type-safe_2009,
	author = {Andy Gill},
	editor = {Stephanie Weirich},
	title = {Type-safe observable sharing in Haskell},
	booktitle = {Proceedings of the 2nd {ACM} {SIGPLAN} Symposium on Haskell, Haskell
               2009, Edinburgh, Scotland, UK, 3 September 2009},
	pages = {117--128},
	publisher = {{ACM}},
	year = {2009},
	url = {https://doi.org/10.1145/1596638.1596653},
	doi = {10.1145/1596638.1596653},
	timestamp = {Tue, 06 Nov 2018 16:58:22 +0100},
	biburl = {https://dblp.org/rec/conf/haskell/Gill09.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@inproceedings{giorgolo_monads_2012,
	author = {Gianluca Giorgolo and Ash Asudeh},
	title = {Monads for Conventional Implicatures.},
	booktitle = {Proceedings of Sinn und Bedeutung 16.},
	year = {2012},
	organization = {MITWorking
Papers in Linguistics.}
},

@article{giorgolo_monads_2014,
	author = {Gianluca Giorgolo and Ash Asudeh},
	title = {Monads as a solution for generalized opacity},
	journal = {EACL 2014},
	pages = {19},
	year = {2014}
},

@phdthesis{girard_interprtation_1972,
	author = {Jean-Yves Girard},
	type = {Thèse d'état},
	title = {Interprétation fonctionnelle et elimination des coupures de l'arithmétique d'ordre supérieur},
	school = {Université de Paris 7},
	year = {1972}
},

@article{girard_linear_1987,
	author = {Jean-Yves Girard},
	file = {:/home/bernardy/Papers/Linear logic-1987.pdf:pdf},
	title = {Linear logic},
	journal = {Theoretical Computer Science},
	volume = {50},
	number = {1},
	pages = {1--101},
	year = {1987},
	publisher = {Elsevier},
	see = {:girard_advances_1995;:girard_light_1998}
},

@incollection{girard_parallelism_1987,
	author = {Jean-Yves Girard},
	file = {:/home/bernardy/Papers/Linear logic and parallelism-1987.pdf:pdf},
	forcedkey = {girard_parallelism_1987},
	title = {Linear logic and parallelism},
	booktitle = {Mathematical models for the semantics of parallelism},
	pages = {166--182},
	year = {1987},
	publisher = {Springer}
},

@book{girard_proofs_1989,
	author = {Jean Yves Girard and Yves Lafont and Paul Taylor},
	file = {:/home/bernardy/Papers/Proofs and Types-1989.pdf:pdf},
	title = {Proofs and Types},
	isbn = {0-521-37181-3},
	url = {http://www.paultaylor.eu/stable/Proofs\%2BTypes.html},
	publisher = {Cambridge University Press},
	year = {1989}
},

@inproceedings{girard_geometry_1990,
	author = {Jean-Yves Girard},
	title = {Geometry of interaction 2: deadlock-free algorithms},
	booktitle = {COLOG-88},
	pages = {76--93},
	year = {1990},
	organization = {Springer}
},

@article{girard_new_1991,
	author = {Jean-Yves Girard},
	title = {A new constructive logic: classical logic},
	journal = {Mathematical Structures in Computer Science},
	volume = {1},
	number = {3},
	pages = {255--296},
	year = {1991},
	publisher = {Cambridge Univ Press}
},

@article{girard_bounded_1992,
	author = {Jean-Yves Girard and Andre Scedrov and Philip J. Scott},
	file = {:/home/bernardy/Papers/Bounded linear logic a modular approach to polynomial-time computability -1992.pdf:pdf},
	title = {Bounded linear logic: a modular approach to polynomial-time computability },
	journal = {Theoretical Computer Science},
	volume = {97},
	number = {1},
	pages = {1 - 66},
	year = {1992},
	note = {},
	issn = {0304-3975},
	doi = {http://dx.doi.org/10.1016/0304-3975(92)90386-T},
	url = {http://www.sciencedirect.com/science/article/pii/030439759290386T},
	abstract = {Usual typed lambda-calculi yield input/output specifications; in this paper the authors show how to extend this paradigm to complexity specifications. This is achieved by means of a restricted version of linear logic in which the use of exponential connectives is bounded in advance. This bounded linear logic naturally involves polynomials in its syntax and dynamics. It is then proved that any functional term of appropriate type actually encodes a polynomial-time algorithm and that conversely any polynomial-time function can be obtained in this way. }
},

@book{girard_advances_1995,
	author = {J.Y. Girard and Y. Lafont and L. Regnier},
	title = {Advances in linear logic},
	volume = {222},
	year = {1995},
	publisher = {Cambridge University Press}
},

@article{girard_light_1998,
	author = {Jean-Yves Girard},
	title = {Light linear logic},
	journal = {Information and Computation},
	volume = {143},
	number = {2},
	pages = {175--204},
	year = {1998},
	publisher = {Elsevier}
},

@inbook{girard_point_2004,
	author = {Jean-Yves Girard},
	file = {:/home/bernardy/Papers/Le point aveugle-2004.pdf:pdf},
	chapter = {1-2},
	doi = {10.3917/top.084.0201},
	issn = {0040-9375},
	number = {3},
	pages = {201},
	title = {{Le point aveugle}},
	url = {http://www.cairn.info/revue-topique-2003-3-page-201.htm},
	volume = {84},
	year = {2004}
},

@inbook{girard_blind_2004,
	author = {Jean-Yves Girard},
	file = {:/home/bernardy/Papers/The blind spot-2004.pdf:pdf},
	chapter = {Part III -},
	pages = {182--272},
	title = {{The blind spot}},
	url = {http://iml.univ-mrs.fr/\~{}girard/coursang/coursang0.pdf.gz},
	year = {2004}
},

@InProceedings{glickmann_web_2005,
	author = {O. Glickmann and I. Dagan and M. Koppel},
	title = {Web based probabilistic
textual entailment.},
	booktitle = {Proceedings of the PASCAL Challenges Workshop on Recognizing
Textual Entailment.},
	year = {2005},
	OPTeditor = {},
	OPTpages = {},
	OPTorganization = {},
	OPTpublisher = {},
	OPTaddress = {},
	OPTmonth = {},
	OPTnote = {}
},

@article{glivenko_sur_1929,
	author = {Valery Glivenko},
	title = {Sur quelques points de la logique de {M. Brouwer}},
	journal = {Bulletins de la classe des sciences},
	volume = {15},
	number = {5},
	pages = {183--188},
	year = {1929}
},

@article{glockner_breaking_2018,
	author = {Max Glockner and Vered Shwartz and Yoav Goldberg},
	title = {Breaking nli systems with sentences that require simple lexical inferences},
	journal = {arXiv preprint arXiv:1805.02266},
	year = {2018}
},

@misc{glynn_type_2000,
	author = {K Glynn and P Stuckey and M Sulzmann},
	title = {Type classes and constraint handling rules},
	url = {http://citeseer.ist.psu.edu/334241.html},
	abstract = {Type classes give a clean approach to dene overloading in programming languages such as Haskell. Haskell 98 supports only single-parameter and constructor type classes. Other extensions such as multi-parameter type classes are highly desired but are still not ocially supported in Haskell 98. Subtle issues arise which possibly might lead to a loss of feasible type inference and ambiguous programs. A proper logical fundament for type class systems seems to be missing where such issues can...},
	year = {2000},
	keywords = {typeclass}
},

@incollection{glck_derivation_2004,
	author = {Robert Glück and Masahiko Kawabe},
	title = {Derivation of Deterministic Inverse Programs Based on {LR} Parsing},
	url = {http://www.springerlink.com/content/tfaxx9x8mxukcreb},
	abstract = {We present a method for automatic program inversion of functional programs based on methods of {LR} parsing. We formalize the transformation and illustrate it with the inversion of a program for run-length encoding. We solve one of the main problems of automatic program inversionâthe elimination of nondeterminismâby viewing an inverse program as a context-free grammar and applying to it methods of {LR} parsing to turn it into a recursive, deterministic inverse program. This improves the efficiency of the inverse programs and greatly expands the application range of our earlier method for program inversion.},
	booktitle = {Functional and Logic Programming},
	year = {2004},
	keywords = {aop},
	pages = {291--306}
},

@article{gonthier_formal_2008,
	author = {Georges Gonthier},
	title = {Formal proof--the four-color theorem},
	journal = {Notices of the AMS},
	volume = {55},
	number = {11},
	pages = {1382--1393},
	year = {2008}
},

@techreport{gonthier_ssreflect_tutorial_2009,
	author = {G. Gonthier and S. Le and  others},
	forcedkey = {gonthier_ssreflect_tutorial_2009},
	title = {An {Ssreflect} Tutorial},
	year = {2009},
	institution = {{INRIA}}
},

@inproceedings{gonthier_ssreflect_2009,
	author = {G. Gonthier},
	title = {Ssreflect: Structured Scripting for Higher-Order
                  Theorem Proving},
	booktitle = {PLMMS’09},
	pages = {1},
	year = {2009},
	publisher = {ACM}
},

@incollection{gonthier_machine-checked_2013,
	author = {Georges Gonthier and Andrea Asperti and Jeremy Avigad and Yves Bertot and Cyril Cohen and Fran{\c{c}}ois Garillot and St{\'e}phane Le Roux and Assia Mahboubi and Russell O?Connor and Sidi Ould Biha and  others},
	title = {A machine-checked proof of the odd order theorem},
	booktitle = {Interactive Theorem Proving},
	pages = {163--179},
	year = {2013},
	publisher = {Springer}
},

@misc{gonzalez_pipes_2015,
	author = {Gabriel Gonzalez},
	title = {The pipes package},
	url = {http://hackage.haskell.org/packages/pipes},
	year = {2015}
},

@incollection{goodman_church_2008,
	author = {N. Goodman and V. K. Mansinghka and D. Roy and K. Bonawitz and J. Tenenbaum},
	Booktitle = {Proceedings of the 24th Conference Uncertainty in Artificial Intelligence (UAI)},
	Title = {Church: a Language for Generative Models},
	Pages = {220--229},
	Year = {2008}
},

@article{goodman_knowledge_2013,
	author = {Noah D. Goodman and Andreas Stuhlmüller},
	title = {Knowledge and Implicature: Modeling Language Understanding as Social Cognition},
	volume = {5},
	copyright = {Copyright © 2013 Cognitive Science Society, Inc.},
	issn = {1756-8765},
	shorttitle = {Knowledge and {Implicature}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/tops.12007},
	doi = {https://doi.org/10.1111/tops.12007},
	abstract = {Is language understanding a special case of social cognition? To help evaluate this view, we can formalize it as the rational speech-act theory: Listeners assume that speakers choose their utterances approximately optimally, and listeners interpret an utterance by using Bayesian inference to “invert” this model of the speaker. We apply this framework to model scalar implicature (“some” implies “not all,” and “N” implies “not more than N”). This model predicts an interaction between the speaker's knowledge state and the listener's interpretation. We test these predictions in two experiments and find good fit between model predictions and human judgments.},
	language = {en},
	number = {1},
	urldate = {2021-01-19},
	journal = {Topics in Cognitive Science},
	year = {2013},
	keywords = {Bayesian model, Language, Scalar implicature},
	pages = {173--184}
},

@misc{goodman_design_2014,
	author = {Noah D Goodman and Andreas Stuhlm\"{u}ller},
	title = {The Design and Implementation of Probabilistic Programming Languages},
	year = {2014},
	howpublished = {\url{http://dippl.org}},
	note = {Accessed: 2018-12-10}
},

@incollection{goodman_probabilistic_2015,
	author = {N. Goodman and D. Lassiter},
	Address = {Malden, Oxford},
	Booktitle = {The Handbook of Contemporary Semantic Theory, Second Edition},
	Editor = {S. Lappin and C. Fox},
	Publisher = {Wiley-Blackwell},
	Title = {Probabilistic Semantics and Pragmatics: Uncertainty in Language and Thought},
	Pages = {655--686},
	Year = {2015}
},

@article{goodman_pragmatic_2016,
	author = {Noah D. Goodman and Michael C. Frank},
	title = {Pragmatic {Language} {Interpretation} as {Probabilistic} {Inference}},
	volume = {20},
	issn = {1364-6613},
	url = {https://www.sciencedirect.com/science/article/pii/S136466131630122X},
	doi = {10.1016/j.tics.2016.08.005},
	abstract = {Understanding language requires more than the use of fixed conventions and more than decoding combinatorial structure. Instead, comprehenders make exquisitely sensitive inferences about what utterances mean given their knowledge of the speaker, language, and context. Building on developments in game theory and probabilistic modeling, we describe the rational speech act (RSA) framework for pragmatic reasoning. RSA models provide a principled way to formalize inferences about meaning in context; they have been used to make successful quantitative predictions about human behavior in a variety of different tasks and situations, and they explain why complex phenomena, such as hyperbole and vagueness, occur. More generally, they provide a computational framework for integrating linguistic structure, world knowledge, and context in pragmatic language understanding.},
	language = {en},
	number = {11},
	urldate = {2021-02-11},
	journal = {Trends in Cognitive Sciences},
	month = {nov},
	year = {2016},
	pages = {818--829}
},

@misc{goossens_xetex_2010,
	author = {Michel Goossens},
	file = {:/home/bernardy/Papers/The XETEX Companion-2010.pdf:pdf},
	booktitle = {Writing},
	title = {{The XETEX Companion}},
	year = {2010}
},

@book{gower_procrustes_2004,
	author = {J. C. Gower and Garmt B. Dijksterhuis},
	title = {Procrustes Problems},
	year = {2004},
	publisher = {{Oxford University Press}},
	address = {{Oxford ; New York}},
	annotation = {OCLC: ocm53156636},
	isbn = {978-0-19-851058-1},
	keywords = {Multivariate analysis},
	lccn = {QA278 .G686 2004},
	number = {30},
	series = {Oxford Statistical Science Series}
},

@book{greenberg_simplified_2006,
	author = {Harvey J. Greenberg},
	file = {:/home/bernardy/Papers/A Simplified Introduction to LaTeX-2006.pdf:pdf},
	title = {{A Simplified Introduction to LaTeX}},
	year = {2006}
},

@inproceedings{greenwald_agreeing_2006,
	author = {Michael Greenwald and Sanjeev Khanna and Keshav Kunal and Benjamin Pierce and Alan Schmitt and Shlomi Dolev},
	title = {Agreeing to Agree: {{C}onflict} Resolution for Optimistically Replicated Data},
	booktitle = {International Symposium on Distributed Computing {(DISC)}},
	year = {2006},
	keywords = {bibtex-import, vc}
},

@inproceedings{grefenstette_learning_2015,
	author = {Edward Grefenstette and Karl Moritz Hermann and Mustafa Suleyman and Phil Blunsom},
	title = {Learning to Transduce with Unbounded Memory},
	booktitle = {Proceedings of the 28th International Conference on Neural Information Processing Systems},
	series = {NIPS'15},
	year = {2015},
	location = {Montreal, Canada},
	pages = {1828--1836},
	numpages = {9},
	url = {http://dl.acm.org/citation.cfm?id=2969442.2969444},
	acmid = {2969444},
	publisher = {MIT Press},
	address = {Cambridge, MA, USA}
},

@techreport{gregor_concepts_2006,
	author = {D Gregor},
	title = {Concepts for the {C++0x} Standard Library: Containers},
	year = {2006},
	keywords = {sibylle, wgp08}
},

@techreport{gregor_proposed_2007,
	author = {D Gregor and B Stroustrup and J Siek and James Widman},
	title = {Proposed {{W}ording} for {{C}oncepts} {({R}evision} 4)},
	year = {2007},
	keywords = {sibylle, wgp08},
	annote = {{{\textless}p{\textgreater}Draft,} will be published as a revision to {{\textbackslash}cite{Gregor:2007:PWC}{\textless}/p{\textgreater}}}
},

@techreport{gregor_core_2008,
	author = {D Gregor and A Lumsdaine},
	title = {Core Concepts for the {C++0x} Standard Library},
	year = {2008},
	keywords = {sibylle, wgp08},
	see = {related_library:gregor_concepts_2006}
},

@misc{gregor_conceptgcc_2008,
	author = {Douglas Gregor},
	title = {{Concept{GCC}} --- a prototype compiler for {{\textbackslash}{\textbackslash}Cpp{}} concepts},
	year = {2008},
	keywords = {sibylle, wgp08}
},

@article{grice_meaning_1957,
	author = {H. P. Grice},
	title = {Meaning},
	volume = {66},
	issn = {0031-8108},
	url = {http://www.jstor.org/stable/2182440},
	doi = {10.2307/2182440},
	number = {3},
	urldate = {2021-02-20},
	journal = {The Philosophical Review},
	year = {1957},
	note = {Publisher: [Duke University Press, Philosophical Review]},
	pages = {377--388}
},

@incollection{grice_logic_1975,
	author = {H. Paul Grice},
	address = {New York},
	title = {Logic and {Conversation}},
	volume = {3, Speech Acts},
	booktitle = {Syntax and {Semantics}},
	publisher = {Academic Press},
	editor = {Cole, Peter and Morgan, Jerry L.},
	year = {1975},
	pages = {41--58}
},

@article{grishin_nonstandard_1974,
	author = {Vyacheslav Nikolaevich Grishin},
	title = {A nonstandard logic and its application to set theory,"},
	journal = {Studies in Formalized Languages and Nonclassical Logics (Russian), Izdat,Nauka," Moskow},
	pages = {135--171},
	year = {1974}
},

@article{groenendijk_dynamic_1991,
	author = {Jeroen Groenendijk and Martin Stokhof},
	title = {Dynamic Predicate Logic},
	volume = {14},
	journal = {Linguistics and Philosophy},
	pages = {39--100},
	publisher = {Springer},
	doi = {10.1007/BF00628304},
	year = {1991},
	number = {1}
},

@inproceedings{groote_type_2001,
	author = {Philippe de Groote},
	title = {Type raising, continuations, and classical logic},
	booktitle = {Proceedings of the thirteenth Amsterdam Colloquium},
	pages = {97--101},
	year = {2001}
},

@inproceedings{groote_montagovian_2006,
	author = {Philippe de Groote},
	title = {Towards a Montagovian account of dynamics},
	booktitle = {Semantics and Linguistic Theory},
	volume = {16},
	pages = {1--16},
	year = {2006}
},

@inproceedings{groote_presupposition_2010,
	author = {Philippe de Groote and Ekaterina Lebedeva},
	title = {Presupposition Accommodation As Exception Handling},
	booktitle = {Proceedings of the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
	series = {SIGDIAL '10},
	year = {2010},
	isbn = {978-1-932432-85-5},
	location = {Tokyo, Japan},
	pages = {71--74},
	numpages = {4},
	publisher = {Association for Computational Linguistics},
	address = {Stroudsburg, PA, USA}
},

@phdthesis{grove_scope-taking_2019,
	author = {Julian Grove},
	year = {2019},
	title = {Scope-taking and presupposition satisfaction},
	school = {University of Chicago},
	type = {Doctoral dissertation}
},

@unpublished{grove_algebraic_2021,
	author = {Julian Grove and Jean-Philippe Bernardy},
	year = {2021},
	title = {Algebraic effects for extensible dynamic semantics},
	type = {rejected from Lacl}
},

@inproceedings{grove_compositional_2021,
	author = {Julian Grove and Jean-Philippe Bernardy and Stergios Chatzikyriakidis},
	title = {From compositional semantics to Bayesian pragmatics via logical inference},
	booktitle = {Proceedings of Natural Logic meets Machine Learning 2021},
	year = {2021}
},

@incollection{grudzinska_generalized_2017,
	author = {Justyna Grudzi{\'{n}}ska and Marek Zawadowski},
	editor = {Chatzikyriakidis, Stergios
and Luo, Zhaohui},
	title = {Generalized Quantifiers on Dependent Types: A System for Anaphora},
	booktitle = {Modern Perspectives in Type-Theoretical Semantics},
	year = {2017},
	publisher = {Springer International Publishing},
	address = {Cham},
	pages = {95--131},
	isbn = {978-3-319-50422-3},
	doi = {10.1007/978-3-319-50422-3_5},
	url = {http://dx.doi.org/10.1007/978-3-319-50422-3_5}
},

@inproceedings{guillemette_type-preserving_2007,
	author = {Louis-Julien Guillemette and Stefan Monnier},
	title = {A type-preserving closure conversion in haskell},
	booktitle = {Proceedings of the ACM SIGPLAN workshop on Haskell},
	pages = {83--92},
	year = {2007},
	organization = {ACM}
},

@inproceedings{guillemette_type-preserving_2008,
	author = {Louis-Julien Guillemette and Stefan Monnier},
	file = {:/home/bernardy/Papers/A type-preserving compiler in Haskell-2008.pdf:pdf;:/home/bernardy/Papers/A type-preserving compiler in Haskell-2008.Yms:Yms},
	title = {A type-preserving compiler in Haskell},
	booktitle = {Proceedings of the 13th {ACM} {SIGPLAN} international conference on Functional Programming},
	pages = {75--86},
	year = {2008},
	organization = {ACM}
},

@article{gulordava_colorless_2018,
	author = {Kristina Gulordava and Piotr Bojanowski and Edouard Grave and Tal Linzen and Marco Baroni},
	title = {Colorless green recurrent networks dream hierarchically},
	journal = {arXiv preprint arXiv:1803.11138},
	year = {2018}
},

@article{gulordava_colorless_2018,
	author = {Kristina Gulordava and Piotr Bojanowski and Edouard Grave and Tal Linzen and Marco Baroni},
	title = {Colorless green recurrent networks dream hierarchically},
	journal = {arXiv preprint arXiv:1803.11138},
	year = {2018}
},

@incollection{gumperz_speech_1972,
	author = {J Gumperz},
	title = {The {{Speech Community}}},
	booktitle = {Language and Social Context: Selected Readings},
	editor = {Giglioli, Pier Paolo},
	year = {1972},
	publisher = {{Harmondsworth : Penguin}},
	abstract = {399 pages ; 18 cm; Includes bibliographical references; Hymes, D. Toward ethnographies of communication.--Fishman, J.A. The sociology of language.--Goffman, E. The neglected situation.--Basso, K.H. To give up on words: silence in Western Apache culture.--Frake, C.O. How to ask for a drink in Subanun.--Schegloff, E.A. Notes on a conversational practice: formulating place.--Searle, J. What is a speech act?--Bernstein, B. Social class, language and socialization.--Labov, W. The logic of nonstandard English.--Gumperz, J. The speech community.--Ferguson, C.A. Diglossia.--Brown, R. and Gilman, A. The pronouns of power and solidarity.--Labov, W. The study of language in its social context.--Goody, J. and Watt, I. The consequences of literacy.--Inglehart, R. and Woodward, M. Language conflicts and the political community},
	isbn = {978-0-14-080244-3 978-0-14-022649-2},
	keywords = {Sociolinguistics},
	language = {eng}
},

@inproceedings{guo_hierarchically_2006,
	author = {Jia Guo and Ganesh Bikshandi and Daniel Hoeflinger and Gheorghe Almasi and Basilio Fraguela and Mar{\'\i}a Jes{\'u}s Garzar{\'a}n and David Padua and Christoph Von Praun},
	title = {Hierarchically tiled arrays for parallelism and locality},
	booktitle = {Parallel and Distributed Processing Symposium, 2006. IPDPS 2006. 20th International},
	pages = {8--pp},
	year = {2006},
	organization = {IEEE}
},

@article{gururangan_annotation_2018,
	author = {Suchin Gururangan and Swabha Swayamdipta and Omer Levy and Roy Schwartz and Samuel R Bowman and Noah A Smith},
	title = {Annotation artifacts in natural language inference data},
	journal = {arXiv preprint arXiv:1803.02324},
	year = {2018}
},

@misc{glineau_samuels_2009,
	author = {Samuel Gélineau},
	title = {Samuel's Really Straightforward Proof of the Parametricity Result, extended (trivially) to dependent types.},
	url = {http://gelisam.blogspot.com/2009/09/samuels-really-straightforward-proof-of.html},
	year = {2009},
	howpublished = {\url{http://gelisam.blogspot.com/2009/09/samuels-really-straightforward-proof-of.html}}
},

@book{halpern_reasoning_2017,
	author = {Joseph Y. Halpern},
	title = {Reasoning About Uncertainty},
	year = {2017},
	publisher = {MIT Press},
	address = {Cambridge, MA, USA}
},

@phdthesis{hansson_tool_2014,
	author = {Kristoffer Hansson and Jonas Hugo},
	type = {{MSc} Thesis},
	title = {A tool to generate an incremental lexer from a lexical specification},
	school = {Chalmers University of Technology},
	year = {2014}
},

@incollection{harper_type_1989,
	author = {Robert Harper and Robert Pollack},
	title = {Type checking, universe polymorphism, and typical ambiguity in the calculus of constructions draft},
	url = {http://dx.doi.org/10.1007/3-540-50940-2_39},
	abstract = {The Generalized Calculus of Constructions {(CC)} of Coquand and Huet is a system for formalizing constructive mathematics. {CC} includes a cumulative hierarchy of universes, with each universe closed under the type forming operations. Universe hierarchies are tedious to use in practice. Russell and Whitehead introduced a convention for dealing with stratification, called typical ambiguity, in which universe levels are not explicitly mentioned, but it is tactily asserted that some correctly stratified level assignment exists. Using an operational semantics for type synthesis, we study type checking and typical ambiguity for {CC.} We show type synthesis is effective in {CC.} Even if explicit universe levels are erased from a term it is possible to compute a schematic type for that term, and a set of constraints, that characterize all types of all well-typed instances of the term. We also consider the extension with -reductions, which introduces a form of universe polymorphism induced by the failure of type unicity in {CC.}},
	booktitle = {{TAPSOFT} '89},
	year = {1989},
	pages = {241--256}
},

@misc{harper_foundations_2013,
	author = {Robert W. Harper},
	title = {Foundations and Applications of Higher-Dimensional Directed Type Theory},
	year = {2013},
	note = {Research programme \HREF{available online}{http://www.cs.cmu.edu/~rwh/papers/2dtt-nsf/description.pdf}}
},

@book{harper_practical_????,
	author = {Robert Harper},
	file = {:/home/bernardy/Papers/Practical Foundations for Programming Languages-????.pdf:pdf},
	title = {Practical Foundations for Programming Languages},
	url = {http://www.cs.cmu.edu/~rwh/plbook/book.pdf}
},

@article{harrop_disjunctions_1956,
	author = {Ronald Harrop},
	title = {{On disjunctions and existential statements in intuitionistic systems of logic}},
	journal = {Mathematische Annalen},
	volume = {132},
	number = {4},
	pages = {347--361},
	year = {1956},
	publisher = {Springer}
},

@inproceedings{haruta_logical_2020,
	author = {Izumi Haruta and Koji Mineshima and Daisuke Bekki},
	editor = {Shruti Rijhwani and
               Jiangming Liu and
               Yizhong Wang and
               Rotem Dror},
	title = {Logical Inferences with Comparatives and Generalized Quantifiers},
	booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational
               Linguistics: Student Research Workshop, {ACL} 2020, Online, July 5-10,
               2020},
	pages = {263--270},
	publisher = {Association for Computational Linguistics},
	year = {2020},
	url = {https://www.aclweb.org/anthology/2020.acl-srw.35/},
	timestamp = {Thu, 25 Jun 2020 16:12:00 +0200},
	biburl = {https://dblp.org/rec/conf/acl/HarutaMB20.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@book{hawkins_definiteness_2015,
	author = {John A Hawkins},
	title = {Definiteness and indefiniteness: A study in reference and grammaticality prediction},
	volume = {11},
	year = {2015},
	publisher = {Routledge}
},

@phdthesis{heim_semantics_1982,
	author = {Irene Heim},
	year = {1982},
	school = {UMass Amherst},
	title = {The Semantics of Definite and Indefinite Noun Phrases}
},

@book{heim_semantics_1998,
	author = {Irene Heim and Angelika Kratzer},
	year = {1998},
	publisher = {Blackwell},
	title = {Semantics in Generative Grammar}
},

@misc{heinz_listings_2007,
	author = {Carsten Heinz and Brooks Moses},
	file = {:/home/bernardy/Papers/The Listings Package-2007.pdf:pdf},
	pages = {1--58},
	title = {{The Listings Package}},
	year = {2007}
},

@article{heunen_arrows_2006,
	author = {Chris Heunen and Bart Jacobs},
	title = {Arrows, like monads, are monoids},
	journal = {Electronic Notes in Theoretical Computer Science},
	volume = {158},
	pages = {219--236},
	year = {2006},
	publisher = {Elsevier}
},

@article{hewitt_rnns_2020,
	author = {John Hewitt and Michael Hahn and Surya Ganguli and Percy Liang and Christopher D Manning},
	title = {RNNs can generate bounded hierarchical languages with optimal memory},
	journal = {arXiv preprint arXiv:2010.07515},
	summary_jp = {This is a theoretical construction.
  Stack is implemented using shift matrices of the form

  0 0 0 0
  1 0 0 0
  0 1 0 0
  0 0 1 0
                  
   Experiment: For all configurations, we find that the LSTMs using
   our memory limit achieve error less than 10e−4 when trained on 20
   million tokens.  Strikingly, this is despite the fact that for
   large m (nesting depth) and k (bracket types), a small fraction of
   the possible stack states is seen at training time; this shows that
   the LSTMs are not simply learning k^m structureless DFA
   (deterministic finite automaton) states.
                  
},
	url = {https://arxiv.org/pdf/2010.07515.pdf},
	year = {2020}
},

@InProceedings{hickl_recognizing_2005,
	author = {A. Hickl and J. Williams and J. Bensley and K. Roberts and B. Rink and Y. Shi},
	title = {Recognizing Textual Entailment with L{CC}'s
GROUNDHOG System},
	booktitle = {Proc. of Second {PASCAL} Challenges Workshop on Recognizing
Textual Entailment},
	year = {2005},
	pages = {80-85},
	OPTorganization = {},
	OPTpublisher = {},
	OPTaddress = {},
	OPTmonth = {},
	OPTnote = {}
},

@misc{hicks_adapting_2008,
	author = {Michael Hicks and Jeffrey S. Foster},
	file = {:/home/bernardy/Papers/Adapting Scrum to Managing a Research Group-2008.pdf:pdf},
	title = {Adapting Scrum to Managing a Research Group},
	year = {2008},
	url = {http://www.cs.umd.edu/~mwh/papers/scram.pdf}
},

@book{higginbotham_tense_2009,
	author = {James Higginbotham},
	title = {Tense, aspect, and indexicality},
	volume = {26},
	year = {2009},
	publisher = {OUP Oxford}
},

@article{hill_simlex-999_2015,
	author = {Felix Hill and Roi Reichart and Anna Korhonen},
	title = {Simlex-999: Evaluating Semantic Models with Genuine Similarity Estimation},
	journal = {Comput. Linguist.},
	issue_date = {December 2015},
	volume = {41},
	number = {4},
	month = {dec},
	year = {2015},
	issn = {0891-2017},
	pages = {665--695},
	numpages = {31},
	acmid = {2893324},
	publisher = {MIT Press},
	address = {Cambridge, MA, USA}
},

@inproceedings{hinze_type-indexed_2002,
	author = {Ralf Hinze and Johan Jeuring and Andres Löh},
	file = {:/home/bernardy/Papers/Type-Indexed Data Types-2002.pdf:pdf},
	title = {{Type-Indexed} Data Types},
	isbn = {3-540-43857-2},
	url = {http://portal.acm.org/citation.cfm?id=747315},
	booktitle = {Proceedings of the 6th International Conference on Mathematics of Program Construction},
	publisher = {{Springer-Verlag}},
	year = {2002},
	pages = {148--174}
},

@article{hinze_generics_2004,
	author = {Ralf Hinze},
	title = {Generics for the masses},
	volume = {39},
	url = {http://portal.acm.org/citation.cfm?id=1016882},
	doi = {10.1145/1016848.1016882},
	abstract = {A generic function is a function that can be instantiated on many data types to obtain data type specific functionality. Examples of generic functions are the functions that can be derived in Haskell, such as show, read, and '=='. The recent years have seen a number of proposals that support the definition of generic functions. Some of the proposals define new languages, some define extensions to existing languages. As a common characteristic none of the proposals can be made to work within Haskell 98: they all require something extra, either a more sophisticated type system or an additional language construct. The purpose of this pearl is to show that one can, in fact, program generically within Haskell 98 obviating to some extent the need for fancy type systems or separate tools. Haskell's type classes are at the heart of this approach: they ensure that generic functions can be defined succinctly and, in particular, that they can be used painlessly.},
	number = {9},
	journal = {{SIGPLAN} Not.},
	year = {2004},
	keywords = {generic programming, haskell 98, type classes},
	pages = {236--243}
},

@article{hinze_church_2005,
	author = {Ralf Hinze},
	file = {:/home/bernardy/Papers/Church Numerals, Twice!-2005.pdf:pdf},
	title = {Church Numerals, Twice!},
	volume = {15},
	url = {http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=266743},
	doi = {10.1017/S0956796804005313},
	number = {1},
	journal = {Journal of Functional Programming},
	year = {2005},
	pages = {1--13}
},

@article{hinze_finger_2006,
	author = {Ralf Hinze and Ross Paterson},
	file = {:/home/bernardy/Papers/Finger trees a simple general-purpose data structure-2006.bGQ:bGQ},
	title = {Finger trees: a simple general-purpose data structure},
	journal = {Journal of Functional Programming},
	volume = {16},
	number = {2},
	pages = {197--218},
	year = {2006},
	publisher = {Cambridge Univ Press}
},

@book{hinze_typed_2006,
	author = {Ralf Hinze and Johan Jeuring and Andres Löh},
	title = {Typed Contracts for Functional Programming},
	volume = {3945},
	url = {http://dx.doi.org/10.1007/11737414_15},
	abstract = {A robust software component fulfills a contract: it expects data satisfying a certain property and promises to return data satisfying another property. The object-oriented community uses the design-by-contract approach extensively. Proposals for language extensions that add contracts to higher-order functional programming have appeared recently. In this paper we propose an embedded domain-specific language for typed, higher-order and first-class contracts, which is both more expressive than previous proposals, and allows for a more informative blame assignment. We take some first steps towards an algebra of contracts, and we show how to define a generic contract combinator for arbitrary algebraic data types. The contract language is implemented as a library in Haskell using the concept of generalised algebraic data types.},
	month = {jan},
	year = {2006},
	keywords = {blame, contract, invariant},
	pages = {208--225}
},

@misc{hinze_guide2lhs2tex_2007,
	author = {Ralf Hinze and Andres L\"{o}h},
	file = {:/home/bernardy/Papers/Guide2lhs2TeX-2007.pdf:pdf},
	pages = {1--37},
	title = {{Guide2lhs2TeX}},
	year = {2007}
},

@article{hinze_generic_2009,
	author = {Ralf Hinze and Andres Löh},
	title = {Generic programming in {3D}},
	volume = {74},
	url = {http://portal.acm.org/citation.cfm?id=1537539},
	abstract = {Support for generic programming consists of three essential ingredients: support for overloaded functions, a run-time type representation, and a generic view on data. Different approaches to datatype-generic programming occupy different points in this design space. In this article, we revisit the {''Scrap} your boilerplate'' approach and identify its location within the three-dimensional design space. The characteristic features of {''Scrap} your boilerplate'' are its two generic views, the 'spine' view for consuming and transforming data, and the 'type-spine' view for producing data. We show how to combine these views with different overloading mechanisms and type representations.},
	number = {8},
	journal = {Sci. Comput. Program.},
	year = {2009},
	keywords = {generic programming, haskell 98, language design, type classes},
	pages = {590--628}
},

@misc{hinze_lhs2tex_2009,
	author = {Ralf Hinze},
	file = {:/home/bernardy/Papers/Lhs2TeX manual-2009.pdf:pdf},
	booktitle = {Sciences-New York},
	pages = {1--37},
	title = {{Lhs2TeX manual}},
	year = {2009}
},

@article{hirschowitz_topological_2008,
	author = {André Hirschowitz and Michel Hirschowitz and Tom Hirschowitz},
	title = {Topological observations on multiplicative additive linear logic},
	journal = {arXiv preprint arXiv:0807.2636},
	year = {2008}
},

@article{hirschowitz_contraction-free_2009,
	author = {Andr{\'e} Hirschowitz and Michel Hirschowitz and Tom Hirschowitz},
	title = {Contraction-free proofs and finitary games for Linear Logic},
	journal = {Electronic Notes in Theoretical Computer Science},
	volume = {249},
	pages = {287--305},
	year = {2009},
	publisher = {Elsevier}
},

@article{hirschowitz_topological_????,
	author = {Andr{\'e} Hirschowitz and Michel Hirschowitz and Tom Hirschowitz},
	title = {Towards Topological Games}
},

@article{hochreiter_long_1997,
	author = {Sepp Hochreiter and J{\"u}rgen Schmidhuber},
	title = {Long short-term memory},
	year = {1997},
	month = {nov},
	volume = {9},
	pages = {1735--1780},
	publisher = {MIT Press},
	issn = {0899-7667},
	doi = {10.1162/neco.1997.9.8.1735},
	abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	journal = {Neural Computation},
	number = {8}
},

@inproceedings{hockenmaier_learning_2017,
	author = {Julia Hockenmaier and Alice Lai},
	title = {Learning to Predict Denotational Probabilities For Modeling Entailment},
	booktitle = {Proceedings of the 15th Conference of the European Chapter of the
               Association for Computational Linguistics, {EACL} 2017, Valencia,
               Spain, April 3-7, 2017, Volume 1: Long Papers},
	pages = {721--730},
	year = {2017}
},

@article{hoffman_testing_1998,
	author = {Daniel Hoffman and Jayakrishnan Nair and Paul Strooper},
	title = {Testing generic {{Ada}} packages with {APE}},
	volume = {{XVIII}},
	url = {http://portal.acm.org/citation.cfm?id=301687.289640},
	doi = {10.1145/301687.289640},
	abstract = {Note: {OCR} errors may be found in this Reference List extracted from the full text article. {ACM} has opted to expose the complete List rather than only correct and linked references.},
	number = {6},
	journal = {Ada Letters},
	year = {1998},
	pages = {255--262}
},

@inproceedings{hofmann_groupoid_1996,
	author = {Martin Hofmann and Thomas Streicher},
	file = {:/home/bernardy/Papers/The Groupoid Interpretation of Type Theory-1996.pdf:pdf},
	title = {The Groupoid Interpretation of Type Theory},
	booktitle = {Venice Festschrift},
	year = {1996},
	pages = {83--111},
	publisher = {Oxford University Press}
},

@incollection{hofmann_type_2000,
	author = {Martin Hofmann},
	affiliation = {LFCS Edinburgh Mayfield Rd Edinburgh EH9 3JZ UK},
	title = {A Type System for Bounded Space and Functional In-Place Update—Extended Abstract},
	booktitle = {Programming Languages and Systems},
	series = {Lecture Notes in Computer Science},
	editor = {Smolka, Gert},
	publisher = {Springer Berlin / Heidelberg},
	isbn = {978-3-540-67262-3},
	keyword = {Computer Science},
	pages = {165-179},
	volume = {1782},
	doi = {10.1007/3-540-46425-5_11},
	abstract = {We show how linear typing can be used to obtain functional programs which modify heap-allocated data structures in place. We present this both as a “design pattern” for writing C-code in a functional style and as a compilation process from linearly typed first-order functional programs into malloc()-free C code. The main technical result is the correctness of this compilation. The crucial innovation over previous linear typing schemes consists of the introduction of a resource type ◊ which controls the number of constructor symbols such as cons in recursive definitions and ensures linear space while restricting expressive power surprisingly little. While the space efficiency brought about by the new typing scheme and the compilation into C can also be realised by with state-of-the-art optimising compilers for functional languages such as Ocaml [ 15 ], the present method provides guaranteed bounds on heap space which will be of use for applications such as languages for embedded systems or ‘proof carrying code’ [ 18 ].},
	year = {2000}
},

@MISC{hofmann_in-place_2000,
	author = {Martin Hofmann},
	title = {In-place update with linear types or How to compile functional programs into malloc()-free C},
	note = {Preprint},
	year = {2000}
},

@Inbook{honda_types_1993,
	author = {Kohei Honda},
	editor = {Best, Eike},
	title = {Types for dyadic interaction},
	bookTitle = {CONCUR'93: 4th Intrenational Conference on Concurrency
                  Theory Hildesheim, Germany, August 23--26, 1993
                  Proceedings},
	year = {1993},
	publisher = {Springer Berlin Heidelberg},
	address = {Berlin, Heidelberg},
	pages = {509--523},
	isbn = {978-3-540-47968-0},
	doi = {10.1007/3-540-57208-2_35},
	url = {http://dx.doi.org/10.1007/3-540-57208-2_35}
},

@misc{honnibal_spacy_2017,
	author = {Matthew Honnibal and Ines Montani},
	title = {{{spaCy}} 2: {{Natural}} Language Understanding with {{Bloom}} Embeddings, Convolutional Neural Networks and Incremental Parsing},
	year = {2017},
	howpublished = {Explosion}
},

@inproceedings{honsell_pre-logical_2009,
	author = {F. Honsell and D. Sannella},
	file = {:/home/bernardy/Papers/Pre-logical relations-2009.pdf:pdf},
	title = {Pre-logical relations},
	booktitle = {Computer Science Logic},
	pages = {826--826},
	year = {2009},
	series = {Lecture Notes in Computer Science},
	volume = {1683},
	doi = {10.1007/3-540-48168-0},
	publisher = {Springer}
},

@article{hoste_introduction_2005,
	author = {Kenneth Hoste},
	file = {:/home/bernardy/Papers/An Introduction to Gtk2Hs, a Haskell GUI Library-2005.pdf:pdf},
	journal = {The Monad Reader},
	number = {1},
	pages = {1--15},
	title = {{An Introduction to Gtk2Hs, a Haskell GUI Library}},
	year = {2005}
},

@inproceedings{hovy_demographic_2015,
	author = {Dirk Hovy},
	title = {Demographic {{Factors Improve Classification Performance}}},
	booktitle = {Proceedings of the 53rd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} and the 7th {{International Joint Conference}} on {{Natural Language Processing}} ({{Volume}} 1: {{Long Papers}})},
	year = {2015},
	month = {jul},
	pages = {752--762},
	publisher = {{Association for Computational Linguistics}},
	address = {{Beijing, China}},
	doi = {10.3115/v1/P15-1073}
},

@incollection{huang_anaphora_2005,
	author = {Y. Huang},
	volume = {1},
	booktitle = {Encyclopedia of language and lingustics},
	editor = {K. Brown},
	address = {New York},
	title = {Anaphora, cataphora, exophora, logophoricity},
	publisher = {Elsevier},
	year = {2005},
	pages = {231--238}
},

@inproceedings{huang_enriching_2014,
	author = {Yu-Yang Huang and Rui Yan and Tsung-Ting Kuo and Shou-De Lin},
	title = {Enriching {{Cold Start Personalized Language Model Using Social Network Information}}},
	booktitle = {Proceedings of the 52nd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 2: {{Short Papers}})},
	year = {2014},
	pages = {611--617},
	publisher = {{Association for Computational Linguistics}},
	address = {{Baltimore, Maryland}},
	doi = {10.3115/v1/P14-2100},
	abstract = {Personalized language models are useful in many applications, such as personalized search and personalized recommendation. Nevertheless, it is challenging to build a personalized language model for cold start users, in which the size of the training corpus of those users is too small to create a reasonably accurate and representative model. We introduce a generalized framework to enrich the personalized language models for cold start users. The cold start problem is solved with content written by friends on social network services. Our framework consists of a mixture language model, whose mixture weights are estimated with a factor graph. The factor graph is used to incorporate prior knowledge and heuristics to identify the most appropriate weights. The intrinsic and extrinsic experiments show significant improvement on cold start users.},
	language = {en}
},

@inproceedings{huang_densely_2017,
	author = {Gao Huang and Zhuang Liu},
	title = {Densely connected convolutional networks},
	year = {2017}
},

@Inbook{hudak_arrows_2003,
	author = {Paul Hudak and Antony Courtney and Henrik Nilsson and John Peterson},
	editor = {Jeuring, Johan and {Peyton Jones}, Simon},
	title = {Arrows, Robots, and Functional Reactive Programming},
	bookTitle = {Advanced Functional Programming: 4th International School, AFP 2002, Oxford, UK, August 19-24, 2002. Revised Lectures},
	year = {2003},
	publisher = {Springer Berlin Heidelberg},
	address = {Berlin, Heidelberg},
	pages = {159--187},
	abstract = {Functional reactive programming},
	isbn = {978-3-540-44833-4},
	doi = {10.1007/978-3-540-44833-4_6},
	url = {https://doi.org/10.1007/978-3-540-44833-4_6}
},

@inproceedings{hudak_history_2007,
	author = {Paul Hudak and John Hughes and Simon {Peyton Jones} and Philip Wadler},
	title = {A History of Haskell: Being Lazy with Class},
	year = {2007},
	isbn = {9781595937667},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/1238844.1238856},
	doi = {10.1145/1238844.1238856},
	abstract = {This paper describes the history of Haskell, including its genesis and principles, technical contributions, implementations and tools, and applications and impact.},
	booktitle = {Proceedings of the Third ACM SIGPLAN Conference on History of Programming Languages},
	pages = {12–1–12–55},
	numpages = {55},
	location = {San Diego, California},
	series = {HOPL III}
},

@article{hudson_incremental_1991,
	author = {Scott Hudson},
	file = {:/home/bernardy/Papers/Incremental attribute evaluation a flexible algorithm for lazy update-1991.pdf:pdf},
	title = {Incremental attribute evaluation: a flexible algorithm for lazy update},
	volume = {13},
	issn = {0164-0925},
	url = {http://dx.doi.org/10.1145/117009.117012},
	number = {3},
	journal = {{ACM} Trans. Program. Lang. Syst.},
	month = {jul},
	year = {1991},
	keywords = {lazy},
	pages = {315--341}
},

@article{huet_zipper_1997,
	author = {Gérard Huet},
	title = {The Zipper},
	volume = {7},
	url = {http://portal.acm.org/citation.cfm?id=969872},
	abstract = {Almost every programmer has faced the problem of representing a tree together with a subtree that is the focus of attention, where that focus may move left, right, up or down the tree. The Zipper is Huet's nifty name for a nifty data structure which fulfills this need. I wish I had known of it when I faced this task, because the solution I came up with was not quite so efficient or elegant as the Zipper.},
	number = {5},
	journal = {J. Funct. Program.},
	year = {1997},
	pages = {549--554}
},

@article{hughes_novel_1986,
	author = {R J M Hughes},
	title = {A novel representation of lists and its application to the function "reverse"},
	volume = {22},
	url = {http://portal.acm.org/citation.cfm?id=8468.8475},
	number = {3},
	journal = {Inf. Process. Lett.},
	year = {1986},
	pages = {141--144}
},

@article{hughes_functional_1989,
	author = {J Hughes},
	file = {:/home/bernardy/Papers/Why Functional Programming Matters-1989.pdf:pdf},
	title = {Why Functional Programming Matters},
	volume = {32},
	url = {http://citeseer.ist.psu.edu/hughes84why.html},
	abstract = {As software becomes more and more complex, it is more and more important to structure it well. Well-structured software is easy to write, easy to debug, and provides a collection of modules that can be re-used to reduce future programming costs. Conventional languages place conceptual limits on the way problems can be modularised. Functional languages push those limits back. In this paper we show that two features of functional languages in particular, higher-order functions and lazy...},
	number = {2},
	journal = {Computer Journal},
	year = {1989},
	keywords = {haskell},
	pages = {98--107}
},

@inproceedings{hughes_design_1995,
	author = {John Hughes},
	title = {The Design of a Pretty-printing Library},
	isbn = {3-540-59451-5},
	url = {http://portal.acm.org/citation.cfm?id=734154},
	booktitle = {Advanced Functional Programming, First International Spring School on Advanced Functional Programming {Techniques-Tutorial} Text},
	publisher = {{Springer-Verlag}},
	year = {1995},
	pages = {53--96}
},

@misc{hughes_restricted_1999,
	author = {J Hughes},
	title = {Restricted Datatypes in Haskell},
	url = {http://citeseer.ist.psu.edu/hughes99restricted.html},
	abstract = {The implementations of abstract type constructors must often restrict the type parameters: for example, one implementation of sets may require equality on the element type, while another implementation requires an ordering. Haskell has no mechanism to abstract over such restrictions, which can hinder us from replacing one implementation by another, or making several implementations instances of the same class. This paper proposes a language extension called restricted data types to...},
	year = {1999}
},

@article{hughes_generalising_2000,
	author = {John Hughes},
	title = {Generalising monads to arrows},
	journal = {Sci. Comput. Program.},
	volume = {37},
	number = {1-3},
	pages = {67--111},
	year = {2000},
	url = {https://doi.org/10.1016/S0167-6423(99)00023-4},
	doi = {10.1016/S0167-6423(99)00023-4},
	timestamp = {Wed, 14 Nov 2018 10:21:27 +0100},
	biburl = {https://dblp.org/rec/bib/journals/scp/Hughes00},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@inproceedings{hughes_polish_2003,
	author = {R. John M. Hughes and S. Doaitse Swierstra},
	file = {:/home/bernardy/Papers/Polish parsers, step by step-2003.pdf:pdf},
	address = {Uppsala, Sweden},
	title = {Polish parsers, step by step},
	isbn = {1-58113-756-7},
	url = {http://portal.acm.org/citation.cfm?id=944705.944727},
	doi = {10.1145/944705.944727},
	abstract = {We present the derivation of a space efficient parser combinator library: the constructed parsers do not keep unnecessary references to the input, produce online results and efficiently handle ambiguous grammars. The underlying techniques can be applied in many contexts where traditionally backtracking is {used.We} present two data types, one for keeping track of the progress of the search process, and one for representing the final result in a linear way. Once these data types are combined into a single type, we can perform a breadth-first search, while returning parts of the result as early as possible.},
	booktitle = {Proceedings of the eighth {ACM} {SIGPLAN} international conference on Functional Programming},
	publisher = {{ACM}},
	year = {2003},
	keywords = {ambiguous grammars, breadth-first search, glr parsing, online results, parser combinators, polish representation},
	pages = {239--248}
},

@incollection{hughes_quickcheck_2007,
	author = {John Hughes},
	title = {{QuickCheck} Testing for Fun and Profit},
	url = {http://dx.doi.org/10.1007/978-3-540-69611-7_1},
	abstract = {One of the nice things about purely functional languages is that functions often satisfy simple properties, and enjoy simple
algebraic relationships. Indeed, if the functions of an {API} satisfy elegant laws, that in itself is a sign of a good design—the
laws not only indicate conceptual simplicity, but are useful in practice for simplifying programs that use the {API,} by equational
reasoning or otherwise.},
	booktitle = {Practical Aspects of Declarative Languages},
	publisher = {Springer},
	year = {2007},
	pages = {1--32}
},

@inproceedings{hunt_distributed_1997,
	author = {James Hunt and Frank Lamers and Jurgen Reuter and Walter Tichy},
	title = {Distributed Configuration Management via Java and the World Wide Web},
	url = {http://citeseer.ist.psu.edu/hunt97distributed.html},
	abstract = {. The introduction of Java has been heralded as a revolution in network computing. Certainly, machine and operating system independent applets flittering through the Internet promised to jazz up web surfing; but could they be used to advantage for distributed computing ? The authors had encountered substantial problems in implementing a distributed revision control system, called {WWRC,} based on passive Web browsers. Java seemed to offer solutions to these problems. To this end, the...},
	booktitle = {System Configuration Management},
	year = {1997},
	keywords = {vc},
	pages = {161--174}
},

@inproceedings{hurkens_simplification_1995,
	author = {Antonius J. C. Hurkens},
	file = {:/home/bernardy/Papers/A simplification of Girard's paradox-1995.pdf:pdf},
	booktitle = {Typed Lambda Calculi and Applications},
	pages = {266--278},
	publisher = {Springer},
	title = {{A simplification of Girard's paradox}},
	url = {http://www.springerlink.com/index/w718604jn467672h.pdf},
	year = {1995}
},

@article{hutton_monadic_1998,
	author = {G. Hutton and E. Meijer},
	title = {Monadic parsing in Haskell},
	volume = {8},
	number = {04},
	journal = {Journal of Functional Programming},
	year = {1998},
	pages = {437--444}
},

@article{hyland_full_1993,
	author = {Martin Hyland and Valeria de Paiva},
	title = {Full intuitionistic linear logic},
	journal = {Annals of Pure and Applied Logic},
	volume = {64},
	number = {3},
	pages = {273--291},
	year = {1993},
	publisher = {Elsevier}
},

@article{hyland_combining_2006,
	author = {Martin Hyland and Gordon Plotkin and John Power},
	title = {Combining Effects: Sum and Tensor},
	journal = {Theor. Comput. Sci.},
	issue_date = {25 July 2006},
	volume = {357},
	number = {1},
	month = {jul},
	year = {2006},
	issn = {0304-3975},
	pages = {70--99},
	numpages = {30},
	url = {http://dx.doi.org/10.1016/j.tcs.2006.03.013},
	doi = {10.1016/j.tcs.2006.03.013},
	acmid = {1161499},
	publisher = {Elsevier Science Publishers Ltd.},
	address = {Essex, UK},
	keywords = {Lawvere theory, computational effect, modularity, monad}
},

@InProceedings{ionescu_domain-specific_2015,
	author = {Cezar Ionescu and Patrik Jansson},
	title = {Domain-Specific Languages of Mathematics: Presenting
                  Mathematical Analysis using Functional Programming},
	booktitle = {Proceedings 4th International Workshop on Trends in
                  Functional Programming in Education},
	year = {2015},
	series = {Electronic Proceedings in Theoretical Computer
                  Science},
	publisher = {Open Publishing Association},
	TODOpages = {},
	TODOdoi = {},
	TODOISSN = {}
},

@book{jackson_principles_1975,
	author = {Michael A. Jackson},
	title = {Principles of Program Design},
	year = {1975},
	isbn = {0123790506},
	publisher = {Academic Press, Inc.},
	address = {Orlando, FL, USA}
},

@article{jacobs_categorical_2009,
	author = {Bart Jacobs and Chris Heunen and Ichiro Hasuo},
	title = {Categorical semantics for arrows},
	journal = {Journal of functional programming},
	volume = {19},
	number = {3-4},
	pages = {403--438},
	year = {2009},
	publisher = {Cambridge University Press}
},

@InProceedings{jansson_testing_2007,
	author = {Patrik Jansson and Johan Jeuring and  {students of the
                  Utrecht University Generic Programming class}},
	title = {Testing properties of generic functions},
	booktitle = {Proceedings of IFL 2006},
	pages = {217--234},
	year = {2007},
	editor = {Zoltan Horvath},
	volume = {4449},
	series = {Lecture Notes in Computer Science},
	publisher = {Springer},
	citations = {1 (2009-03-23)}
},

@book{jensen_pascal_1991,
	author = {Kathleen Jensen and Niklaus Wirth and Andrew B. Mickel and James F. Miner},
	title = {{PASCAL} user manual and report: {ISO PASCAL} standard},
	isbn = {0387976493},
	year = {1991},
	publisher = {Springer}
},

@InProceedings{jirka_introducing_2016,
	author = { Jirka and Amblard Mar{\v{s}}{\'i}k},
	editor = {Foret, Annie
and Morrill, Glyn
and Muskens, Reinhard
and Osswald, Rainer
and Pogodalla, Sylvain},
	title = {Introducing a Calculus of Effects and Handlers for Natural Language Semantics},
	booktitle = {Formal Grammar},
	year = {2016},
	publisher = {Springer Berlin Heidelberg},
	address = {Berlin, Heidelberg},
	pages = {257--272},
	abstract = {In compositional model-theoretic semantics, researchers assemble truth-conditions or other kinds of denotations using the lambda calculus. It was previously observed [26] that the lambda terms and/or the denotations studied tend to follow the same pattern: they are instances of a monad. In this paper, we present an extension of the simply-typed lambda calculus that exploits this uniformity using the recently discovered technique of effect handlers [22]. We prove that our calculus exhibits some of the key formal properties of the lambda calculus and we use it to construct a modular semantics for a small fragment that involves multiple distinct semantic phenomena.},
	isbn = {978-3-662-53042-9}
},

@article{johann_generalization_2002,
	author = {Patricia Johann},
	title = {A Generalization of Short-cut Fusion and its Correctness Proof},
	volume = {15},
	url = {http://dx.doi.org/10.1023/A:1022982420888},
	doi = {10.1023/A:1022982420888},
	abstract = {Short-cut fusion is a program transformation technique that uses a single, local transformation—called the foldr-build rule—to remove certain intermediate lists from modularly constructed functional programs. Arguments that short-cut fusion is correct typically appeal either to intuition or to “free theorems”—even though the latter have not been known to hold for the languages supporting higher-order polymorphic functions and fixed point recursion in which short-cut fusion is usually applied. In this paper we use Pitts' recent demonstration that contextual equivalence in such languages is relationally parametric to prove that programs in them which have undergone short-cut fusion are contextually equivalent to their unfused counterparts. For each algebraic data type we then define a generalization of build which constructs substitution instances of its associated data structures, and use Pitts' techniques to prove the correctness of a contextual equivalence-preserving fusion rule which generalizes short-cut fusion. These rules optimize compositions of functions that uniformly consume algebraic data structures with functions that uniformly produce substitution instances of those data sructures.},
	number = {4},
	journal = {{Higher-Order} and Symbolic Computation},
	month = {dec},
	year = {2002},
	pages = {273--300}
},

@inproceedings{johann_free_2004,
	author = {Patricia Johann and Janis Voigtländer},
	address = {Venice, Italy},
	title = {Free theorems in the presence of seq},
	isbn = {{1-58113-729-X}},
	booktitle = {Proceedings of the 31st {ACM} {SIGPLAN-SIGACT} symposium on Principles of programming languages},
	publisher = {{ACM}},
	year = {2004},
	pages = {99--110}
},

@article{johann_impact_2006,
	author = {Patricia Johann and Janis Voigtländer},
	title = {The Impact of seq on Free Theorems-based Program Transformations},
	volume = {69},
	url = {http://portal.acm.org/citation.cfm?id=1227251},
	abstract = {Parametric polymorphism constrains the behavior of pure functional programs in a way that allows the derivation of interesting theorems about them solely from their types, i.e., virtually for free. Unfortunately, standard parametricity results - including so-called free theorems - fail for nonstrict languages supporting a polymorphic strict evaluation primitive such as Haskell's seq. A folk theorem maintains that such results hold for a subset of Haskell corresponding to a {Girard-Reynolds} calculus with fixpoints and algebraic datatypes even when seq is present provided the relations which appear in their derivations are required to be bottom-reflecting and admissible. In this paper we show that this folklore is incorrect, but that parametricity results can be recovered in the presence of seq by restricting attention to left-closed, total, and admissible relations instead. The key novelty of our approach is the asymmetry introduced by left-closedness, which leads to "inequational" versions of standard parametricity results together with preconditions guaranteeing their validity even when seq is present. We use these results to derive criteria ensuring that both equational and inequational versions of short cut fusion and related program transformations based on free theorems hold in the presence of seq},
	number = {1-2},
	journal = {Fundamenta Informaticae},
	year = {2006},
	keywords = {control primitives, correctness proofs, denotational semantics, functional programming languages, haskell, logical relations, mixing strict and nonstrict evaluation, parametricity, polymorphism, program transformations, rank-2 types, short cut fusion, theorems for free},
	pages = {63--102}
},

@inproceedings{johann_initial_2007,
	author = {Patricia Johann and Neil Ghani},
	series = {Lecture Notes in Computer Science},
	title = {Initial Algebra Semantics Is Enough!},
	volume = {4583},
	url = {http://dx.doi.org/10.1007/978-3-540-73228-0_16},
	abstract = {Initial algebra semantics is a cornerstone of the theory of modern functional programming languages. For each inductive data
type, it provides a fold combinator encapsulating structured recursion over data of that type, a Church encoding, a build combinator which constructs data of that type, and a fold/build rule which optimises modular programs by eliminating intermediate data of that type. It has long been thought that initial
algebra semantics is not expressive enough to provide a similar foundation for programming with nested types. Specifically,
the folds have been considered too weak to capture commonly occurring patterns of recursion, and no Church encodings, build combinators, or fold/build rules have been given for nested types. This paper overturns this conventional wisdom by solving all of these problems.},
	booktitle = {Typed Lambda Calculi and Applications},
	publisher = {Springer},
	year = {2007},
	pages = {207--222}
},

@inproceedings{johann_foundations_2008,
	author = {Patricia Johann and Neil Ghani},
	title = {Foundations for structured programming with {GADTs}},
	isbn = {9781595936899},
	url = {http://dx.doi.org/10.1145/1328438.1328475},
	booktitle = {{POPL} '08: Proceedings of the 35th annual {ACM} {SIGPLAN-SIGACT} symposium on Principles of programming languages},
	publisher = {{ACM}},
	year = {2008},
	keywords = {aop},
	pages = {297--308}
},

@article{johann_principled_2009,
	author = {Patricia Johann and Neil Ghani},
	title = {A principled approach to programming with nested types in Haskell},
	volume = {22},
	url = {http://dx.doi.org/10.1007/s10990-009-9047-7},
	doi = {10.1007/s10990-009-9047-7},
	abstract = {Abstract  Initial algebra semantics is one of the cornerstones of the theory of modern functional programming languages. For each inductive
data type, it provides a Church encoding for that type, a build combinator which constructs data of that type, a fold combinator which encapsulates structured recursion over data of that type, and a fold/build rule which optimises modular programs by eliminating from them data constructed using the buildcombinator, and immediately consumed using the foldcombinator, for that type. It has long been thought that initial algebra semantics is not expressive enough to provide a similar
foundation for programming with nested types in Haskell. Specifically, the standard folds derived from initial algebra semantics have been considered too weak to capture commonly occurring patterns of recursion
over data of nested types in Haskell, and no build combinators or fold/build rules have until now been defined for nested types. This paper shows that standard folds are, in fact, sufficiently expressive for programming with nested types in Haskell. It also defines buildcombinators and fold/build fusion rules for nested types. It thus shows how initial algebra semantics provides a principled, expressive, and elegant
foundation for programming with nested types in Haskell.},
	number = {2},
	journal = {{Higher-Order} and Symbolic Computation},
	month = {jun},
	year = {2009},
	pages = {155--189}
},

@article{johnsson_efficient_1998,
	author = {Thomas Johnsson},
	file = {:/home/bernardy/Papers/Efficient graph algorithms using lazy monolithic arrays-1998.pdf:pdf},
	title = {Efficient graph algorithms using lazy monolithic arrays},
	volume = {8},
	url = {http://portal.acm.org/citation.cfm?id=969592.969594},
	abstract = {Many, perhaps even most, algorithms that involve data structures are traditionally expressed by incremental updates of the data structures. In functional languages, however, incremental updates are usually both clumsy and inefficient, especially when the data structure is an {array.In} functional languages, we instead prefer to express such array algorithms using monolithic arrays – wholesale creation of the final answer – both for succinctness of expression, efficiency (only one array created) and (sometimes) implicit parallelism. The ease with which the solution can be reformulated of course depends on the problem, and varies from trivial (e.g. matrix multiplication), to challenging (e.g. solving linear equation systems using Gauss elimination, which in fact can be done by creating only two arrays, recursively defined, of which one is the answer). Other problems have been notoriously resistant to attack; these usually involve some unpredictable processing order of the elements. One such problem is graph marking, i.e. marking the nodes reachable from a set of roots. Hitherto, no functional method has been known except emulating the traditional imperative solution {(King} \& Launchbury, 1995; Launchbury \& Peyton Jones, {1995).The} contribution of this paper is to show how this problem, and some related ones, can be solved using a novel array creation primitive, lazier than previous ones.},
	number = {4},
	journal = {J. Funct. Program.},
	year = {1998},
	pages = {323--333},
	annote = {{{\textless}p{\textgreater}lazyArray} :: {(Int,} Int) -\&gt; [(int,a)] -\&gt; Array Int [a]{\textless}/p{\textgreater}}
},

@inproceedings{jones_system_1993,
	author = {Mark Jones},
	title = {A system of constructor classes: overloading and implicit higher-order polymorphism},
	isbn = {{089791595X}},
	url = {http://dx.doi.org/10.1145/165180.165190},
	booktitle = {{FPCA} '93: Proceedings of the conference on Functional programming languages and computer architecture},
	publisher = {{ACM} Press},
	year = {1993},
	keywords = {typeclass},
	pages = {52--61}
},

@book{jones_partial_1993,
	author = {Neil D. Jones and Carsten K. Gomard and Peter Sestoft},
	file = {:/home/bernardy/Papers/Partial Evaluation and Automatic Program Generation-1993.pdf:pdf},
	booktitle = {Transformation},
	publisher = {Prentice Hall},
	title = {Partial Evaluation and Automatic Program Generation},
	url = {http://www.dina.dk/~sestoft/pebook/pebook.html},
	year = {1993}
},

@article{jones_dictionary-free_1994,
	author = {Mark P. Jones},
	title = {{Dictionary-Free} Overloading by Partial Evaluation},
	volume = {8},
	url = {http://dx.doi.org/10.1007/BF01019005},
	number = {3},
	journal = {{LISP} and Symbolic Computation},
	year = {1994},
	keywords = {sibylle, typeclass, wgp08},
	pages = {229--248}
},

@incollection{jones_type_2000,
	author = {Mark P. Jones},
	file = {:/home/bernardy/Papers/Type Classes with Functional Dependencies-2000.pdf:pdf},
	title = {Type Classes with Functional Dependencies},
	url = {http://dx.doi.org/10.1007/3-540-46425-5_15},
	abstract = {Type classes in Haskell allow programmers to define functions that can be used on a set of different types, with a potentially different implementation in each case. For example, type classes are used to support equality and numeric types, and for monadic programming. A commonly requested extension to support âmultiple parametersâ allows a more general interpretation of classes as relations on types, and has many potentially useful applications. Unfortunately, many of these examples do not work well in practice, leading to ambiguities and inaccuracies in inferred types and delaying the detection of type errors. This paper illustrates the kind of problems that can occur with multiple parameter type classes, and explains how they can be resolved by allowing programmers to specify explicit dependencies between the parameters. A particular novelty of this paper is the application of ideas from the theory of relational databases to the design of type systems.},
	booktitle = {ESOP},
	year = {2000},
	keywords = {typeclass},
	pages = {230--244}
},

@inproceedings{joulin_inferring_2015,
	author = {Armand Joulin and Tomas Mikolov},
	title = {Inferring algorithmic patterns with stack-augmented recurrent nets},
	booktitle = {Advances in neural information processing systems},
	pages = {190--198},
	year = {2015}
},

@inproceedings{jourdan_validating_2012,
	author = {Jacques{-}Henri Jourdan and Fran{\c{c}}ois Pottier and Xavier Leroy},
	title = {Validating {LR(1)} Parsers},
	booktitle = {{ESOP} 2012},
	pages = {397--416},
	year = {2012},
	url = {http://dx.doi.org/10.1007/978-3-642-28869-2_20},
	doi = {10.1007/978-3-642-28869-2_20},
	timestamp = {Fri, 23 Mar 2012 15:26:14 +0100},
	biburl = {http://dblp.uni-trier.de/rec/bib/conf/esop/JourdanPL12},
	bibsource = {dblp computer science bibliography, http://dblp.org}
},

@book{jurafsky_speech_2000,
	author = {Daniel Jurafsky and James H. Martin},
	address = {USA},
	edition = {1st},
	title = {Speech and {Language} {Processing}: {An} {Introduction} to {Natural} {Language} {Processing}, {Computational} {Linguistics}, and {Speech} {Recognition}},
	isbn = {978-0-13-095069-7},
	shorttitle = {Speech and {Language} {Processing}},
	abstract = {From the Publisher: This book takes an empirical approach to language processing, based on applying statistical and other machine-learning algorithms to large corpora. Methodology boxes are included in each chapter. Each chapter is built around one or more worked examples to demonstrate the main idea of the chapter. Covers the fundamental algorithms of various fields, whether originally proposed for spoken or written language to demonstrate how the same algorithm can be used for speech recognition and word-sense disambiguation. Emphasis on web and other practical applications. Emphasis on scientific evaluation. Useful as a reference for professionals in any of the areas of speech and language processing.},
	publisher = {Prentice Hall PTR},
	year = {2000}
},

@inproceedings{jurczyk_selqa_2016,
	author = {Tomasz Jurczyk and Michael Zhai and Jinho D Choi},
	title = {Selqa: A new benchmark for selection-based question answering},
	booktitle = {Tools with Artificial Intelligence (ICTAI), 2016 IEEE 28th International Conference on},
	pages = {820--827},
	year = {2016},
	organization = {IEEE}
},

@inproceedings{jrvi_algorithm_2006,
	author = {Jaakko Järvi and Douglas Gregor and Jeremiah Willcock and Andrew Lumsdaine and Jeremy Siek},
	title = {Algorithm specialization in generic programming: challenges of constrained generics in C++},
	isbn = {1595933204},
	url = {http://dx.doi.org/10.1145/1133981.1134014},
	booktitle = {{PLDI} '06: Proceedings of the 2006 {ACM} {SIGPLAN} conference on Programming language design and implementation},
	publisher = {{ACM}},
	year = {2006},
	keywords = {c, concept, typeclass},
	pages = {272--282}
},

@inproceedings{jrvi_library_2007,
	author = {J Järvi and M Marcus and J Smith and C Consel and J Lawall},
	title = {Library composition and adaptation using {{{\textbackslash}{\textbackslash}Cpp}} concepts},
	booktitle = {Generative Programming and Component Engineering, 6th International Conference, {GPCE} 2007, Salzburg, Austria, October 1-3, 2007, Proceedings},
	year = {2007},
	keywords = {sibylle, wgp08},
	pages = {73--82}
},

@inproceedings{kalchbrenner_recurrent_2013,
	author = {Nal Kalchbrenner and Phil Blunsom},
	title = {Recurrent {{Continuous Translation Models}}},
	booktitle = {Proceedings of the 2013 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
	year = {2013},
	pages = {10},
	address = {{Seattle, Washington}},
	abstract = {We introduce a class of probabilistic continuous translation models called Recurrent Continuous Translation Models that are purely based on continuous representations for words, phrases and sentences and do not rely on alignments or phrasal translation units. The models have a generation and a conditioning aspect. The generation of the translation is modelled with a target Recurrent Language Model, whereas the conditioning on the source sentence is modelled with a Convolutional Sentence Model. Through various experiments, we show first that our models obtain a perplexity with respect to gold translations that is {$>$} 43\% lower than that of stateof-the-art alignment-based translation models. Secondly, we show that they are remarkably sensitive to the word order, syntax, and meaning of the source sentence despite lacking alignments. Finally we show that they match a state-of-the-art system when rescoring n-best lists of translations.},
	language = {en}
},

@article{kamareddine_canonical_1996,
	author = {F. Kamareddine and R. Nederpelt},
	file = {:/home/bernardy/Papers/Canonical typing and-conversion in the Barendregt Cube-1996.ps:ps},
	title = {{Canonical typing and∏-conversion in the Barendregt Cube}},
	journal = {Journal of Functional Programming},
	volume = {6},
	number = {02},
	pages = {245--267},
	issn = {0956-7968},
	year = {1996},
	publisher = {Cambridge Univ Press}
},

@InProceedings{kamp_two_1975,
	author = {H. Kamp},
	title = {Two theories about adjectives},
	booktitle = {Formal Semantics of Natural Language},
	year = {1975},
	editor = {E. Keenan},
	publisher = {Cambridge Univ Press},
	OPTisbn = {},
	OPTseries = {},
	OPTpages = {},
	OPTvolume = {}
},

@book{kamp_discourse_1993,
	author = {Hans Kamp and Uwe Reyle},
	publisher = {Dordrecht: Kluwer Academic Publishers},
	year = {1993},
	title = {From Discourse to Logic}
},

@article{karlsson_constraints_2007,
	author = {Fred Karlsson},
	title = {Constraints on multiple center-embedding of clauses},
	journal = {Journal of Linguistics},
	volume = {43},
	number = {2},
	pages = {365--392},
	year = {2007},
	publisher = {Cambridge University Press}
},

@phdthesis{karlsson_robust_2009,
	author = {Anders Karlsson},
	type = {{MSc} Thesis},
	title = {Robust and Precise Incremental Parsing of Haskell},
	school = {Chalmers University of Technology},
	year = {2009},
	see = {cites:bernardy_lazy_2009;:wagner_efficient_1998;:ghezzi_incremental_1979}
},

@inproceedings{karlsson_working_2010,
	author = {Fred Karlsson},
	title = {Working Memory Constraints on Multiple Center-Embedding},
	booktitle = {Proceedings of the Cognitive Science Society},
	volume = {32},
	number = {32},
	year = {2010}
},

@inproceedings{karpathy_visualizing_2015,
	author = {Andrej Karpathy and Justin Johnson and Li Fei-Fei},
	title = {Visualizing and understanding recurrent networks},
	booktitle = {Proceedings of ICLR 2015},
	year = {2015}
},

@article{karpathy_unreasonable_2016,
	author = {Andrej Karpathy},
	title = {The unreasonable effectiveness of recurrent neural networks},
	note = {http://karpathy.github.io/2015/05/21/rnn-effectiveness},
	year = {2016}
},

@inproceedings{karttunen_discourse_1969,
	author = {Lauri Karttunen},
	title = {Discourse Referents},
	booktitle = {Proceedings of the 1969 Conference on Computational Linguistics},
	series = {COLING '69},
	year = {1969},
	location = {Stockholm, Sweden},
	pages = {1--38},
	numpages = {38},
	doi = {10.3115/990403.990490},
	publisher = {Association for Computational Linguistics},
	address = {Stroudsburg, PA, USA}
},

@article{karttunen_definite_1971,
	author = {Lauri Karttunen},
	ISSN = {0015900X},
	journal = {Foundations of Language},
	number = {2},
	pages = {157--182},
	publisher = {Springer},
	title = {Definite Descriptions with Crossing Coreference: A Study of the Bach-Peters Paradox},
	volume = {7},
	year = {1971}
},

@techreport{kasami_efficient_1965,
	author = {T. Kasami},
	title = {AN EFFICIENT RECOGNITION AND SYNTAX ANALYSIS ALGORITHM FOR CONTEXT-FREE LANGUAGES.},
	year = {1965},
	institution = {DTIC Document}
},

@inproceedings{kawazoe_inference_2015,
	author = {Ai Kawazoe and Ribeka Tanaka and Koji Mineshima and Daisuke Bekki},
	title = {An inference problem set for evaluating semantic theories and semantic processing systems for {J}apanese},
	booktitle = {JSAI International Symposium on Artificial Intelligence},
	pages = {58--65},
	year = {2015},
	organization = {Springer}
},

@inproceedings{kay_you_2008,
	author = {Michael Kay},
	title = {You Pull, {I}'ll Push: on the Polarity of Pipelines},
	booktitle = {Proceeding of Balisage: The Markup Conference},
	url = {http://www.balisage.net/Proceedings/vol3/html/Kay01/BalisageVol3-Kay01.html},
	year = {2008}
},

@Book{keenan_boolean_1985,
	author = {Edward Keenan and L.M. Falz},
	title = {Boolean Semantics for Natural Language},
	publisher = {Springer},
	address = {Berlin, New York},
	year = {1985}
},

@inproceedings{keller_regular_2010,
	author = {Ben Lippmeier Gabriele Keller and Manuel M. T. Chakravarty and Roman Leshchinskiy and Simon L {Peyton Jones}},
	title = {Regular, shape-polymorphic, parallel arrays in Haskell},
	booktitle = {ICFP},
	year = {2010},
	pages = {261-272},
	ee = {http://doi.acm.org/10.1145/1863543.1863582},
	bibsource = {DBLP, http://dblp.uni-trier.de}
},

@inproceedings{keller_parametricity_2012,
	author = {Chantal Keller and Marc Lasson},
	title = {Parametricity in an Impredicative Sort},
	booktitle = {CSL},
	year = {2012},
	pages = {381-395},
	ee = {http://dx.doi.org/10.4230/LIPIcs.CSL.2012.381},
	bibsource = {DBLP, http://dblp.uni-trier.de}
},

@conference{kennedy_relational_1997,
	author = {Andrew J Kennedy},
	file = {:/home/bernardy/Papers/Relational parametricity and units of measure-1997.pdf:pdf},
	title = {{Relational parametricity and units of measure}},
	booktitle = {Proceedings of the 24th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
	pages = {442--455},
	year = {1997},
	organization = {ACM}
},

@article{kennedy_vagueness_2007,
	author = {Christopher Kennedy},
	title = {Vagueness and grammar: The semantics of relative and absolute gradable adjectives},
	journal = {Linguistics and philosophy},
	volume = {30},
	number = {1},
	pages = {1--45},
	year = {2007},
	publisher = {Springer}
},

@misc{khanna_formal_2006,
	author = {Sanjeev Khanna and Keshav Kunal and Benjamin Pierce},
	file = {:/home/bernardy/Papers/A Formal Investigation of Diff3-2006.pdf:pdf},
	title = {A Formal Investigation of Diff3},
	url = {http://www.cis.upenn.edu/~bcpierce/papers/diff3-short.pdf},
	year = {2006},
	keywords = {bibtex-import, diff3, vc, vc-project},
	howpublished = {\url{http://www.cis.upenn.edu/~bcpierce/papers/diff3-short.pdf}},
	annote = {{{\textless}p{\textgreater}(private-note)Manuscript{\textless}/p{\textgreater}}}
},

@inproceedings{kim_program_2006,
	author = {Miryung Kim and David Notkin},
	title = {Program element matching for multi-version program analyses},
	isbn = {1595933972},
	url = {http://dx.doi.org/10.1145/1137983.1137999},
	booktitle = {{MSR} '06: Proceedings of the 2006 international workshop on Mining software repositories},
	publisher = {{ACM} Press},
	year = {2006},
	keywords = {evolution, vc},
	pages = {58--64}
},

@article{kim_semantic_2018,
	author = {Seonhoon Kim and Jin-Hyuk Hong and Inho Kang and Nojun Kwak},
	title = {Semantic Sentence Matching with Densely-connected Recurrent and Co-attentive Information},
	journal = {arXiv preprint arXiv:1805.11360},
	year = {2018}
},

@article{kingma_adam_2014,
	author = {Diederik P. Kingma and Jimmy Ba},
	title = {Adam: {A} Method for Stochastic Optimization},
	journal = {CoRR},
	volume = {abs/1412.6980},
	year = {2014},
	url = {http://arxiv.org/abs/1412.6980},
	timestamp = {Thu, 01 Jan 2015 19:51:08 +0100},
	biburl = {http://dblp.uni-trier.de/rec/bib/journals/corr/KingmaB14},
	bibsource = {dblp computer science bibliography, http://dblp.org}
},

@inproceedings{kiselyov_strongly_2004,
	author = {Oleg Kiselyov and Ralf Lämmel and Keean Schupke},
	title = {Strongly typed heterogeneous collections},
	url = {http://dx.doi.org/http://doi.acm.org/10.1145/1017472.1017488},
	booktitle = {Haskell '04: Proceedings of the {ACM} {SIGPLAN} workshop on Haskell},
	publisher = {{ACM} Press},
	year = {2004},
	keywords = {hlist},
	pages = {96--107}
},

@misc{kiselyov_polymorphic_2006,
	author = {Oleg Kiselyov},
	title = {Polymorphic variants: solving the expression problem},
	url = {http://okmij.org/ftp/Haskell/generics.html#PolyVariant},
	month = {jul},
	year = {2006},
	keywords = {open},
	howpublished = {\url{http://okmij.org/ftp/Haskell/generics.html#PolyVariant}}
},

@inproceedings{kiselyov_lightweight_2007,
	author = {Oleg Kiselyov and {Chung-Chieh} Shan},
	title = {Lightweight static resources, for safe embedded and systems programming},
	url = {http://okmij.org/ftp/Haskell/types.html#ls-resources},
	abstract = {It is an established trend to develop low-level code -- embedded software, device drivers, and operating systems -- using high-level languages, especially functional languages with advanced facilities to abstract and generate code. To be reliable and secure, low-level code must correctly manage space, time, and other resources, so special type systems and verification tools arose to regulate resource access statically. However, a general-purpose functional language practical today can provide the same static assurances, also without run-time overhead. We substantiate this claim and promote the trend with two security kernels in the domain of device drivers: * one built around raw pointers, to track and arbitrate the size, alignment, write permission, and other properties of memory areas across indexing and casting; * the other built around a device register, to enforce protocol and timing requirements while reading from the register. Our style is convenient in Haskell thanks to custom kinds and predicates (as type classes); type-level numbers, functions, and records (using functional dependencies); and mixed type- and term-level programming (enabling partial type signatures).},
	booktitle = {Draft Proceedings of Trends in Functional Programming},
	publisher = {Seton Hall University},
	year = {2007},
	keywords = {programming, typelevel}
},

@inproceedings{kiselyov_iteratees_2012,
	author = {Oleg Kiselyov},
	title = {Iteratees},
	booktitle = {Functional and Logic Programming - 11th International Symposium, {FLOPS}
               2012, Kobe, Japan, May 23-25, 2012. Proceedings},
	pages = {166--181},
	year = {2012},
	url = {http://dx.doi.org/10.1007/978-3-642-29822-6_15},
	doi = {10.1007/978-3-642-29822-6_15},
	timestamp = {Mon, 21 May 2012 11:24:38 +0200},
	biburl = {http://dblp.uni-trier.de/rec/bib/conf/flops/Kiselyov12},
	bibsource = {dblp computer science bibliography, http://dblp.org}
},

@inproceedings{kiselyov_lazy_2012,
	author = {Oleg Kiselyov and Simon {Peyton Jones} and Amr Sabry},
	title = {Lazy v. Yield: Incremental, Linear Pretty-Printing},
	booktitle = {Programming Languages and Systems - 10th Asian Symposium, {APLAS}
               2012, Kyoto, Japan, December 11-13, 2012. Proceedings},
	pages = {190--206},
	year = {2012},
	url = {http://dx.doi.org/10.1007/978-3-642-35182-2_14},
	doi = {10.1007/978-3-642-35182-2_14},
	timestamp = {Mon, 04 Feb 2013 12:47:37 +0100},
	biburl = {http://dblp.uni-trier.de/rec/bib/conf/aplas/KiselyovJS12},
	bibsource = {dblp computer science bibliography, http://dblp.org}
},

@misc{kiselyov_lazy_2013,
	author = {Oleg Kiselyov},
	title = {Lazy IO breaks equational reasoning},
	year = {2013},
	note = {\HREF{Manuscript available on the author's web page}{http://okmij.org/ftp/Haskell/index.html}}
},

@inproceedings{kiselyov_freer_2015,
	author = {Oleg Kiselyov and Hiromi Ishii},
	title = {Freer monads, more extensible effects},
	booktitle = {Proceedings of the 8th {ACM} {SIGPLAN} Symposium on Haskell, Haskell
               2015, Vancouver, BC, Canada, September 3-4, 2015},
	pages = {94--105},
	year = {2015},
	url = {https://doi.org/10.1145/2804302.2804319},
	doi = {10.1145/2804302.2804319},
	timestamp = {Tue, 06 Nov 2018 16:58:22 +0100},
	biburl = {https://dblp.org/rec/bib/conf/haskell/KiselyovI15},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@misc{kiselyov_httpokmij.orgftphaskelltypes.htmlclass-based-dispatch_????,
	author = {Oleg Kiselyov},
	title = {{http://okmij.org/ftp/Haskell/types.html\#class-based-dispatch}},
	url = {http://okmij.org/ftp/Haskell/types.html#class-based-dispatch},
	abstract = {This message gives an example of a dynamic type class cast in Haskell. We want to dispatch on a class of a type rather on a type itself. In other words, we would like to simulate {IsInstanceOf.}},
	keywords = {typeclass},
	howpublished = {\url{http://okmij.org/ftp/Haskell/types.html#class-based-dispatch}}
},

@article{kleene_interpretation_1945,
	author = {Stephen Cole Kleene},
	title = {On the interpretation of intuitionistic number theory},
	journal = {Journal of Symbolic Logic},
	volume = {10},
	number = {4},
	pages = {109--124},
	year = {1945},
	publisher = {Association for Symbolic Logic}
},

@book{kleene_introduction_1971,
	author = {Stephen Cole Kleene},
	title = {{Introduction to metamathematics}},
	year = {1971},
	publisher = {Wolters-Noordhoff}
},

@article{klein_semantics_1980,
	author = {Ewan Klein},
	year = {1980},
	pages = {1--45},
	journal = {Linguistics and Philosophy},
	title = {A Semantics for Positive and Comparative Adjectives},
	number = {1},
	volume = {4},
	publisher = {Springer}
},

@misc{kmett_machines_2015,
	author = {Edward A. Kmett and Rúnar Bjarnason and Josh Cough},
	title = {The machines package},
	url = {https://github.com/ekmett/machines/},
	year = {2015}
},

@book{knuth_art_1997,
	author = {Donald E. Knuth},
	title = {The Art of Computer Programming, Volume 1: Fundamental Algorithms},
	isbn = {0201896834},
	shorttitle = {Art of Computer Programming, Volume 1},
	publisher = {{Addison-Wesley} Professional},
	year = {1997}
},

@misc{knuth_mathematical_1997,
	author = {Donald E. Knuth and Tracy Larrabee and Paul M. Roberts},
	file = {:/home/bernardy/Papers/Mathematical writing-1997.pdf:pdf},
	doi = {10.1017/S026988899722309X},
	issn = {02698889},
	month = {sep},
	number = {3},
	pages = {331--334},
	title = {{Mathematical writing}},
	url = {http://www.journals.cambridge.org/abstract\_S026988899722309X},
	volume = {12},
	year = {1997}
},

@book{knuth_art_1998,
	author = {Donald E. Knuth},
	edition = {2},
	title = {The Art of Computer Programming, Volume 3: Sorting and Searching (2nd Edition)},
	isbn = {0201896850},
	shorttitle = {Art of Computer Programming, Volume 3},
	publisher = {{Addison-Wesley} Professional},
	month = {5},
	year = {1998}
},

@misc{ko_modularising_2013,
	author = {Hsiang-Shang Ko and Jeremy Gibbons},
	title = {Modularising inductive families},
	year = {2013},
	month = {March},
	note = {To appear in Progress in Informatics.},
	url = {http://www.cs.ox.ac.uk/people/hsiang-shang.ko/pcOrn/pcOrn.pdf}
},

@article{kobele_cooper_2018,
	author = {Gregory M. Kobele},
	title = {The Cooper Storage Idiom},
	journal = {J. Log. Lang. Inf.},
	volume = {27},
	number = {2},
	pages = {95--131},
	year = {2018},
	url = {https://doi.org/10.1007/s10849-017-9263-1},
	doi = {10.1007/s10849-017-9263-1},
	timestamp = {Thu, 17 Sep 2020 12:00:23 +0200},
	biburl = {https://dblp.org/rec/journals/jolli/Kobele18.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@inproceedings{kreisel_interpretation_1959,
	author = {Georg Kreisel},
	title = {Interpretation of analysis by means of constructive functionals of finite types},
	booktitle = {Constructivity in mathematics},
	editor = {A. Heyting},
	pages = {101--128},
	year = {1959},
	address = {North-Holland, Amsterdam}
},

@article{krioukov_hyperbolic_2010,
	author = {Dmitri V. Krioukov and Fragkiskos Papadopoulos and Maksim Kitsak and Amin Vahdat and Mari{\'a}n Bogu{\~n}{\'a}},
	title = {Hyperbolic Geometry of Complex Networks},
	journal = {Physical review. E, Statistical, nonlinear, and soft matter physics},
	year = {2010},
	volume = {82 3 Pt 2},
	pages = {036106}
},

@book{krishnamurthi_programming_2007,
	author = {Shriram Krishnamurthi},
	title = {Programming languages: Application and interpretation},
	year = {2007},
	publisher = {Brown Univ.}
},

@article{krishnamurthi_teaching_2008,
	author = {Shriram Krishnamurthi},
	title = {Teaching programming languages in a post-linnaean age},
	journal = {ACM Sigplan Notices},
	volume = {43},
	number = {11},
	pages = {81},
	year = {2008}
},

@inproceedings{krishnaswami_semantic_2011,
	author = {Neelakantan R. Krishnaswami and Nick Benton},
	title = {A Semantic Model for Graphical User Interfaces},
	booktitle = {Proceedings of the 16th ACM SIGPLAN International Conference on Functional Programming},
	series = {ICFP '11},
	year = {2011},
	isbn = {978-1-4503-0865-6},
	location = {Tokyo, Japan},
	pages = {45--57},
	numpages = {13},
	url = {http://doi.acm.org/10.1145/2034773.2034782},
	doi = {10.1145/2034773.2034782},
	acmid = {2034782},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {denotational semantics, functional reactive programming, guarded recursion, linear logic, ultrametric spaces}
},

@inproceedings{krishnaswami_internalizing_2013,
	author = {Neelakantan R. Krishnaswami and Derek Dreyer},
	title = {Internalizing Relational Parametricity in the Extensional Calculus of Constructions},
	booktitle = {Computer Science Logic 2013 {(CSL} 2013), {CSL} 2013, September 2-5,
               2013, Torino, Italy},
	pages = {432--451},
	year = {2013},
	crossref = {DBLP:conf/csl/2013},
	url = {http://dx.doi.org/10.4230/LIPIcs.CSL.2013.432},
	doi = {10.4230/LIPIcs.CSL.2013.432},
	timestamp = {Wed, 04 Sep 2013 20:26:36 +0200},
	biburl = {http://dblp.uni-trier.de/rec/bib/conf/csl/KrishnaswamiD13},
	bibsource = {dblp computer science bibliography, http://dblp.org}
},

@article{krivine_programming_1990,
	author = {Jean-Louis Krivine and Michel Parigot},
	title = {Programming with proofs},
	journal = {Journal of Information Processing and Cybernetics},
	volume = {26},
	number = {3},
	year = {1990},
	issn = {0863-0593},
	pages = {149--167},
	publisher = {Akademie-Verlag GmbH},
	address = {Berlin, Germany, Germany}
},

@book{krivine_lambda-calcul_1997,
	author = {Jean-Louis Krivine},
	file = {:/home/bernardy/Papers/Lambda-calcul types et modèles-1990.pdf:pdf},
	title = {Lambda-calcul -- types et modèles},
	isbn = {2225820910},
	publisher = {Dunod},
	year = {1997}
},

@article{krivine_call-by-name_2007,
	author = {Jean-Louis Krivine},
	file = {:/home/bernardy/Papers/A call-by-name lambda-calculus machine-2007.:},
	title = {A call-by-name lambda-calculus machine},
	journal = {Higher-Order and Symbolic Computation},
	volume = {20},
	number = {3},
	pages = {199--207},
	year = {2007},
	publisher = {Springer}
},

@inproceedings{kumar_ask_2016,
	author = {Ankit Kumar and Ozan Irsoy and Peter Ondruska and Mohit Iyyer and James Bradbury and Ishaan Gulrajani and Victor Zhong and Romain Paulus and Richard Socher},
	title = {Ask me anything: Dynamic memory networks for natural language processing},
	booktitle = {International Conference on Machine Learning},
	pages = {1378--1387},
	year = {2016}
},

@inproceedings{kumar_community_2018,
	author = {Srijan Kumar and William L. Hamilton and Jure Leskovec and Dan Jurafsky},
	title = {Community {{Interaction}} and {{Conflict}} on the {{Web}}},
	booktitle = {Proceedings of the 2018 {{World Wide Web Conference}} on {{World Wide Web}} - {{WWW}} '18},
	year = {2018},
	pages = {933--943},
	publisher = {{ACM Press}},
	address = {{Lyon, France}},
	doi = {10.1145/3178876.3186141},
	abstract = {Users organize themselves into communities on web platform60 s. These communities can interact with one another, often leading to conflicts and toxic interactions. However, little is known about the mechanisms of interactions between communities and how th40ey impact users.},
	isbn = {978-1-4503-5639-8},
	language = {en}
},

@article{kuper_freeze_????,
	author = {Lindsey Kuper and Aaron Turon and R Neelakantan and Ryan R Newton},
	title = {Freeze After Writing}
},

@article{lafont_linear_1988,
	author = {Yves Lafont},
	file = {:/home/bernardy/Papers/The linear abstract machine-1988.pdf:pdf},
	title = {The linear abstract machine},
	journal = {Theoretical Computer Science},
	volume = {59},
	number = {1},
	pages = {157--180},
	year = {1988},
	publisher = {Elsevier}
},

@techreport{lafont_continuation_1993,
	author = {Yves Lafont and Bernhard Reus and Thomas Streicher},
	title = {Continuation semantics or expressing implication by negation},
	year = {1993},
	publisher = {Univ. M{\"u}nchen, Inst. f{\"u}r Informatik}
},

@inproceedings{lafourcade_jeuxdemots_2008,
	author = {Mathieu Lafourcade and Alain Joubert},
	title = {Jeuxdemots: un prototype ludique pour l'{\'e}mergence de relations entre termes},
	booktitle = {JADT'08: Journ{\'e}es internationales d'Analyse statistiques des Donn{\'e}es Textuelles},
	ADDRESS = {France},
	pages = {657--666},
	year = {2008}
},

@book{lafourcade_games_2015,
	author = {Mathieu Lafourcade and Alain Joubert and Nathalie Le Brun},
	title = {Games with a Purpose (GWAPS)},
	year = {2015},
	publisher = {John Wiley \& Sons}
},

@InProceedings{lafourcade_jeuxdemots_2018,
	author = {Mathieu Lafourcade and Alain Joubert and Nathalie Le Brun},
	title = {The JeuxDeMots Project is 10 Years Old: what Assessments?},
	booktitle = {Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)},
	year = {2018},
	month = {may},
	date = {7-12},
	location = {Miyazaki, Japan},
	editor = {Jon Chamberlain and Udo Kruschwitz and Karën Fort and Christopher Cieri},
	publisher = {European Language Resources Association (ELRA)},
	address = {Paris, France},
	isbn = {979-10-95546-10-8},
	language = {english}
},

@inproceedings{lai_illinois-lh_2014,
	author = {Alice Lai and Julia Hockenmaier},
	title = {Illinois-LH: {A} Denotational and Distributional Approach to Semantics},
	booktitle = {Proceedings of the 8th International Workshop on Semantic Evaluation,
               SemEval@COLING 2014, Dublin, Ireland, August 23-24, 2014.},
	pages = {329--334},
	year = {2014}
},

@article{lake_still_2017,
	author = {Brenden M Lake and Marco Baroni},
	title = {Still not systematic after all these years: On the compositional skills of sequence-to-sequence recurrent networks},
	journal = {arXiv preprint arXiv:1711.00350},
	year = {2017}
},

@article{lakretz_can_2021,
	author = {Yair Lakretz and Th{\'e}o Desbordes and Jean-R{\'e}mi King and Beno{\^\i}t Crabb{\'e} and Maxime Oquab and Stanislas Dehaene},
	title = {Can RNNs learn Recursive Nested Subject-Verb Agreements?},
	journal = {arXiv preprint arXiv:2101.02258},
	year = {2021}
},

@article{landin_mechanical_1964,
	author = {Peter J Landin},
	title = {The mechanical evaluation of expressions},
	journal = {The Computer Journal},
	volume = {6},
	number = {4},
	pages = {308--320},
	year = {1964},
	publisher = {Br Computer Soc}
},

@article{landin_next_1966,
	author = {Peter J Landin},
	file = {:/home/bernardy/Papers/The next 700 programming languages-1966.pdf:pdf},
	title = {The next 700 programming languages},
	journal = {Communications of the ACM},
	volume = {9},
	number = {3},
	pages = {157--166},
	year = {1966},
	publisher = {ACM}
},

@article{lange_cnf_2009,
	author = {M. Lange and H. Lei{\ss}},
	file = {:/home/bernardy/Papers/To CNF or not to CNF? an efficient yet presentable version of the CYK algorithm-2009.pdf:pdf},
	title = {To {CNF} or not to {CNF}? an efficient yet presentable version of the {CYK} algorithm},
	journal = {Informatica Didactica (8)(2008--2010)},
	year = {2009}
},

@article{lappin_algorithm_1994,
	author = {Shalom Lappin and Herbert J. Leass},
	title = {An {Algorithm} for {Pronominal} {Anaphora} {Resolution}},
	volume = {20},
	url = {https://www.aclweb.org/anthology/J94-4002},
	number = {4},
	urldate = {2021-02-21},
	journal = {Computational Linguistics},
	year = {1994},
	pages = {535--561}
},

@InCollection{lappin_curry_2015,
	author = {Shalom Lappin},
	editor = {Shalom Lappin and Chris Fox},
	booktitle = {The Handbook of Contemporary Semantic Theory, Second Edition},
	title = {Curry Typing, Polymorphism, and Fine-Grained Intensionality},
	publisher = {Wiley-Blackwell},
	address = {Malden, MA and Oxford},
	pages = {408--428},
	year = {2015}
},

@InProceedings{lappin_computationally_2018,
	author = {Shalom Lappin},
	title = {Towards a Computationally Viable Framework for Semantic Representation},
	booktitle = {Proceedings of the Symposium on Logic and Algorithms in Computational Linguistics 2018},
	publisher = {Stockholm University, DiVA Portal for digital publications},
	pages = {47-63},
	year = {2018}
},

@inproceedings{larsson_semantic-linear_2021,
	author = {Staffan Larsson and Jean-Philippe Bernardy},
	title = {Semantic Classification and Learning Using a Linear Tranformation Model in a Probabilistic Type Theory with Records},
	booktitle = {Proceedings of the Reasoning and Interaction Conference (ReInAct 2021)},
	month = {oct},
	year = {2021},
	address = {Gothenburg, Sweden},
	publisher = {Association for Computational Linguistics},
	url = {https://aclanthology.org/2021.reinact-1.3},
	pages = {14--22},
	abstract = {Starting from an existing account of semantic classification and learning from interaction formulated in a Probabilistic Type Theory with Records, encompassing Bayesian inference and learning with a frequentist flavour, we observe some problems with this account and provide an alternative account of classification learning that addresses the observed problems. The proposed account is also broadly Bayesian in nature but instead uses a linear transformation model for classification and learning.},
	forcedkey = {larsson_semantic-linear_2021}
},

@inproceedings{larsson_semantic_2021,
	author = {Staffan Larsson and Jean-Philippe Bernardy and Robin Cooper},
	title = {Semantic Learning in a Probabilistic Type Theory with Records},
	booktitle = {Proceedings of Computing Semantics with Types, Frames and Related Structures},
	year = {2021}
},

@article{lassiter_presuppositions_2012,
	author = {Daniel Lassiter},
	title = {Presuppositions, provisos, and probability},
	volume = {5},
	doi = {10.3765/sp.5.2},
	number = {2},
	journal = {Semantics and Pragmatics},
	month = {may},
	year = {2012},
	keywords = {Bayesian pragmatics, conditionals, Presupposition, probability, proviso problem},
	pages = {1--37}
},

@article{lassiter_context_2013,
	author = {Daniel Lassiter and Noah D. Goodman},
	title = {Context, scale structure, and statistics in the interpretation of positive-form adjectives},
	volume = {23},
	copyright = {Copyright (c)},
	issn = {2163-5951},
	url = {https://journals.linguisticsociety.org/proceedings/index.php/SALT/article/view/2658},
	doi = {10.3765/salt.v23i0.2658},
	abstract = {Relative adjectives in the positive form exhibit vagueness and context-sensitivity. We suggest that these phenomena can be explained by the interaction of a free threshold variable in the meaning of the positive form with a probabilistic model of pragmatic inference. We describe a formal model of utterance interpretation as coordination, which jointly infers the value of the threshold variable and the intended meaning of the sentence. We report simulations exploring the effect of background statistical knowledge on adjective interpretation in this model. Motivated by these simulation results, we suggest that this approach can account for the correlation between scale structure and the relative/absolute distinction while also allowing for exceptions noted in previous work. Finally, we argue for a probabilistic explanation of why the sorites paradox is compelling with relative adjectives even though the second premise is false on a universal interpretation, and show that this account predicts Kennedyâ€™s (2007) observation that the sorites paradox is more compelling with relative than with absolute adjectives.},
	language = {en-US},
	number = {0},
	urldate = {2021-02-11},
	journal = {Semantics and Linguistic Theory},
	month = {aug},
	year = {2013},
	note = {Number: 0},
	keywords = {Bayesian pragmatics, probability, absolute adjectives, coordination games, Relative adjectives, sorites, vagueness},
	pages = {587--610}
},

@incollection{lassiter_adjectival_2015,
	author = {D. Lassiter},
	Address = {Malden, Oxford},
	Booktitle = {The Handbook of Contemporary Semantic Theory, Second Edition},
	Editor = {S. Lappin and C. Fox},
	Publisher = {Wiley-Blackwell},
	Title = {Adjectival modification and gradation},
	Pages = {655--686},
	Year = {2015}
},

@article{lassiter_adjectival_2017,
	author = {Daniel Lassiter and Noah D. Goodman},
	title = {Adjectival vagueness in a {Bayesian} model of interpretation},
	volume = {194},
	issn = {1573-0964},
	url = {https://doi.org/10.1007/s11229-015-0786-1},
	doi = {10.1007/s11229-015-0786-1},
	abstract = {We derive a probabilistic account of the vagueness and context-sensitivity of scalar adjectives from a Bayesian approach to communication and interpretation. We describe an iterated-reasoning architecture for pragmatic interpretation and illustrate it with a simple scalar implicature example. We then show how to enrich the apparatus to handle pragmatic reasoning about the values of free variables, explore its predictions about the interpretation of scalar adjectives, and show how this model implements Edgington’s (Analysis 2:193–204,1992, Keefe and Smith (eds.) Vagueness: a reader,  1997) account of the sorites paradox, with variations. The Bayesian approach has a number of explanatory virtues: in particular, it does not require any special-purpose machinery for handling vagueness, and it is integrated with a promising new approach to pragmatics and other areas of cognitive science.},
	language = {en},
	number = {10},
	urldate = {2021-02-11},
	journal = {Synthese},
	month = {oct},
	year = {2017},
	pages = {3801--3836}
},

@phdthesis{lattner_llvm_2002,
	author = {Chris Lattner},
	title = {{{LLVM:} An Infrastructure for {Multi-Stage} Optimization}},
	url = {http://llvm.org/pubs/2002-12-LattnerMSThesis.pdf},
	year = {2002},
	keywords = {bibtex-import, llvm},
	annote = {{\textless}p{\textgreater}(private-note){{\textbackslash}em See {{\textbackslash}tt http://llvm.cs.uiuc.edu}.}{\textless}/p{\textgreater}}
},

@article{lau_grammaticality_2017,
	author = {Jey Han Lau and Alexander Clark and Shalom Lappin},
	title = {Grammaticality, Acceptability, and Probability: {A} Probabilistic View of Linguistic Knowledge},
	year = {2017},
	volume = {41},
	pages = {1202--1241},
	issn = {1551-6709},
	doi = {10.1111/cogs.12414},
	abstract = {The question of whether humans represent grammatical knowledge as a binary condition on membership in a set of well-formed sentences, or as a probabilistic property has been the subject of debate among linguists, psychologists, and cognitive scientists for many decades. Acceptability judgments present a serious problem for both classical binary and probabilistic theories of grammaticality. These judgements are gradient in nature, and so cannot be directly accommodated in a binary formal grammar. However, it is also not possible to simply reduce acceptability to probability. The acceptability of a sentence is not the same as the likelihood of its occurrence, which is, in part, determined by factors like sentence length and lexical frequency. In this paper, we present the results of a set of large-scale experiments using crowd-sourced acceptability judgments that demonstrate gradience to be a pervasive feature in acceptability judgments. We then show how one can predict acceptability judgments on the basis of probability by augmenting probabilistic language models with an acceptability measure. This is a function that normalizes probability values to eliminate the confounding factors of length and lexical frequency. We describe a sequence of modeling experiments with unsupervised language models drawn from state-of-the-art machine learning methods in natural language processing. Several of these models achieve very encouraging levels of accuracy in the acceptability prediction task, as measured by the correlation between the acceptability measure scores and mean human acceptability values. We consider the relevance of these results to the debate on the nature of grammatical competence, and we argue that they support the view that linguistic knowledge can be intrinsically probabilistic.},
	annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.12414},
	copyright = {Copyright \textcopyright{} 2016 Cognitive Science Society, Inc.},
	journal = {Cognitive Science},
	keywords = {Grammaticality,Probabilistic modeling,Syntactic knowledge},
	language = {en},
	number = {5}
},

@inproceedings{lau_topically_2017,
	author = {Jey Han Lau and Timothy Baldwin and Trevor Cohn},
	title = {Topically Driven Neural Language Model},
	booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	year = {2017},
	month = {jul},
	pages = {355--365},
	publisher = {{Association for Computational Linguistics}},
	address = {{Vancouver, Canada}},
	doi = {10.18653/v1/P17-1033},
	abstract = {Language models are typically applied at the sentence level, without access to the broader document context. We present a neural language model that incorporates document context in the form of a topic model-like architecture, thus providing a succinct representation of the broader document context outside of the current sentence. Experiments over a range of datasets demonstrate that our model outperforms a pure sentence-based model in terms of language model perplexity, and leads to topics that are potentially more coherent than those produced by a standard LDA topic model. Our model also has the ability to generate related sentences for a topic, providing another way to interpret topics.}
},

@inproceedings{launchbury_natural_1993,
	author = {John Launchbury},
	title = {A Natural Semantics for Lazy Evaluation},
	booktitle = {POPL},
	year = {1993},
	pages = {144-154}
},

@inproceedings{launchbury_lazy_1994,
	author = {John Launchbury and Simon {Peyton Jones}},
	editor = {Vivek Sarkar and
               Barbara G. Ryder and
               Mary Lou Soffa},
	title = {Lazy Functional State Threads},
	booktitle = {Proceedings of the {ACM} SIGPLAN'94 Conference on Programming Language
               Design and Implementation (PLDI), Orlando, Florida, USA, June 20-24,
               1994},
	pages = {24--35},
	publisher = {{ACM}},
	year = {1994},
	url = {https://doi.org/10.1145/178243.178246},
	doi = {10.1145/178243.178246},
	timestamp = {Tue, 06 Nov 2018 16:59:30 +0100},
	biburl = {https://dblp.org/rec/conf/pldi/LaunchburyJ94.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@PhDThesis{laurent_etude_2002,
	author = {Olivier Laurent},
	file = {:/home/bernardy/Papers/Etude de la polarisation en logique-2002.pdf:pdf},
	title = {Etude de la polarisation en logique},
	school = {{U}niversit\'e {A}ix-{M}arseille~{II}},
	type = {Th\`ese de Doctorat},
	month = {March},
	year = {2002}
},

@misc{laurent_proof_2004,
	author = {Olivier Laurent},
	title = {A proof of the focalization property of Linear Logic},
	year = {2004},
	howpublished = {Note available on the author's web page.}
},

@phdthesis{lebedeva_expressing_2012,
	author = {Ekaterina Lebedeva},
	title = {{Expressing discourse dynamics through continuations}},
	url = {https://tel.archives-ouvertes.fr/tel-01749193},
	number = {2012LORR0025},
	school = {{Universit{\'e} de Lorraine}},
	year = {2012}
},

@article{lee_fast_2002,
	author = {Lillian Lee},
	title = {Fast context-free grammar parsing requires fast boolean matrix multiplication},
	journal = {Journal of the ACM (JACM)},
	volume = {49},
	number = {1},
	pages = {1--15},
	year = {2002},
	publisher = {ACM}
},

@misc{lehman_biblatex_2010,
	author = {Philipp Lehman},
	file = {:/home/bernardy/Papers/The biblatex package-2010.pdf:pdf},
	pages = {1--200},
	title = {{The biblatex package}},
	year = {2010}
},

@conference{leivant_contracting_1990,
	author = {Daniel Leivant},
	title = {{Contracting proofs to programs}},
	booktitle = {Logic and Computer Science},
	pages = {279--327},
	year = {1990}
},

@inproceedings{leivant_foundational_1991,
	author = {Daniel Leivant},
	title = {A foundational delineation of computational feasibility},
	booktitle = {Logic in Computer Science, 1991. LICS'91., Proceedings of Sixth Annual IEEE Symposium on},
	pages = {2--11},
	year = {1991},
	organization = {IEEE}
},

@inproceedings{lerner_composing_2002,
	author = {Sorin Lerner and David Grove and Craig Chambers},
	title = {Composing dataflow analyses and transformations},
	volume = {37},
	isbn = {1581134509},
	url = {http://dx.doi.org/10.1145/503272.503298},
	booktitle = {{POPL} '02: Proceedings of the 29th {ACM} {SIGPLAN-SIGACT} symposium on Principles of programming languages},
	publisher = {{ACM} Press},
	month = {jan},
	year = {2002},
	keywords = {cool},
	pages = {270--282}
},

@article{leroy_formal_2009,
	author = {Xavier Leroy},
	title = {Formal verification of a realistic compiler},
	journal = {Communications of the ACM},
	year = {2009},
	volume = {52},
	number = {7},
	pages = {107--115},
	xtopic = {compcert},
	urllocal = {http://gallium.inria.fr/~xleroy/publi/compcert-CACM.pdf},
	urlpublisher = {http://doi.acm.org/10.1145/1538788.1538814},
	abstract = {This paper reports on the development and formal verification (proof
of semantic preservation) of CompCert, a compiler from Clight (a
large subset of the C programming language) to PowerPC assembly code,
using the Coq proof assistant both for programming the compiler and
for proving its correctness.  Such a verified compiler is useful in
the context of critical software and its formal verification: the
verification of the compiler guarantees that the safety properties
proved on the source code hold for the executable compiled code as
well.}
},

@Misc{leroy_compcert_2013,
	author = {X. Leroy},
	OPTcrossref = {},
	title = {The CompCert C verified compiler: Documentation and User?s Manual},
	howpublished = {http://compcert.inria.fr/man/manual.pdf},
	year = {2013},
	OPTmonth = {},
	OPTnote = {},
	OPTannote = {}
},

@inproceedings{liang_monad_1995,
	author = {Sheng Liang and Paul Hudak and Mark Jones},
	title = {Monad Transformers and Modular Interpreters},
	year = {1995},
	isbn = {0897916921},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/199448.199528},
	doi = {10.1145/199448.199528},
	booktitle = {Proceedings of the 22nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
	pages = {333–343},
	numpages = {11},
	location = {San Francisco, California, USA},
	series = {POPL 1995}
},

@inproceedings{licata_canonicity_2012,
	author = {Daniel Licata and Robert Harper},
	title = {Canonicity for 2-Dimensional Type Theory},
	booktitle = {Proceedings of the 39th annual {ACM} {SIGPLAN-SIGACT} symposium on Principles of programming languages},
	publisher = {{ACM}},
	year = {2012}
},

@inproceedings{lindley_algebraic_2014,
	author = {Sam Lindley},
	title = {Algebraic effects and effect handlers for idioms and arrows},
	booktitle = {Proceedings of the 10th ACM SIGPLAN workshop on Generic programming},
	pages = {47--58},
	year = {2014}
},

@article{linzen_assessing_2016,
	author = {Tal Linzen and Emmanuel Dupoux and Yoav Golberg},
	title = {Assessing the Ability of {LSTM}s to Learn Syntax-Sensitive Dependencies},
	journal = {Transactions of the Association of Computational Linguistics},
	volume = {4},
	year = {2016},
	pages = {521--535}
},

@inproceedings{lippe_operation-based_1992,
	author = {Ernst Lippe and Norbert van Oosterom},
	title = {Operation-based merging},
	isbn = {0163-5948},
	url = {http://dx.doi.org/10.1145/142868.143753},
	booktitle = {{SDE} 5: Proceedings of the fifth {ACM} {SIGSOFT} symposium on Software development environments},
	publisher = {{ACM} Press},
	year = {1992},
	keywords = {change-based, good, vc, vc-project},
	pages = {78--87},
	annote = {{\textless}p{\textgreater}== introduces changed-based {VC} == conflict-free = commutation{\textless}/p{\textgreater}}
},

@inproceedings{lippmeier_efficient_2011,
	author = {Ben Lippmeier and Gabriele Keller},
	title = {Efficient parallel stencil convolution in Haskell},
	booktitle = {Haskell},
	year = {2011},
	pages = {59-70},
	ee = {http://doi.acm.org/10.1145/2034675.2034684},
	bibsource = {DBLP, http://dblp.uni-trier.de}
},

@inproceedings{lippmeier_guiding_2012,
	author = {Ben Lippmeier and Manuel Chakravarty and Gabriele Keller and Simon {Peyton Jones}},
	title = {Guiding parallel array fusion with indexed types},
	booktitle = {Haskell},
	pages = {25-36},
	year = {2012},
	organization = {ACM}
},

@inproceedings{lippmeier_polarized_2016,
	author = {Ben Lippmeier and Fil Mackay and Amos Robinson},
	title = {Polarized data parallel data flow},
	booktitle = {Proceedings of the 5th International Workshop on
                  Functional High-Performance Computing},
	pages = {52--57},
	year = {2016},
	organization = {ACM}
},

@article{liu_multi-task_2019,
	author = {Xiaodong Liu and Pengcheng He and Weizhu Chen and Jianfeng Gao},
	title = {Multi-Task Deep Neural Networks for Natural Language Understanding},
	journal = {arXiv preprint arXiv:1901.11504},
	year = {2019}
},

@TechReport{ljunglof_bilingual_2011,
	author = {P. Ljungl{\"{o}}f and M. Siverbo},
	title = {A bilingual treebank for the {F}ra{C}aS test suite},
	institution = {University of Gothenburg},
	year = {2011},
	type = {CLT project report},
	number = {},
	OPTaddress = {},
	OPTmonth = {},
	OPTnote = {}
},

@article{longo_genericity_1993,
	author = {Giuseppe Longo and Kathleen Milsted and Sergei Soloviev and Kathleen Milsted},
	title = {The Genericity Theorem and the Notion of Parametricity in the Polymorphic {lambda-Calculus}},
	volume = {121},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.53.4136},
	journal = {{THEORETICAL} {COMPUTER} {SCIENCE}},
	year = {1993},
	pages = {323---349}
},

@article{loshchilov_decoupled_2019,
	author = {Ilya Loshchilov and Frank Hutter},
	title = {Decoupled {{Weight Decay Regularization}}},
	year = {2019},
	month = {jan},
	abstract = {L\$\_2\$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is \textbackslash emph\{not\} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L\$\_2\$ regularization (often calling it "weight decay" in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by \textbackslash emph\{decoupling\} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments is available at https://github.com/loshchil/AdamW-and-SGDW},
	archiveprefix = {arXiv},
	eprint = {1711.05101},
	eprinttype = {arxiv},
	journal = {arXiv:1711.05101 [cs, math]},
	keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Mathematics - Optimization and Control},
	primaryclass = {cs, math}
},

@book{luo_computation_1994,
	author = {Zhaohui Luo},
	title = {Computation and reasoning: a type theory for computer science},
	isbn = {0-19-853835-9},
	shorttitle = {Computation and reasoning},
	url = {http://portal.acm.org/citation.cfm?id=184757},
	publisher = {Oxford University Press, Inc.},
	year = {1994}
},

@InProceedings{luo_common_2012,
	author = {Z. Luo},
	title = {Common Nouns as Types},
	booktitle = {Logical Aspects of Computational Linguistics (LACL'2012). LNCS 7351},
	year = {2012},
	editor = {D. Bechet and A. Dikovsky},
	OPTpages = {173-185}
},

@article{luo_formal_2012,
	author = {Zhaohui Luo},
	title = {Formal semantics in modern type theories with coercive subtyping},
	journal = {Linguistics and Philosophy},
	volume = {35},
	number = {6},
	pages = {491--513},
	year = {2012},
	publisher = {Springer}
},

@inproceedings{lmmel_generic_2002,
	author = {Ralf Lämmel},
	address = {Pittsburgh, Pennsylvania},
	title = {Towards generic refactoring},
	isbn = {1-58113-606-4},
	url = {http://portal.acm.org/citation.cfm?doid=570186.570188},
	doi = {10.1145/570186.570188},
	abstract = {We define a challenging and meaningful benchmark for genericity in language processing, namely the notion of generic program refactoring. We provide the first implementation of the benchmark based on functional strategic programming in Haskell. We use the basic refactoring of abstraction extraction as the running example. Our implementation comes as a functional programming framework with hot spots for the language-specific ingredients for refactoring, e.g., means for abstraction construction and destruction, and recognisers for name analysis. The language-parametric framework can be instantiated for various, rather different languages, e.g., Java, Prolog, Haskell, or {XML} schema.},
	booktitle = {Proceedings of the 2002 {ACM} {SIGPLAN} workshop on Rule-based programming},
	publisher = {{ACM}},
	year = {2002},
	keywords = {frameworks, functional programming, generic programming, language, program transformation, refactoring, reuse, strafunski},
	pages = {15--28}
},

@inproceedings{lmmel_expression_2008,
	author = {Ralf Lämmel and Ondrej Rypacek},
	title = {{{The} expression lemma}},
	booktitle = {{{Proceedings} of Mathematics of Program Construction {(MPC)} 2008}},
	publisher = {Springer},
	year = {2008},
	keywords = {open},
	annote = {{{\textless}p{\textgreater}To} appear{\textless}/p{\textgreater}}
},

@article{lh_tutorial_2001,
	author = {A. Löh and C. McBride and W. Swierstra},
	file = {:/home/bernardy/Papers/A tutorial implementation of a dependently typed lambda calculus-2001.pdf:pdf},
	title = {{A tutorial implementation of a dependently typed lambda calculus}},
	journal = {Fundamenta Informaticae},
	volume = {21},
	pages = {1001--1031},
	year = {2001},
	publisher = {Citeseer}
},

@inproceedings{lh_open_2006,
	author = {Andres Löh and Ralf Hinze},
	address = {Venice, Italy},
	title = {Open data types and open functions},
	isbn = {1-59593-388-3},
	url = {http://portal.acm.org/citation.cfm?id=1140352},
	doi = {10.1145/1140335.1140352},
	abstract = {The problem of supporting the modular extensibility of both data and functions in one programming language at the same time is known as the expression problem. Functional languages traditionally make it easy to add new functions, but extending data (adding new data constructors) requires modifying existing code. We present a semantically and syntactically lightweight variant of open data types and open functions as a solution to the expression problem in the Haskell language. Constructors of open data types and equations of open functions may appear scattered throughout a program with several modules. The intended semantics is as follows: the program should behave as if the data types and functions were closed, defined in one place. The order of function equations is determined by best-fit pattern matching, where a specific pattern takes precedence over an unspecific one. We show that our solution is applicable to the expression problem, generic programming, and exceptions. We sketch two implementations: a direct implementation of the semantics, and a scheme based on mutually recursive modules that permits separate compilation},
	booktitle = {Proceedings of the 8th {ACM} {SIGPLAN} international conference on Principles and practice of declarative programming},
	publisher = {{ACM}},
	year = {2006},
	keywords = {expression problem, extensible data types, extensible exceptions, extensible functions, functional programming, generic programming, mutually recursive modules, open},
	pages = {133--144}
},

@misc{lh_principled_????,
	author = {Andres Löh and Wouter Swierstra and Daan Leijen},
	title = {A Principled Approach to Version Control},
	keywords = {vc, vc-project},
	howpublished = {\url{}}
},

@incollection{ma_types_1992,
	author = {{QingMing} Ma and John C. Reynolds},
	title = {Types, abstraction, and parametric polymorphism, part 2},
	url = {http://dx.doi.org/10.1007/3-540-55511-0_1},
	abstract = {The concept of relations over sets is generalized to relations over an arbitrary category, and used to investigate the abstraction (or logical-relations) theorem, the identity extension lemma, and parametric polymorphism, for Cartesian-closed-category models of the simply typed lambda calculus and {PL-category} models of the polymorphic typed lambda calculus. Treatments of Kripke relations and of complete relations on domains are included.},
	booktitle = {Mathematical Foundations of Programming Semantics},
	year = {1992},
	keywords = {parametricity},
	pages = {1--40}
},

@inproceedings{maccartney_natural_2007,
	author = {Bill MacCartney and Christopher D Manning},
	title = {Natural logic for textual inference},
	booktitle = {Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing},
	pages = {193--200},
	year = {2007},
	organization = {Association for Computational Linguistics}
},

@InProceedings{maccartney_phrase-based_2008,
	author = {Bill MacCartney and M. Galley and Christopher D. Manning},
	title = {A phrase-based alignment model for natural language inference},
	booktitle = {Proceedings of EMNLP-08},
	year = {2008},
	pages = {802-811},
	OPTorganization = {},
	OPTpublisher = {},
	OPTaddress = {},
	OPTmonth = {},
	OPTnote = {}
},

@article{mackie_lilac_1994,
	author = {I. Mackie},
	title = {Lilac: A functional programming language based on linear logic},
	journal = {Journal of Functional Programming},
	volume = {4},
	number = {4},
	pages = {395--433},
	year = {1994},
	publisher = {Cambridge Univ Press}
},

@inproceedings{magnusson_fine-grained_1993,
	author = {Boris Magnusson and Ulf Asklund and Sten Min{\textbackslash}"{or}},
	title = {{Fine-Grained} Revision Control for Collaborative Software Development},
	url = {http://citeseer.ist.psu.edu/magnusson93finegrained.html},
	abstract = {This paper presents a framework for controlling the evolution of complex software systems concurrently developed by teams of software engineers. A general technique for fine-grained revision control of hierarchically structured information, such as programs and documents, is described and evaluated. All levels in the hierarchy are revision controlled, leaves as well as branch nodes. The technique supports sharing of unchanged nodes among revisions, automatic change propagation, and...},
	booktitle = {Proceedings of {ACM} {{SIGSOFT}} '93: Symposium on Foundations of Software Engineering},
	year = {1993},
	keywords = {vc},
	pages = {21--30}
},

@inproceedings{magnusson_fine_1996,
	author = {Boris Magnusson and Ulf Asklund},
	title = {Fine Grained Version Control of Configurations in {COOP/Orm}},
	url = {http://citeseer.ist.psu.edu/19322.html},
	abstract = {. This paper describes a unified approach to version control of documents and configurations. Hierarchical structure, which is present in most documents such as programs, is recognized and utilized in a fine-grained version control system. The same mechanism is used for version control of configurations and extended to handle {DAGs} as well as trees. Change propagation within one hierarchical document is automatic while bindings between documents are explicit. The model is novel because of its...},
	booktitle = {System Configuration Management},
	year = {1996},
	keywords = {vc},
	pages = {31--48},
	annote = {{\textless}p{\textgreater}blabla{\textless}/p{\textgreater}}
},

@incollection{mairson_outline_1991,
	author = {Harry Mairson},
	series = {Lecture Notes in Computer Science},
	title = {Outline of a proof theory of parametricity},
	volume = {523},
	doi = {10.1007/3540543961_15},
	abstract = {Reynolds' Parametricity Theorem (also known as the Abstraction Theorem), a result concerning the model theory of the second order polymorphic typed λ-calculus {(F2),} has recently been used by Wadler to prove some unusual and interesting properties of programs. We present a purely syntactic version of the Parametricity Theorem, showing that it is simply an example of formal theorem proving in second order minimal logic over a first order equivalence theory on λ-terms. We analyze the use of parametricity in proving program equivalences, and show that structural induction is still required: parametricity is not enough.},
	booktitle = {Proceedings of the 5th {ACM} conference on Functional programming languages and computer architecture},
	publisher = {{Springer-Verlag}},
	year = {1991},
	pages = {313--327}
},

@inproceedings{makwana_numlin_2019,
	author = {Dhruv C. Makwana and Neelakantan R. Krishnaswami},
	title = {NumLin: Linear Types for Linear Algebra},
	booktitle = {33rd European Conference on Object-Oriented Programming, {ECOOP} 2019,
               July 15-19, 2019, London, United Kingdom},
	pages = {14:1--14:25},
	year = {2019},
	crossref = {DBLP:conf/ecoop/2019},
	url = {https://doi.org/10.4230/LIPIcs.ECOOP.2019.14},
	doi = {10.4230/LIPIcs.ECOOP.2019.14},
	timestamp = {Thu, 08 Aug 2019 11:07:57 +0200},
	biburl = {https://dblp.org/rec/bib/conf/ecoop/MakwanaK19},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@article{malde_calculating_2006,
	author = {Ketil Malde and Robert Giegerich},
	title = {Calculating {PSSM} probabilities with lazy dynamic programming},
	volume = {16},
	url = {http://portal.acm.org/citation.cfm?id=1114011},
	abstract = {Position-specific scoring matrices are one way to represent approximate string patterns, which are commonly encountered in the field of bioinformatics. An important problem that arises with their application is calculating the statistical significance of matches. We review the currently most efficient algorithm for this task, and show how it can be implemented in Haskell, taking advantage of the built-in non-strictness of the language. The resulting program turns out to be an instance of dynamic programming, using lists rather the typical dynamic programming matrix.},
	number = {1},
	journal = {J. Funct. Program.},
	year = {2006},
	keywords = {dynamic programming},
	pages = {75--81}
},

@incollection{malik_generating_2007,
	author = {Muhammad Malik and Aman Pervaiz and Sarfraz Khurshid},
	file = {:/home/bernardy/Papers/Generating Representation Invariants of Structurally Complex Data-2007.pdf:pdf},
	title = {Generating Representation Invariants of Structurally Complex Data},
	url = {http://www.springerlink.com/index/u35h787512q2j106.pdf},
	doi = {10.1007/978-3-540-71209-1_5},
	abstract = {Generating likely invariants using dynamic analyses is becoming an increasingly effective technique in software checking methodologies. This paper presents Deryaft, a novel algorithm for generating likely representation invariants of structurally complex data. Given a small set of concrete structures, Deryaft analyzes their key characteristics to formulate local and global properties that the structures exhibit. For effective formulation of structural invariants, Deryaft focuses on graph properties, including reachability, and views the program heap as an edge-labeled graph. Deryaft outputs a Java predicate that represents the invariants; the predicate takes an input structure and returns true if and only if it satisfies the invariants. The invariants generated by Deryaft directly enable automation of various existing frameworks, such as the Korat test generation framework and the Juzi data structure repair framework, which otherwise require the user to provide the invariants. Experimental results with the Deryaft prototype show that it feasibly generates invariants for a range of subject structures, including libraries as well as a stand-alone application.},
	booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
	year = {2007},
	keywords = {invariant, recovery},
	pages = {34--49},
	annote = {{\textless}p{\textgreater}* works on a snapshot of dynamic data * graph-like representation of heap * popular contender: Daikon (can be better for some inputs){\textless}/p{\textgreater}}
},

@inproceedings{maraev_kosttr-based_2018,
	author = {Vladislav Maraev and Jonathan Ginzburg and Staffan Larsson and Ye Tian and Jean-Philippe Bernardy},
	title = {Towards KoS/TTR-based proof-theoretic dialogue management},
	booktitle = {Proceedings of SemDial 2018 (AixDial): The 22nd Workshop on the Semantics and Pragmatics of Dialogue},
	year = {2018}
},

@inproceedings{maraev_predicting_2019,
	author = {Vladislav Maraev and Christine Howes and Jean-Philippe Bernardy},
	title = {Predicting laughter relevance spaces in dialogue},
	booktitle = {IWSDS - 10th International Workshop on Spoken Dialogue Systems},
	location = {Syracuse, Sicily, Italy},
	month = {April},
	day = {24-26},
	year = {2019}
},

@article{maraev_dialogue_2020,
	author = {Vladislav Maraev and Jean-Philippe Bernardy and Johnathan Ginzburg},
	title = {Dialogue management with linear logic: the role of metavariables in questions and clarifications},
	journal = {Traitement Automatique des Langues},
	year = {2020},
	pages = {43--67},
	volume = {61},
	number = {3},
	publisher = {Association pour le Traitement Automatique des Langues}
},

@inproceedings{maraev_non-humorous_2021,
	author = {Vladislav Maraev and Jean-Philippe Bernardy and Christine Howes},
	title = {Non-humorous use of laughter in spoken dialogue systems },
	booktitle = {Proceedings of the 7th Linguistic and Cognitive Approaches To Dialog Agents Workshop},
	year = {2021}
},

@inproceedings{maraev_should_2021,
	author = {Vladislav Maraev and Ellen Breitholtz and Christine Howes and Jean-Philippe Bernardy},
	title = {Why Should {I} Turn Left? Towards Active Explainability for Spoken Dialogue Systems.},
	booktitle = {Proceedings of the Reasoning and Interaction Conference (ReInAct 2021)},
	month = {oct},
	year = {2021},
	address = {Gothenburg, Sweden},
	publisher = {Association for Computational Linguistics},
	url = {https://aclanthology.org/2021.reinact-1.9},
	pages = {58--64},
	abstract = {In this paper we argue that to make dialogue systems able to actively explain their decisions they can make use of enthymematic reasoning. We motivate why this is an appropriate strategy and integrate it within our own proof-theoretic dialogue manager framework based on linear logic. In particular, this enables a dialogue system to provide reasonable answers to why-questions that query information previously given by the system.}
},

@inproceedings{marelli_sick_2014,
	author = {Marco Marelli and Stefano Menini and Marco Baroni and Luisa Bentivogli and Raffaella Bernardi and Roberto Zamparelli},
	title = {A {SICK} cure for the evaluation of compositional distributional semantic models.},
	booktitle = {LREC},
	pages = {216--223},
	year = {2014}
},

@inproceedings{marelli_semeval-2014_2014,
	author = {Marco Marelli and Luisa Bentivogli and Marco Baroni and Raffaella Bernardi and Stefano Menini and Roberto Zamparelli},
	title = {Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment},
	booktitle = {Proceedings of the 8th international workshop on semantic evaluation (SemEval 2014)},
	pages = {1--8},
	year = {2014}
},

@phdthesis{marlow_deforestation_1995,
	author = {Simon David Marlow},
	title = {Deforestation for Higher-Order Functional Programs},
	year = {1995},
	school = {University of Glasgow}
},

@unpublished{marlow_haskell_2010,
	author = {Simon Marlow},
	file = {:/home/bernardy/Papers/Haskell 2010 Language Report-2010.pdf:pdf},
	title = {Haskell 2010 Language Report},
	howpublished = {\url{http://haskell.org/definition/haskell2010.pdf}},
	year = {2010}
},

@inproceedings{marlow_seq_2010,
	author = {Simon Marlow and Patrick Maier and Hans-Wolfgang Loidl and Mustafa K Aswad and Philip W Trinder},
	title = {Seq no more: better strategies for parallel Haskell},
	booktitle = {Haskell},
	pages = {91--102},
	year = {2010},
	organization = {ACM}
},

@inproceedings{marlow_desugaring_2016,
	author = {Simon Marlow and Simon Peyton Jones and Edward Kmett and Andrey Mokhov},
	editor = {Geoffrey Mainland},
	title = {Desugaring Haskell's do-notation into applicative operations},
	booktitle = {Proceedings of the 9th International Symposium on Haskell, Haskell
               2016, Nara, Japan, September 22-23, 2016},
	pages = {92--104},
	publisher = {{ACM}},
	year = {2016},
	url = {https://doi.org/10.1145/2976002.2976007},
	doi = {10.1145/2976002.2976007},
	timestamp = {Tue, 06 Nov 2018 16:58:22 +0100},
	biburl = {https://dblp.org/rec/conf/haskell/MarlowJKM16.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@book{marr_vision_1982,
	author = {David Marr},
	address = {Cambridge},
	title = {Vision: {A} {Computational} {Investigation} into the {Human} {Representation} and {Processing} of {Visual} {Information}},
	publisher = {MIT Press},
	year = {1982}
},

@inproceedings{martin_hyperintensional_2012,
	author = {Scott Martin and Carl Pollard},
	title = {Hyperintensional Dynamic Semantics},
	booktitle = {Formal grammar},
	pages = {114--129},
	year = {2012},
	organization = {Springer}
},

@inproceedings{martin_community2vec_2017,
	author = {Trevor Martin},
	title = {Community2vec: {{Vector}} Representations of Online Communities Encode Semantic Relationships},
	shorttitle = {Community2vec},
	booktitle = {Proceedings of the {{Second Workshop}} on {{NLP}} and {{Computational Social Science}}},
	year = {2017},
	month = {aug},
	pages = {27--31},
	publisher = {{Association for Computational Linguistics}},
	address = {{Vancouver, Canada}},
	doi = {10.18653/v1/W17-2904},
	abstract = {Vector embeddings of words have been shown to encode meaningful semantic relationships that enable solving of complex analogies. This vector embedding concept has been extended successfully to many different domains and in this paper we both create and visualize vector representations of an unstructured collection of online communities based on user participation. Further, we quantitatively and qualitatively show that these representations allow solving of semantically meaningful community analogies and also other more general types of relationships. These results could help improve community recommendation engines and also serve as a tool for sociological studies of community relatedness.}
},

@Unpublished{martin-lof_intuitionistic_1971,
	author = {P. Martin-L{\"{o}}f},
	title = {An Intuitionistic Theory of Types},
	note = {manuscript},
	year = {1971},
	OPTmonth = {}
},

@book{martin-lf_intuitionistic_1984,
	author = {Per Martin-Löf},
	file = {:/home/bernardy/Papers/Intuitionistic type theory-1984.pdf:pdf},
	title = {Intuitionistic type theory},
	year = {1984},
	publisher = {Bibliopolis}
},

@inproceedings{martinez-gomez_on-demand_2017,
	author = {Pascual Mart{\i}nez-G{\'o}mez and Koji Mineshima and Yusuke Miyao and Daisuke Bekki},
	title = {On-demand Injection of Lexical Knowledge for Recognising Textual Entailment},
	booktitle = {Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics (EACL'17)},
	year = {2017}
},

@article{matsakis_rust_2014,
	author = {Nicholas D. Matsakis and II Klock},
	title = {The Rust Language},
	journal = {Ada Lett.},
	issue_date = {December 2014},
	volume = {34},
	number = {3},
	month = {oct},
	year = {2014},
	issn = {1094-3641},
	pages = {103--104},
	numpages = {2},
	url = {http://doi.acm.org/10.1145/2692956.2663188},
	doi = {10.1145/2692956.2663188},
	acmid = {2663188},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {affine type systems, memory management, rust, systems programming}
},

@inproceedings{mazurak_lightweight_2010,
	author = {Karl Mazurak and Jianzhou Zhao and Steve Zdancewic},
	title = {Lightweight linear types in system f},
	booktitle = {Proceedings of the 5th ACM SIGPLAN workshop on Types in language design and implementation},
	pages = {77--88},
	year = {2010},
	organization = {ACM}
},

@Inbook{mcbride_got_2016,
	author = {Conor McBride},
	editor = {Lindley, Sam and McBride, Conor and Trinder, Phil and
                  Sannella, Don},
	title = {I Got Plenty o' Nuttin'},
	bookTitle = {A List of Successes That Can Change the World: Essays
                  Dedicated to Philip Wadler on the Occasion of His
                  60th Birthday},
	year = {2016},
	publisher = {Springer International Publishing},
	address = {Cham},
	pages = {207--233},
	isbn = {978-3-319-30936-1},
	doi = {10.1007/978-3-319-30936-1_12},
	url = {http://dx.doi.org/10.1007/978-3-319-30936-1_12}
},

@article{mcdonell_optimising_2013,
	author = {Trevor L McDonell and Manuel MT Chakravarty and Gabriele Keller and Ben Lippmeier},
	title = {Optimising purely functional GPU programs},
	journal = {ACM SIGPLAN Notices},
	volume = {48},
	number = {9},
	pages = {49--60},
	year = {2013},
	publisher = {ACM}
},

@unpublished{mcbride_ornamental_2010,
	author = {Conor Mcbride},
	title = {Ornamental Algebras, Algebraic Ornaments},
	year = {2010},
	note = {Manuscript available online},
	url = {http://personal.cis.strath.ac.uk/~conor/pub/OAAO/Ornament.pdf}
},

@article{mckinna_type-correct_2006,
	author = {James Mckinna and Joel Wright},
	title = {A type-correct, stack-safe, provably correct, expression compiler},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.105.4086},
	doi = {10.1.1.105.4086},
	journal = {in Epigram. Submitted to the Journal of Functional Programming},
	year = {2006}
},

@incollection{meertens_calculate_1996,
	author = {Lambert Meertens},
	file = {:/home/bernardy/Papers/Calculate polytypically!-1996.pdf:pdf},
	title = {Calculate polytypically!},
	url = {http://www.springerlink.com/index/f021401k11vj268p.pdf},
	doi = {10.1007/3-540-61756-6_73},
	abstract = {A polytypic function definition is a function definition that is parametrised with a datatype. It embraces a class of algorithms. As an example we define a simple polytypic crush combinator that can be used to calculate polytypically. The ability to define functions polytypically adds another level of flexibility in the reusability of programming idioms and in the design of libraries of interoperable components.},
	booktitle = {Programming Languages: Implementations, Logics, and Programs},
	year = {1996},
	keywords = {aop},
	pages = {1--16}
},

@inproceedings{meijer_functional_1991,
	author = {Erik Meijer and Maarten Fokkinga and Ross Paterson},
	file = {:/home/bernardy/Papers/Functional programming with bananas, lenses, envelopes and barbed wire-1991.pdf:pdf},
	address = {Cambridge, Massachusetts, United States},
	title = {Functional programming with bananas, lenses, envelopes and barbed wire},
	isbn = {0-387-54396-1},
	url = {http://portal.acm.org/citation.cfm?id=128035},
	booktitle = {Proceedings of the 5th {ACM} conference on Functional programming languages and computer architecture},
	publisher = {{Springer-Verlag}},
	year = {1991},
	pages = {124--144}
},

@article{mellies_asynchronous_2005,
	author = {Paul-Andr{\'e} Melli{\`e}s},
	title = {Asynchronous Games 3 An Innocent Model of Linear Logic},
	journal = {Electronic Notes in Theoretical Computer Science},
	volume = {122},
	pages = {171--192},
	year = {2005},
	publisher = {Elsevier}
},

@article{mellis_resource_2010,
	author = {Paul-André Melliès and Nicolas Tabareau},
	title = {Resource modalities in tensor logic},
	journal = {Ann. Pure Appl. Logic},
	volume = {161},
	number = {5},
	pages = {632--653},
	year = {2010},
	url = {http://dx.doi.org/10.1016/j.apal.2009.07.018},
	doi = {10.1016/j.apal.2009.07.018},
	timestamp = {Tue, 27 Apr 2010 07:37:14 +0200},
	biburl = {http://dblp.uni-trier.de/rec/bib/journals/apal/MelliesT10},
	bibsource = {dblp computer science bibliography, http://dblp.org}
},

@article{mens_state-of-the-art_2002,
	author = {T Mens},
	title = {A state-of-the-art survey on software merging},
	volume = {28},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1000449},
	abstract = {Software merging is an essential aspect of the maintenance and evolution of large-scale software systems. This paper provides a comprehensive survey and analysis of available merge approaches. Over the years, a wide variety of different merge techniques has been proposed. While initial techniques were purely based on textual merging, more powerful approaches also take the syntax and semantics of the software into account. There is a tendency towards operation-based merging because of its increased expressiveness. Another tendency is to try to define merge techniques that are as general, accurate, scalable, and customizable as possible, so that they can be used in any phase in the software life-cycle and detect as many conflicts as possible. After comparing the possible merge techniques, we suggest a number of important open problems and future research directions},
	number = {5},
	journal = {Software Engineering, {IEEE} Transactions on},
	year = {2002},
	keywords = {survey, vc, vc-project},
	pages = {449--462}
},

@misc{mens_taxonomy_2003,
	author = {T Mens and J Buckley and M Zenger and A Rashid},
	title = {Towards a Taxonomy of Software Evolution},
	url = {http://citeseer.ist.psu.edu/601028.html},
	abstract = {Previous taxonomies of software evolution have focused on the purpose of the change (i.e., the why) rather than the underlying mechanisms. This paper proposes a taxonomy of software evolution based on the characterizing mechanisms of change and the factors that influence these mechanisms. The taxonomy is organized into the following logical groupings: temporal properties, objects of change, system properties, and change support.},
	year = {2003},
	keywords = {evolution}
},

@article{mens_detecting_2005,
	author = {Tom Mens and Gabriele Taentzer and Olga Runge},
	file = {:/home/bernardy/Papers/Detecting Structural Refactoring Conflicts Using Critical Pair Analysis-2005.pdf:pdf},
	doi = {10.1016/j.entcs.2004.08.038},
	title = {Detecting Structural Refactoring Conflicts Using Critical Pair Analysis},
	volume = {127},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S157106610500143X},
	abstract = {Refactorings are program transformations that improve the software structure while preserving the external behaviour. In spite of this very useful property, refactorings can still give rise to structural conflicts when parallel evolutions to the same software are made by different developers. This paper explores this problem of structural evolution conflicts in a formal way by using graph transformation and critical pair analysis. Based on experiments carried out in the graph transformation tool {AGG,} we show how this formalism can be exploited to detect and resolve refactoring conflicts.},
	number = {3},
	journal = {Electronic Notes in Theoretical Computer Science},
	month = {apr},
	year = {2005},
	keywords = {conflicts,critical pair analysis,evolution,graph transformation,parallel changes,refactoring,restructuring},
	pages = {113--128}
},

@misc{mens_uniform_????,
	author = {Tom Mens and Kim Mens},
	title = {A Uniform Declarative Framework for Automated Software Merging},
	url = {http://citeseer.ist.psu.edu/mens00uniform.html},
	abstract = {We report on a prototype tool that automates the time-consuming and error-prone process of software merging. Our tool is significantly more flexible than existing merge techniques, as it can detect syntactic, structural as well as semantic conflicts. It is implemented as a general framework for software evolution that can be customised to many different domains. Because of this, it can be used to support evolution of any kind of software artifact, independent of the target language or the...},
	keywords = {evolution, vc}
},

@book{metcalf_fortran_1990,
	author = {Michael Metcalf and John Reid},
	title = {Fortran 90 explained},
	isbn = {0198537727},
	year = {1990},
	publisher = {Oxford University Press}
},

@inproceedings{mikolov_distributed_2013,
	author = {Tomas Mikolov and Ilya Sutskever and Kai Chen and Greg Corrado and Jeffrey Dean},
	title = {Distributed Representations of Words and Phrases and Their Compositionality},
	booktitle = {Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 2},
	series = {NIPS'13},
	year = {2013},
	location = {Lake Tahoe, Nevada},
	pages = {3111--3119},
	numpages = {9}
},

@inproceedings{mikolov_advances_2018,
	author = {Tomas Mikolov and Edouard Grave and Piotr Bojanowski and Christian Puhrsch and Armand Joulin},
	title = {Advances in Pre-Training Distributed Word Representations},
	booktitle = {Proceedings of the International Conference on Language Resources and Evaluation (LREC 2018)},
	year = {2018}
},

@article{miller_wordnet_1995,
	author = {George A Miller},
	title = {WordNet: a lexical database for English},
	journal = {Communications of the ACM},
	volume = {38},
	number = {11},
	pages = {39--41},
	year = {1995},
	publisher = {ACM}
},

@inproceedings{miller_proof_2003,
	author = {Dale A. Miller and Alwen F. Tiu},
	file = {:/home/bernardy/Papers/A Proof Theory for Generic Judgments An extended abstract-2003.pdf:pdf},
	title = {A Proof Theory for Generic Judgments: An extended abstract},
	booktitle = {Proceedings of the 18th Annual IEEE Symposium on Logic in Computer Science},
	year = {2003},
	month = {June},
	pages = {118--127},
	location = {Ottawa, Canada},
	publisher = {IEEE Computer Society}
},

@inproceedings{miller_proofs_2007,
	author = {Dale Miller and Alexis Saurin},
	title = {From proofs to focused proofs: a modular proof of focalization in linear logic},
	booktitle = {Computer Science Logic},
	pages = {405--419},
	year = {2007},
	organization = {Springer}
},

@article{milner_logic_1972,
	author = {Robin Milner},
	file = {:/home/bernardy/Papers/Logic for Computable Functions description of a machine implementation.-1972.pdf:pdf},
	journal = {Artificial Intelligence},
	title = {{Logic for Computable Functions: description of a machine implementation.}},
	url = {http://portal.acm.org/citation.cfm?id=891954},
	year = {1972}
},

@book{milner_definition_1990,
	author = {Robert Milner and Mads Tofte and Robert Harper},
	title = {The definition of {Standard ML}},
	isbn = {0262631296},
	year = {1990},
	publisher = {MIT press}
},

@inproceedings{mineshima_higher-order_2015,
	author = {Koji Mineshima and Pascual Martínez-Gómez and Yusuke Miyao and Daisuke Bekki},
	address = {Lisbon, Portugal},
	title = {Higher-order logical inference with compositional semantics},
	url = {https://www.aclweb.org/anthology/D15-1244},
	doi = {10.18653/v1/D15-1244},
	urldate = {2021-03-01},
	booktitle = {Proceedings of the 2015 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	month = {sep},
	year = {2015},
	pages = {2055--2061}
},

@phdthesis{miquel_calcul_2001,
	author = {Alexandre Miquel},
	file = {:/home/bernardy/Papers/Le Calcul des Constructions implicite syntaxe et smantique-2001.pdf:pdf},
	title = {Le Calcul des Constructions implicite: syntaxe et sémantique},
	type = {Thèse de doctorat},
	school = {Université Paris 7},
	month = {12},
	year = {2001}
},

@misc{miquel_theorie_????,
	author = {Alexandre Miquel},
	title = {Theorie de la demonstration},
	url = {http://perso.ens-lyon.fr/alexandre.miquel/enseignement/index.html},
	howpublished = {\url{http://perso.ens-lyon.fr/alexandre.miquel/enseignement/index.html}}
},

@misc{miquel_type_????,
	author = {Alexandre Miquel},
	title = {Type Theory: Impredicative Part},
	url = {http://www.math.chalmers.se/~miquel/},
	howpublished = {\url{http://www.math.chalmers.se/~miquel/}}
},

@phdthesis{mishra-linger_irrelevance_2008,
	author = {Nathan Mishra-Linger},
	file = {:/home/bernardy/Papers/Irrelevance, Polymorphism, and Erasure in Type Theory-2008.pdf:pdf},
	school = {Portland State University},
	title = {Irrelevance, Polymorphism, and Erasure in Type Theory},
	year = {2008}
},

@conference{mishra-linger_erasure_2008,
	author = {N. Mishra-Linger and Tim Sheard},
	file = {:/home/bernardy/Papers/Erasure and polymorphism in pure type systems-2008.pdf:pdf},
	title = {{Erasure and polymorphism in pure type systems}},
	booktitle = {Proceedings of the Theory and practice of software, 11th international conference on Foundations of software science and computational structures},
	pages = {350--364},
	year = {2008},
	organization = {Springer-Verlag}
},

@inproceedings{mitchell_deriving_2007,
	author = {Neil Mitchell},
	title = {Deriving Generic Functions by Example},
	year = {2007},
	month = {October},
	day = {26},
	pages = {55--62},
	publisher = {Tech. Report {YCS-2007-421}, Dept. of Computer Science, University of {York}, {UK}},
	editor = {Jan Tobias Mühlberg and Juan Ignacio Perna},
	booktitle = {Proceedings of the First York Doctoral Syposium 2007},
	url = {http://community.haskell.org/~ndm/downloads/paper-deriving_generic_functions_by_example-26_oct_2007.pdf}
},

@article{moggi_notions_1991,
	author = {Eugenio Moggi},
	title = {Notions of computation and monads},
	journal = {Information and computation},
	volume = {93},
	number = {1},
	pages = {55--92},
	year = {1991},
	publisher = {Elsevier}
},

@article{mokhov_build_2018,
	author = {Andrey Mokhov and Neil Mitchell and Simon {Peyton Jones}},
	title = {Build systems {\`a} la carte},
	journal = {Proceedings of the ACM on Programming Languages},
	volume = {2},
	number = {ICFP},
	pages = {1--29},
	year = {2018},
	publisher = {ACM New York, NY, USA}
},

@article{mokhov_selective_2019,
	author = {Andrey Mokhov and Georgy Lukyanov and Simon Marlow and Jeremie Dimino},
	title = {Selective applicative functors},
	journal = {Proceedings of the ACM on Programming Languages},
	volume = {3},
	number = {ICFP},
	pages = {1--29},
	year = {2019},
	publisher = {ACM New York, NY, USA}
},

@inproceedings{monnier_singleton_2010,
	author = {Stefan Monnier and David Haguenauer},
	file = {:/home/bernardy/Papers/Singleton types here, singleton types there, singleton types everywhere-2010.pdf:pdf},
	address = {Madrid, Spain},
	title = {Singleton types here, singleton types there, singleton types everywhere},
	isbn = {978-1-60558-890-2},
	url = {http://portal.acm.org/citation.cfm?id=1707790.1707792},
	doi = {10.1145/1707790.1707792},
	abstract = {Singleton types are often considered a poor man's substitute for dependent types. But their generalization in the form of {GADTs} has found quite a following. The main advantage of singleton types and {GADTs} is to preserve the so-called phase distinction, which seems to be so important to make use of the usual compilation techniques.},
	booktitle = {Proceedings of the 4th {ACM} {SIGPLAN} workshop on Programming languages meets program verification},
	publisher = {{ACM}},
	year = {2010},
	keywords = {certified compilation, dependent types, singleton types},
	pages = {1--8},
	annote = {{{\textless}p{\textgreater}Figure} 7 is Reynolds embedding.{\textless}/p{\textgreater}}
},

@InProceedings{montague_english_1970,
	author = {Richard Montague},
	title = {English as a formal language},
	booktitle = {Linguaggi nella Societa e nella Tecnica},
	year = {1970},
	editor = {B. Visentini et al.}
},

@article{montague_universal_1970,
	author = {Richard Montague},
	title = {Universal grammar},
	volume = {36},
	issn = {1755-2567},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1755-2567.1970.tb00434.x},
	doi = {10.1111/j.1755-2567.1970.tb00434.x},
	language = {en},
	number = {3},
	urldate = {2020-10-26},
	journal = {Theoria},
	year = {1970},
	pages = {373--398}
},

@incollection{montague_proper_1973,
	author = {Richard Montague},
	address = {Dordrecht},
	series = {Synthese {Library}},
	title = {The proper treatment of quantification in ordinary English},
	isbn = {978-94-010-2506-5},
	url = {https://doi.org/10.1007/978-94-010-2506-5_10},
	abstract = {The aim of this paper is to present in a rigorous way the syntax and semantics of a certain fragment of a certain dialect of English. For expository purposes the fragment has been made as simple and restricted as it can be while accommodating all the more puzzling cases of quantification and reference with which I am acquainted.1},
	language = {en},
	urldate = {2020-10-24},
	booktitle = {Approaches to {Natural} {Language}: {Proceedings} of the 1970 {Stanford} {Workshop} on {Grammar} and {Semantics}},
	publisher = {Springer Netherlands},
	editor = {Hintikka, K. J. J. and Moravcsik, J. M. E. and Suppes, P.},
	year = {1973},
	doi = {10.1007/978-94-010-2506-5_10},
	keywords = {Common Noun, English Sentence, Individual Concept, Recursive Definition, Syntactic Rule},
	pages = {221--242},
	see = {:montague_proper_1974}
},

@incollection{montague_proper_1974,
	author = {Richard Montague},
	Address = {New Haven},
	Booktitle = {Formal Philosophy},
	Editor = {Richmond Thomason},
	Publisher = {Yale UP},
	Title = {The Proper Treatment of Quantification in Ordinary English},
	Year = {1974}
},

@inproceedings{morihata_third_2009,
	author = {Akimasa Morihata and Kiminori Matsuzaki and Zhenjiang Hu and Masato Takeichi},
	title = {The third homomorphism theorem on trees: downward {\&}
               upward lead to divide-and-conquer},
	booktitle = {POPL},
	year = {2009},
	pages = {177-185},
	ee = {http://doi.acm.org/10.1145/1480881.1480905},
	crossref = {DBLP:conf/popl/2009},
	bibsource = {DBLP, http://dblp.uni-trier.de}
},

@article{morita_automatic_2007,
	author = {Kazutaka Morita and Akimasa Morihata and Kiminori Matsuzaki and Zhenjiang Hu and Masato Takeichi},
	file = {:/home/bernardy/Papers/Automatic inversion generates divide-and-conquer parallel programs-2007.pdf:pdf;:/home/bernardy/Papers/Automatic inversion generates divide-and-conquer parallel programs-2007.bGE:bGE},
	title = {Automatic inversion generates divide-and-conquer parallel programs},
	journal = {ACM SIGPLAN Notices},
	volume = {42},
	number = {6},
	pages = {146--155},
	year = {2007}
},

@inproceedings{morris_indexed_2009,
	author = {Peter Morris and Thorsten Altenkirch},
	title = {Indexed Containers},
	booktitle = {{Twenty-Fourth} {IEEE} Symposium on Logic in Computer Science},
	year = {2009},
	issn = {1043-6871},
	pages = {277-285},
	doi = {http://doi.ieeecomputersociety.org/10.1109/LICS.2009.33},
	publisher = {IEEE Computer Society},
	address = {Los Alamitos, CA, USA}
},

@inproceedings{morris_best_2016,
	author = {J. Garrett Morris},
	title = {The best of both worlds: linear functional programming without compromise},
	booktitle = {Proceedings of the 21st {ACM} {SIGPLAN} International Conference on
               Functional Programming, {ICFP} 2016, Nara, Japan, September 18-22,
               2016},
	pages = {448--461},
	year = {2016},
	url = {http://doi.acm.org/10.1145/2951913.2951925},
	doi = {10.1145/2951913.2951925},
	timestamp = {Tue, 30 Aug 2016 13:53:57 +0200},
	biburl = {http://dblp.uni-trier.de/rec/bib/conf/icfp/Morris16},
	bibsource = {dblp computer science bibliography, http://dblp.org}
},

@phdthesis{moulin_pure_2013,
	author = {Guilhem Moulin},
	title = {Pure Type Systems with an Internalized Parametricity Theorem},
	school = {Chalmers Tekniska Högskola},
	type = {Licenciate Thesis},
	year = {2013}
},

@phdthesis{moulin_internalizing_2016,
	author = {Guilhem Moulin},
	title = {Internalizing Parametricity},
	school = {Chalmers Tekniska Högskola},
	type = {PhD Thesis},
	year = {2016}
},

@article{mu_algebra_2009,
	author = {Shin-Cheng Mu and Hsiang-Shang Ko and Patrik Jansson},
	title = {Algebra of programming in {Agda}: dependent types for relational program derivation},
	publisher = {Cambridge University Press},
	journal = {Journal of Functional Programming},
	volume = {19},
	issue = {5},
	pages = {545--579},
	year = {2009},
	doi = {10.1017/S0956796809007345}
},

@inproceedings{munch-maccagnoni_formulae-as-types_2014,
	author = {Guillaume Munch{-}Maccagnoni},
	title = {Formulae-as-types for an involutive negation},
	booktitle = {Joint Meeting of the Twenty-Third {EACSL} Annual Conference on Computer
               Science Logic {(CSL)} and the Twenty-Ninth Annual {ACM/IEEE} Symposium
               on Logic in Computer Science (LICS), {CSL-LICS} '14, Vienna, Austria,
               July 14 - 18, 2014},
	pages = {70:1--70:10},
	year = {2014},
	url = {http://doi.acm.org/10.1145/2603088.2603156},
	doi = {10.1145/2603088.2603156},
	timestamp = {Thu, 23 Apr 2015 17:57:17 +0200},
	biburl = {http://dblp.uni-trier.de/rec/bib/conf/csl/Munch-Maccagnoni14},
	bibsource = {dblp computer science bibliography, http://dblp.org}
},

@inproceedings{murphy_distributed_2005,
	author = {Tom Murphy and Karl Crary and Robert Harper},
	title = {Distributed Control Flow with Classical Modal Logic},
	booktitle = {Computer Science Logic, 19th International Workshop, {CSL} 2005, 14th
               Annual Conference of the EACSL, Oxford, UK, August 22-25, 2005, Proceedings},
	pages = {51--69},
	year = {2005},
	crossref = {DBLP:conf/csl/2005},
	url = {https://doi.org/10.1007/11538363\_6},
	doi = {10.1007/11538363\_6},
	timestamp = {Tue, 14 May 2019 10:00:42 +0200},
	biburl = {https://dblp.org/rec/conf/csl/VIICH05.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@inproceedings{mycroft_effect_2016,
	author = {Alan Mycroft and Dominic A. Orchard and Tomas Petricek},
	title = {Effect Systems Revisited - Control-Flow Algebra and Semantics},
	booktitle = {Semantics, Logics, and Calculi - Essays Dedicated to Hanne Riis Nielson and Flemming Nielson on the Occasion of Their 60th Birthdays},
	pages = {1--32},
	year = {2016},
	crossref = {DBLP:conf/birthday/2016nielson},
	url = {https://doi.org/10.1007/978-3-319-27810-0\_1},
	doi = {10.1007/978-3-319-27810-0\_1},
	timestamp = {Sun, 02 Jun 2019 21:24:20 +0200},
	biburl = {https://dblp.org/rec/conf/birthday/MycroftOP16.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@inproceedings{neis_non-parametric_2009,
	author = {Georg Neis and Derek Dreyer and Andreas Rossberg},
	file = {:/home/bernardy/Papers/Non-parametric parametricity-2009.pdf:pdf},
	address = {Edinburgh, Scotland},
	title = {Non-parametric parametricity},
	isbn = {978-1-60558-332-7},
	url = {http://portal.acm.org/citation.cfm?id=1596550.1596572},
	doi = {10.1145/1596550.1596572},
	abstract = {Type abstraction and intensional type analysis are features seemingly at odds-type abstraction is intended to guarantee parametricity and representation independence, while type analysis is inherently non-parametric. Recently, however, several researchers have proposed and implemented "dynamic type generation" as a way to reconcile these features. The idea is that, when one defines an abstract type, one should also be able to generate at run time a fresh type name, which may be used as a dynamic representative of the abstract type for purposes of type analysis. The question remains: in a language with non-parametric polymorphism, does dynamic type generation provide us with the same kinds of abstraction guarantees that we get from parametric polymorphism?},
	booktitle = {Proceedings of the 14th {ACM} {SIGPLAN} international conference on Functional Programming},
	publisher = {{ACM}},
	year = {2009},
	keywords = {intensional type analysis, parametricity, representation independence, step-indexed logical relations, type-safe cast},
	pages = {135--148}
},

@inproceedings{nguyen_old_2013,
	author = {Dong Nguyen and Rilana Gravel and Dolf Trieschnigg and Theo Meder},
	title = {How {{Old Do You Think I Am}}?: {{A Study}} of {{Language}} and {{Age}} in {{Twitter}}},
	booktitle = {Proceedings of the {{Seventh International AAAI Conference}} on {{Weblogs}} and {{Social Media}}},
	year = {2013},
	pages = {10},
	abstract = {In this paper we focus on the connection between age and language use, exploring age prediction of Twitter users based on their tweets. We discuss the construction of a fine-grained annotation effort to assign ages and life stages to Twitter users. Using this dataset, we explore age prediction in three different ways: classifying users into age categories, by life stages, and predicting their exact age. We find that an automatic system achieves better performance than humans on these tasks and that both humans and the automatic systems have difficulties predicting the age of older people. Moreover, we present a detailed analysis of variables that change with age. We find strong patterns of change, and that most changes occur at young ages.},
	language = {en}
},

@incollection{nickel_poincare_2017,
	author = {Maximillian Nickel and Douwe Kiela},
	title = {Poincar\'{e} Embeddings for Learning Hierarchical Representations},
	booktitle = {Advances in Neural Information Processing Systems 30},
	editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	pages = {6338--6347},
	year = {2017},
	publisher = {Curran Associates, Inc.}
},

@InProceedings{nickel_learning_2018,
	author = {Maximillian Nickel and Douwe Kiela},
	title = {Learning Continuous Hierarchies in the {L}orentz Model of Hyperbolic Geometry},
	booktitle = {Proceedings of the 35th International Conference on Machine Learning},
	pages = {3779--3788},
	year = {2018},
	editor = {Dy, Jennifer and Krause, Andreas},
	volume = {80},
	series = {Proceedings of Machine Learning Research},
	address = {Stockholmsmässan, Stockholm Sweden},
	month = {10--15 Jul},
	publisher = {PMLR},
	abstract = {We are concerned with the discovery of hierarchical relationships from large-scale unstructured similarity scores. For this purpose, we study different models of hyperbolic space and find that learning embeddings in the Lorentz model is substantially more efficient than in the Poincar{é}-ball model. We show that the proposed approach allows us to learn high-quality embeddings of large taxonomies which yield improvements over Poincar{é} embeddings, especially in low dimensions. Lastly, we apply our model to discover hierarchies in two real-world datasets: we show that an embedding in hyperbolic space can reveal important aspects of a company’s organizational structure as well as reveal historical relationships between language families.}
},

@inproceedings{nielsen_call-by-name_1995,
	author = {Kristian Nielsen and Morten Heine Sørensen},
	title = {{Call-By-Name} {CPS-Translation} as a {Binding-Time} Improvement},
	isbn = {3-540-60360-3},
	url = {http://portal.acm.org/citation.cfm?id=717677},
	booktitle = {Proceedings of the Second International Symposium on Static Analysis},
	publisher = {{Springer-Verlag}},
	year = {1995},
	pages = {296--313}
},

@misc{nilsson_scalacheck_2009,
	author = {Rickard Nilsson},
	title = {{ScalaCheck}},
	url = {http://code.google.com/p/scalacheck/},
	journal = {Google Code},
	month = {7},
	year = {2009},
	howpublished = {\url{http://code.google.com/p/scalacheck/}}
},

@article{nishizaki_programs_1993,
	author = {Shin-ya Nishizaki},
	title = {Programs with continuations and linear logic },
	journal = {Science of Computer Programming },
	volume = {21},
	number = {2},
	pages = {165 - 190},
	year = {1993},
	note = {},
	issn = {0167-6423},
	doi = {http://dx.doi.org/10.1016/0167-6423(93)90005-A},
	url = {http://www.sciencedirect.com/science/article/pii/016764239390005A}
},

@inproceedings{niu_category-theoretic_2005,
	author = {N Niu and S Easterbrook and M Sabetzadeh},
	title = {A category-theoretic approach to syntactic software merging},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1510116},
	abstract = {Software merging is a common and essential activity during the lifespan of large-scale software systems. Traditional textual merge techniques are inadequate for detecting syntactic merge conflicts. In this paper, we propose a domain-independent approach for syntactic software merging that exploits the graph-based structure(s) of programs. We use morphisms between fuzzy graphs to capture the relationships between the structural elements of the programs to be merged, and apply a truth ordering lattice to express inconsistencies and evolutionary properties as we compute the merge. We demonstrate the approach with a three-way consolidation merge in a commercial software system; in particular, we show how analyzing merged call structures can help developers gain a better understanding and control of software evolution.},
	booktitle = {Software Maintenance, 2005. {ICSM'05.} Proceedings of the 21st {IEEE} International Conference on},
	year = {2005},
	keywords = {vc},
	pages = {197--206}
},

@phdthesis{norell_practical_2007,
	author = {Ulf Norell},
	type = {{PhD} Thesis},
	title = {Towards a practical programming language based on dependent type theory},
	url = {http://publications.lib.chalmers.se/cpl/record/index.xsql?pubid=46311},
	abstract = {Dependent type theories have a long history of being used for theorem proving. One aspect of type theory which makes it very powerful as a proof language is that it mixes deduction with computation. This also makes type theory a good candidate for programming---the strength of the type system allows properties of programs to be stated and established, and the computational properties provide semantics for the programs. This thesis is concerned with bridging the gap between the theoretical presentations of type theory and the requirements on a practical programming language. Although there are many challenging research problems left to solve before we have an industrial scale programming language based on type theory, this thesis takes us a good step along the way.},
	school = {Chalmers Tekniska Högskola},
	year = {2007},
	keywords = {type theory, programming, dependent types, pattern matching, metavariables, type checking}
},

@inproceedings{oconnor_mixture_2010,
	author = {Brendan O'Connor and Jacob Eisenstein and Eric P Xing and Noah A Smith},
	title = {A Mixture Model of Demographic Lexical Variation},
	booktitle = {In {{Proceedings}} of {{NIPS Workshop}} on {{Machine Learning}} for {{Social Computing}}},
	year = {2010},
	pages = {6},
	publisher = {{2010}},
	address = {{Vancouver, BC, Canada}},
	abstract = {We propose a Bayesian generative model of how demographic social factors influence lexical choice. We apply the method to a corpus of geo-tagged Twitter messages originating from mobile phones, cross-referenced against U.S. Census demographic data. Our method discovers communities jointly defined by linguistic and demographic properties.},
	language = {en}
},

@misc{osullivan_criterion_2013,
	author = {Bryan O'Sullivan},
	title = {The {{Criterion}} benchmarking library},
	url = {http://github.com/bos/criterion},
	year = {2013}
},

@article{okasaki_call-by-need_1994,
	author = {Chris Okasaki and Peter Lee and David Tarditi},
	title = {Call-by-need and continuation-passing style},
	volume = {7},
	url = {http://dx.doi.org/10.1007/BF01019945},
	doi = {10.1007/BF01019945},
	abstract = {This paper examines the transformation of call-by-need ? terms into continuation-passing style {(CPS).} It begins by presenting a simple transformation of call-by-need ? terms into program graphs and a reducer for such graphs. From this, an informal derivation is carried out, resulting in a translation from ? terms into self-reducing program graphs, where the graphs are represented as {CPS} terms involving storage operations. Though informal, the derivation proceeds in simple steps, and the resulting translation is taken to be our canonical {CPS} transformation for call-by-need ? terms.},
	number = {1},
	journal = {{LISP} and Symbolic Computation},
	month = {jan},
	year = {1994},
	pages = {57--81}
},

@phdthesis{okasaki_purely_1996,
	author = {Chris Okasaki},
	file = {:/home/bernardy/Papers/Purely Functional Data Structure-1996.pdf:pdf},
	school = {Carnegie Mellon University},
	title = {Purely Functional Data Structure},
	year = {1996}
},

@book{okasaki_purely_1999,
	author = {Chris Okasaki},
	title = {Purely Functional Data Structures},
	isbn = {0521663504},
	publisher = {Cambridge University Press},
	month = {jul},
	year = {1999},
	pages = {220},
	see = {version:okasaki_purely_1996}
},

@article{okhotin_parsing_2014,
	author = {Alexander Okhotin},
	title = {Parsing by matrix multiplication generalized to Boolean grammars},
	journal = {Theoretical Computer Science },
	volume = {516},
	number = {0},
	pages = {101 - 120},
	year = {2014},
	note = {},
	issn = {0304-3975},
	doi = {http://dx.doi.org/10.1016/j.tcs.2013.09.011},
	url = {http://www.sciencedirect.com/science/article/pii/S0304397513006919},
	keywords = {Boolean grammars},
	keywords = {Conjunctive grammars},
	keywords = {Context-free grammars},
	keywords = {Matrix multiplication},
	keywords = {Parsing }
},

@phdthesis{olausson_implementing_2014,
	author = {Tobias Olausson},
	type = {{MSc} Thesis},
	title = {Implementing incremental and parallel parsing},
	school = {Chalmers University of Technology},
	year = {2014}
},

@inproceedings{orchard_haskell_2010,
	author = {Dominic Orchard and Tom Schrijvers},
	file = {:/home/bernardy/Papers/Haskell Type Constraints Unleashed-2010.pdf:pdf},
	booktitle = {Functional and Logic Programming},
	pages = {1--19},
	title = {{Haskell Type Constraints Unleashed}},
	url = {http://www.springerlink.com/index/R87810UN65965001.pdf},
	year = {2010}
},

@article{orchard_quantitative_2019,
	author = {Dominic Orchard and Vilem{-}Benjamin Liepelt and Harley Eades III},
	title = {Quantitative program reasoning with graded modal types},
	journal = {{PACMPL}},
	volume = {3},
	number = {{ICFP}},
	pages = {110:1--110:30},
	year = {2019},
	url = {https://doi.org/10.1145/3341714},
	doi = {10.1145/3341714},
	timestamp = {Mon, 21 Oct 2019 15:15:21 +0200},
	biburl = {https://dblp.org/rec/journals/pacmpl/OrchardLE19.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@inproceedings{orita_discourse_2015,
	author = {Naho Orita and Eliana Vornov and Naomi Feldman and Hal Daumé III},
	address = {Beijing, China},
	title = {Why discourse affects speakers' choice of referring expressions},
	url = {https://www.aclweb.org/anthology/P15-1158},
	doi = {10.3115/v1/P15-1158},
	urldate = {2021-03-06},
	booktitle = {Proceedings of the 53rd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 7th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	month = {jul},
	year = {2015},
	pages = {1639--1649}
},

@inproceedings{oury_power_2008,
	author = {Nicolas Oury and Wouter Swierstra},
	file = {:/home/bernardy/Papers/The power of Pi-2008.pdf:pdf},
	address = {Victoria, {BC}, Canada},
	title = {The power of {Pi}},
	isbn = {978-1-59593-919-7},
	url = {http://portal.acm.org/citation.cfm?id=1411204.1411213},
	doi = {10.1145/1411204.1411213},
	abstract = {This paper exhibits the power of programming with dependent types by dint of embedding three domain-specific languages: Cryptol, a language for cryptographic protocols; a small data description language; and relational algebra. Each example demonstrates particular design patterns inherent to dependently-typed programming. Documenting these techniques paves the way for further research in domain-specific embedded type systems.},
	booktitle = {Proceedings of the 13th {ACM} {SIGPLAN} international conference on Functional Programming},
	publisher = {{ACM}},
	year = {2008},
	keywords = {dependent types, domain-specific embedded languages},
	pages = {39--50}
},

@article{parker_detection_1983,
	author = {{DS} Parker and {GJ} Popek and G Rudisin and A Stoughton and {BJ} Walker and E Walton and {JM} Chow and D Edwards and S Kiser and C Kline},
	title = {Detection of Mutual Inconsistency in Distributed Systems},
	volume = {{SE-9}},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1703051},
	abstract = {Many distributed systems are now being developed to provide users with convenient access to data via some kind of communications network. In many cases it is desirable to keep the system functioning even when it is partitioned by network failures. A serious problem in this context is how one can support redundant copies of resources such as files (for the sake of reliability) while simultaneously monitoring their mutual consistency (the equality of multiple copies). This is difficult since network faiures can lead to inconsistency, and disrupt attempts at maintaining consistency. In fact, even the detection of inconsistent copies is a nontrivial problem. Naive methods either 1) compare the multiple copies entirely or 2) perform simple tests which will diagnose some consistent copies as inconsistent. Here a new approach, involving version vectors and origin points, is presented and shown to detect single file, multiple copy mutual inconsistency effectively. The approach has been used in the design of {LOCUS,} a local network operating system at {UCLA.}},
	number = {3},
	journal = {Software Engineering, {IEEE} Transactions on},
	year = {1983},
	keywords = {vc},
	pages = {240--247}
},

@InProceedings{partee_compositionality_2007,
	author = {B. Partee},
	title = {{Compositionality and Coercion in Semantics: The Dynamics of Adjective Meaning}},
	booktitle = {Cognitive Foundations of Interpretation},
	year = {2007},
	publisher = {Royal Netherlands Academy of Arts and Sciences}
},

@InProceedings{partee_privative_2010,
	author = {B. Partee},
	title = {{Privative Adjectives: Subsective plus Coercion}},
	booktitle = {Presuppositions and Discourse: Essays Offered to Hans Kamp},
	year = {2010},
	editor = {R. Bauerle and U. Reyle and T. Zimmermann},
	publisher = {Emerald Group Publishing Ltd.},
	series = {Current Research in Semantics/Pragmatics Interface},
	volume = {21}
},

@inproceedings{pars_algebraic_2020,
	author = {Yves Parès and Jean-Philippe Bernardy and Richard A. Eisenberg},
	title = {Algebraic Effects with Tasks Build Composable Data Workflows},
	booktitle = {Proceedings of the Haskell Symposium},
	year = {2020}
},

@article{paterson_new_2001,
	author = {Ross Paterson},
	title = {A new notation for arrows},
	journal = {ACM SIGPLAN Notices},
	volume = {36},
	number = {10},
	pages = {229--240},
	year = {2001},
	publisher = {ACM New York, NY, USA}
},

@inproceedings{paulin-mohring_extracting_1989,
	author = {Christine Paulin-Mohring},
	file = {:/home/bernardy/Papers/Extracting F's programs from proofs in the calculus of constructions-1989.pdf:pdf},
	title = {Extracting {Fω}'s programs from proofs in the calculus of constructions},
	booktitle = {POPL '89: Proceedings of the 16th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
	year = {1989},
	isbn = {0-89791-294-2},
	pages = {89--104},
	location = {Austin, Texas, United States},
	doi = {http://doi.acm.org/10.1145/75277.75285},
	publisher = {ACM},
	COMMENTaddress = {New York, NY, USA}
},

@phdthesis{paulin-mohring_extraction_1989,
	author = {Christine Paulin-Mohring},
	file = {:/home/bernardy/Papers/Extraction de programmes dans le Calcul des Constructions-1989.ps:ps},
	title = {{Extraction de programmes dans le Calcul des Constructions}},
	year = {1989},
	school = {Université Paris 7}
},

@phdthesis{peng_programmable_????,
	author = {Li Peng},
	type = {{PhD} Thesis},
	title = {{PROGRAMMABLE} {CONCURRENCY} {IN} A {PURE} {AND} {LAZY}
{LANGUAGE}},
	url = {http://www.cis.upenn.edu/~lipeng/homepage/papers/dissertation.pdf},
	school = {University of Pennsylvania}
},

@inproceedings{pennings_using_1992,
	author = {Maarten Pennings and S. Doaitse Swierstra and Harald Vogt},
	title = {Using Cached Functions and Constructors for Incremental Attribute Evaluation},
	isbn = {3-540-55844-6},
	url = {http://portal.acm.org/citation.cfm?id=646448.756843&coll=ACM&dl=ACM&CFID=13026192&CFTOKEN=34892732},
	booktitle = {Proceedings of the 4th International Symposium on Programming Language Implementation and Logic Programming},
	publisher = {{Springer-Verlag}},
	year = {1992},
	pages = {130--144}
},

@inproceedings{pennington_glove_2014,
	author = {Jeffrey Pennington and Richard Socher and Christopher D Manning},
	added-at = {2016-02-18T12:02:38.000+0100},
	booktitle = {EMNLP},
	pages = {1532--1543},
	title = {Glove: Global Vectors for Word Representation},
	volume = {14},
	year = {2014}
},

@book{peters_quantifiers_2006,
	author = {Stanley Peters and Dag Westerst\aa{}hl},
	title = {Quantifiers in Language and Logic},
	publisher = {Oxford University Press UK},
	year = {2006}
},

@inproceedings{peters_dissecting_2018,
	author = {Matthew Peters and Mark Neumann and Luke Zettlemoyer and Wen-tau Yih},
	title = {Dissecting {{Contextual Word Embeddings}}: {{Architecture}} and {{Representation}}},
	booktitle = {Proceedings of the 2018 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
	year = {2018},
	pages = {1499--1509},
	address = {{Brussels, Belgium}},
	abstract = {Contextual word representations derived from pre-trained bidirectional language models (biLMs) have recently been shown to provide significant improvements to the state of the art for a wide range of NLP tasks. However, many questions remain as to how and why these models are so effective. In this paper, we present a detailed empirical study of how the choice of neural architecture (e.g. LSTM, CNN, or self attention) influences both end task accuracy and qualitative properties of the representations that are learned. We show there is a tradeoff between speed and accuracy, but all architectures learn high quality contextual representations that outperform word embeddings for four challenging NLP tasks. Additionally, all architectures learn representations that vary with network depth, from exclusively morphological based at the word embedding layer through local syntax based in the lower contextual layers to longer range semantics such coreference at the upper layers. Together, these results suggest that unsupervised biLMs, independent of architecture, are learning much more about the structure of language than previously appreciated.},
	language = {en}
},

@misc{peterson_yale_2001,
	author = {John Peterson and Zhanyong Wan and Paul Hudak and Henrik Nilsson},
	file = {:/home/bernardy/Papers/The Yale FRP User's Manual-2001.pdf:pdf},
	institution = {Yale University},
	title = {{The Yale FRP User's Manual}},
	year = {2001}
},

@inproceedings{petricek_coeffects_2014,
	author = {Tomas Petricek and Dominic A. Orchard and Alan Mycroft},
	title = {Coeffects: a calculus of context-dependent computation},
	booktitle = {Proceedings of the 19th {ACM} {SIGPLAN} international conference on
               Functional programming, Gothenburg, Sweden, September 1-3, 2014},
	pages = {123--135},
	year = {2014},
	crossref = {DBLP:conf/icfp/2014},
	url = {https://doi.org/10.1145/2628136.2628160},
	doi = {10.1145/2628136.2628160},
	timestamp = {Sun, 02 Jun 2019 21:13:12 +0200},
	biburl = {https://dblp.org/rec/conf/icfp/PetricekOM14.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@article{pfeifer_new_2013,
	author = {Niki Pfeifer},
	title = {The new psychology of reasoning: A mental probability logical perspective},
	journal = {Thinking \& Reasoning},
	volume = {19},
	number = {3-4},
	pages = {329-345},
	year = {2013},
	publisher = {Routledge},
	doi = {10.1080/13546783.2013.838189},
	URL = {https://doi.org/10.1080/13546783.2013.838189}
},

@InProceedings{pfeifer_probabilistic_2018,
	author = {Niki Pfeifer and Giuseppe Sanfilippo},
	editor = {Ciucci, Davide
	and Pasi, Gabriella
	and Vantaggi, Barbara},
	title = {Probabilistic Semantics for Categorical Syllogisms of Figure {II}},
	booktitle = {Scalable Uncertainty Management},
	year = {2018},
	publisher = {Springer International Publishing},
	pages = {196--211},
	isbn = {978-3-030-00461-3}
},

@incollection{pfenning_inductively_1990,
	author = {Frank Pfenning and Christine {Paulin-Mohring}},
	title = {Inductively defined types in the Calculus of Constructions},
	url = {http://dx.doi.org/10.1007/BFb0040259},
	abstract = {We define the notion of an inductively defined type in the Calculus of Constructions and show how inductively defined types can be represented by closed types. We show that
all primitive recursive functionals over these inductively defined types are also representable. This generalizes work by
Bhm \& Berarducci on synthesis of functions on term algebras in the second-order polymorphic λ-calculus {(F}
2). We give several applications of this generalization, including a representation of F
2-programs in F
3, along with a definition of functions reify, reflect, and eval for F
2 in F
3. We also show how to define induction over inductively defined types and sketch some results that show that the extension
of the Calculus of Construction by induction principles does not alter the set of functions in its computational fragment,
F
ω. This is because a proof by induction can be realized by primitive recursion, which is already definable in F
ω.},
	booktitle = {Mathematical Foundations of Programming Semantics},
	year = {1990},
	pages = {209--228},
	volume = {442},
	series = {Lecture Notes in Computer Science},
	publisher = {Springer}
},

@inproceedings{pfenning_structural_1995,
	author = {Frank Pfenning},
	title = {Structural cut elimination},
	booktitle = {Logic in Computer Science, Symposium on},
	pages = {156},
	year = {1995},
	organization = {IEEE Computer Society}
},

@article{pfenning_judgmental_2001,
	author = {Frank Pfenning and Rowan Davies},
	title = {A judgmental reconstruction of modal logic},
	journal = {Mathematical Structures in Computer Science},
	volume = {11},
	number = {4},
	pages = {511--540},
	year = {2001},
	url = {https://doi.org/10.1017/S0960129501003322},
	doi = {10.1017/S0960129501003322},
	timestamp = {Wed, 14 Nov 2018 10:35:18 +0100},
	biburl = {https://dblp.org/rec/bib/journals/mscs/PfenningD01},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@inproceedings{pfenning_intensionality_2001,
	author = {Frank Pfenning},
	file = {:/home/bernardy/Papers/Intensionality, extensionality, and proof irrelevance in modal type theory-????.pdf:pdf},
	booktitle = {Proceedings 16th Annual IEEE Symposium on Logic in Computer Science},
	doi = {10.1109/LICS.2001.932499},
	isbn = {0-7695-1281-X},
	pages = {221--230},
	publisher = {IEEE Computer Society},
	title = {Intensionality, extensionality, and proof irrelevance in modal type theory},
	year = {2001},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=932499}
},

@misc{pfenning_15-816_????,
	author = {Frank Pfenning},
	title = {15-816 Linear Logic / Schedule},
	url = {http://www.cs.cmu.edu/~fp/courses/linear/schedule.html},
	howpublished = {\url{http://www.cs.cmu.edu/~fp/courses/linear/schedule.html}}
},

@article{piantadosi_word_2011,
	author = {Steven Piantadosi and Harry Tily and Edward Gibson},
	year = {2011},
	month = {03},
	pages = {3526-9},
	title = {Word lengths are optimized for efficient communication},
	volume = {108},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	doi = {10.1073/pnas.1012551108}
},

@article{pickering_profunctor_2017,
	author = {Matthew Pickering and Jeremy Gibbons and Nicolas Wu},
	title = {Profunctor Optics: Modular Data Accessors},
	volume = {1},
	ISSN = {2473-7321},
	url = {http://dx.doi.org/10.22152/programming-journal.org/2017/1/7},
	DOI = {10.22152/programming-journal.org/2017/1/7},
	number = {2},
	journal = {The Art, Science, and Engineering of Programming},
	publisher = {Aspect-Oriented Software Association (AOSA)},
	year = {2017},
	month = {Apr}
},

@inproceedings{piementel_sigmorphon_2021,
	author = {Tiago Piementel and Maria Ryskina and Sabrina Mielke and Shiji Wu and Eleanor Chodroff and Brian Leonard and Garret Nicolai and Yustinus Ghanggo Ate and Salam Khalifa and Nizar Habash Charbel El-Khaissi and Omer Goldman and Michael Gasser and William Lane and Matt Coler and Arturo Oncevay and Jaime Rafael Montoya Samame and Gema Celeste Silva Villegas and Adam Ek and Jean-Philippe Bernardy and Andrey Shcherbakov and Aziyana Bayyr-ool and Karina Sheifer and Sofya Ganieva and Matvey Plugaryov and Elena Klyachko and Ali Salehi and Andrew Krizhanovsky and Natalia Krizhanovsky and Clara Vania and Sardana Ivanova and Aelita Salchak and Christopher Straughn and Zoey Liu and Jonathan North Washington and Duygu Ataman and Witold Kieras and Marcin Wolinski and Totok Suhardijanto and Niklas Stoehr and Zahroh Nuriah and Shyam Ratan and Francis M. Tyers and Edoardo M. Ponti and Richard J. Hatcher and Emily Prud'hommeaux and Ritesh Kumar and Mans Hulden and Botond Barta and Dorina Lakatos and Gábor Szolnok and Judit Ács and Mohit Raj and David Yarowsky and Ryan Cotterell and Ben Ambridge and Ekaterina Vylomova},
	title = {SIGMORPHON 2021 Shared Task on Morphological Reinflection: Generalization Across Languages},
	booktitle = {Proceedings of the 18th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology},
	year = {2021}
},

@book{pierce_basic_1991,
	author = {Benjamin C. Pierce},
	edition = {1},
	title = {Basic Category Theory for Computer Scientists},
	isbn = {0262660717},
	publisher = {The {MIT} Press},
	month = {aug},
	year = {1991}
},

@book{pierce_types_2002,
	author = {Benjamin C. Pierce},
	edition = {1},
	title = {Types and Programming Languages},
	isbn = {0-262-16209-1},
	publisher = {The {MIT} Press},
	year = {2002}
},

@inproceedings{pieters_handlers_2017,
	author = {Ruben P Pieters and Tom Schrijvers and Exequiel Rivas},
	title = {Handlers for non-monadic computations},
	booktitle = {Proceedings of the 29th Symposium on the Implementation and Application of Functional Programming Languages},
	pages = {1--11},
	year = {2017}
},

@inproceedings{pitts_polymorphism_1987,
	author = {A. Pitts},
	file = {:/home/bernardy/Papers/Polymorphism is set theoretic, constructively-1987.pdf:pdf;:/home/bernardy/Papers/Polymorphism is set theoretic, constructively-1987.pdf&rct=j&q=polymorphism%20is%20set%20theoretic%20constructively&ei=p-4aTrjIC8_2sgbnv_S4Dw&usg=AFQjCNGpEhX6AIW8oB2ucrL3wA8UpLMsmg&sig2=BwcbqqfvCIwB_JHH_TPeDA:pdf&rct=j&q=polymorphism%20is%20set%20theoretic%20constructively&ei=p-4aTrjIC8_2sgbnv_S4Dw&usg=AFQjCNGpEhX6AIW8oB2ucrL3wA8UpLMsmg&sig2=BwcbqqfvCIwB_JHH_TPeDA;:/home/bernardy/Papers/Polymorphism is set theoretic, constructively-1987.pdf&rct=j&q=polymorphism%20is%20set%20theoretic%20constructively&ei=p-4aTrjIC8_2sgbnv_S4Dw&usg=AFQjCNGpEhX6AIW8oB2ucrL3wA8UpLMsmg&sig2=BwcbqqfvCIwB_JHH_TPeDA:pdf&rct=j&q=polymorphism%20is%20set%20theoretic%20constructively&ei=p-4aTrjIC8_2sgbnv_S4Dw&usg=AFQjCNGpEhX6AIW8oB2ucrL3wA8UpLMsmg&sig2=BwcbqqfvCIwB_JHH_TPeDA},
	title = {Polymorphism is set theoretic, constructively},
	booktitle = {Category Theory and Computer Science},
	pages = {12--39},
	year = {1987},
	organization = {Springer}
},

@article{plaice_new_1993,
	author = {J Plaice and {WW} Wadge},
	title = {A new approach to version control},
	volume = {19},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=221137},
	abstract = {A method for controlling versions of software and other hierarchically structured entities is presented. Using the variant structure principle, a particular version of an entire system is formed by combining the most relevant existing versions of the various components of the system. An algebraic version language that allows histories (numbered series), subversions (or variants), and joins is described. It is shown that the join operation is simply the lattice least upper bound and together with the variant structure principle, provides a systematic framework for recombining divergent variants. The utility of this approach is demonstrated using {LEMUR,} a programming environment for modular C programs, which was developed using itself. The ways in which this notion of versions is related to the possible world semantics of intensional logic are discussed},
	number = {3},
	journal = {Software Engineering, {IEEE} Transactions on},
	year = {1993},
	keywords = {cm, vc},
	pages = {268--276},
	annote = {{\textless}p{\textgreater}ignores the problem of merging{\textless}/p{\textgreater}}
},

@article{plotkin_call-by-name_1975,
	author = {Gordon D. Plotkin},
	file = {:/home/bernardy/Papers/Call-by-name, call-by-value and the lamdba calculus-1975.pdf:pdf},
	journal = {Theoretical Computer Science},
	number = {2},
	pages = {125--129},
	title = {Call-by-name, call-by-value and the λ-calculus},
	volume = {1},
	year = {1975}
},

@inproceedings{plotkin_logic_1993,
	author = {Gordon Plotkin and Martín Abadi},
	file = {:/home/bernardy/Papers/A logic for parametric polymorphism-1993.pdf:pdf},
	title = {A logic for parametric polymorphism},
	volume = {664},
	booktitle = {Proceedings of the International Conference on Typed Lambda Calculi and Applications},
	series = {Lecture Notes in Computer Science},
	publisher = {Springer},
	year = {1993},
	pages = {361–375}
},

@article{plotkin_semantics_2001,
	author = {Gordon Plotkin and John Power},
	series = {{MFPS} 2001,{Seventeenth} {Conference} on the {Mathematical} {Foundations} of {Programming} {Semantics}},
	title = {Semantics for {Algebraic} {Operations}},
	volume = {45},
	issn = {1571-0661},
	url = {http://www.sciencedirect.com/science/article/pii/S1571066104809708},
	doi = {10.1016/S1571-0661(04)80970-8},
	abstract = {Given a category C with finite products and a strong monad T on C, we investigate axioms under which an ObC-indexed family of operations of the form αx:(Tx)n → Tx provides a definitive semantics for algebraic operations added to the computational λ-calculus. We recall a definition for which we have elsewhere given adequacy results for both big and small step operational semantics, and we show that it is equivalent to a range of other possible natural definitions of algebraic operation. We outline examples and non-examples and we show that our definition is equivalent to one for call-by-name languages with effects, too.},
	language = {en},
	urldate = {2020-10-27},
	journal = {Electronic Notes in Theoretical Computer Science},
	month = {nov},
	year = {2001},
	pages = {332--345}
},

@inproceedings{plotkin_handlers_2009,
	author = {Gordon Plotkin and Matija Pretnar},
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Handlers of Algebraic Effects},
	isbn = {978-3-642-00590-9},
	doi = {10.1007/978-3-642-00590-9_7},
	abstract = {We present an algebraic treatment of exception handlers and, more generally, introduce handlers for other computational effects representable by an algebraic theory. These include nondeterminism, interactive input/output, concurrency, state, time, and their combinations; in all cases the computation monad is the free-model monad of the theory. Each such handler corresponds to a model of the theory for the effects at hand. The handling construct, which applies a handler to a computation, is based on the one introduced by Benton and Kennedy, and is interpreted using the homomorphism induced by the universal property of the free model. This general construct can be used to describe previously unrelated concepts from both theory and practice.},
	language = {en},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer},
	editor = {Castagna, Giuseppe},
	year = {2009},
	keywords = {Algebraic Theory, Base Signature, Base Type, Function Symbol, Relation Symbol},
	pages = {80--94}
},

@article{plotkin_handling_2013,
	author = {Gordon D. Plotkin and Matija Pretnar},
	title = {Handling Algebraic Effects},
	journal = {Logical Methods in Computer Science},
	volume = {9},
	number = {4},
	year = {2013},
	url = {https://doi.org/10.2168/LMCS-9(4:23)2013},
	doi = {10.2168/LMCS-9(4:23)2013},
	timestamp = {Tue, 14 May 2019 16:31:14 +0200},
	biburl = {https://dblp.org/rec/bib/journals/corr/PlotkinP13},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@inproceedings{podkopaev_polynomial-time_2014,
	author = {Anton Podkopaev and Dmitri Boulytchev},
	title = {Polynomial-Time Optimal Pretty-Printing Combinators with Choice},
	booktitle = {Perspectives of System Informatics - 9th International Ershov Informatics
               Conference, {PSI} 2014, St. Petersburg, Russia, June 24-27, 2014.
               Revised Selected Papers},
	pages = {257--265},
	year = {2014},
	url = {https://doi.org/10.1007/978-3-662-46823-4_21},
	doi = {10.1007/978-3-662-46823-4_21},
	timestamp = {Sun, 21 May 2017 00:18:10 +0200},
	biburl = {http://dblp.uni-trier.de/rec/bib/conf/ershov/PodkopaevB14},
	bibsource = {dblp computer science bibliography, http://dblp.org}
},

@InProceedings{poesio_telescoping_1992,
	author = {Massimo Poesio and Alessandro Zucchi},
	title = {On Telescoping},
	booktitle = {SALT II - Proceedings from the Conference on Semantics and Linguistic Theory (Columbus, Ohio, May 1-3)},
	year = {1992},
	editor = {Chris Barker and David Dowty},
	pages = {347--366}
},

@article{polakow_relating_1999,
	author = {Jeff Polakow and Frank Pfenning},
	title = {Relating Natural Deduction and Sequent Calculus for Intuitionistic Non-Commutative Linear Logic },
	journal = {Electronic Notes in Theoretical Computer Science },
	volume = {20},
	number = {0},
	pages = {449 - 466},
	year = {1999},
	note = {<ce:title>MFPS XV, Mathematical Foundations of Progamming Semantics, Fifteenth Conference</ce:title> },
	issn = {1571-0661},
	doi = {http://dx.doi.org/10.1016/S1571-0661(04)80088-4},
	url = {http://www.sciencedirect.com/science/article/pii/S1571066104800884}
},

@article{pollack_recursive_1990,
	author = {Jordan B Pollack},
	title = {Recursive distributed representations},
	journal = {Artificial Intelligence},
	volume = {46},
	number = {1},
	pages = {77--105},
	year = {1990},
	publisher = {Elsevier}
},

@article{pottier_polymorphic_2006,
	author = {Francois Pottier and Nadji Gauthier},
	title = {Polymorphic typed defunctionalization and concretization},
	volume = {19},
	url = {http://portal.acm.org/citation.cfm?id=1145530},
	abstract = {Defunctionalization is a program transformation that eliminates functions as first-class values. We show that defunctionalization can be viewed as a type-preserving transformation of an extension of F with guarded algebraic data types into itself. We also suggest that defunctionalization is an instance of concretization, a more general technique that allows eliminating constructs other than functions. We illustrate this point by presenting two new type-preserving transformations that can be viewed as instances of concretization. One eliminates Rémy-style polymorphic records; the other eliminates the dictionary records introduced by the standard compilation scheme for Haskell's type classes.},
	number = {1},
	journal = {{Higher-Order} Symbol. Comput.},
	year = {2006},
	keywords = {closure conversion, concretization, defunctionalization, dictionary records, polymorphic records, polymorphism, type classes, type-preserving compilation},
	pages = {125--162}
},

@inproceedings{pottier_programming_2013,
	author = {François Pottier and Jonathan Protzenko},
	title = {Programming with permissions in {Mezzo}},
	booktitle = {Proceedings of the 2013 {ACM} {SIGPLAN} International
                 Conference on Functional Programming (ICFP'13)},
	month = {sep},
	year = {2013},
	pages = {173--184},
	pdf = {http://gallium.inria.fr/~fpottier/publis/pottier-protzenko-mezzo.pdf},
	longpdf = {http://gallium.inria.fr/~fpottier/publis/mezzo-icfp2013-long.pdf},
	off = {http://dx.doi.org/10.1145/2500365.2500598},
	abstract = {We present Mezzo, a typed programming language of ML
                 lineage. Mezzo is equipped with a novel static
                 discipline of duplicable and affine permissions, which
                 controls aliasing and ownership. This rules out certain
                 mistakes, including representation exposure and data
                 races, and enables new idioms, such as gradual
                 initialization, memory re-use, and (type)state changes.
                 Although the core static discipline disallows sharing a
                 mutable data structure, Mezzo offers several ways of
                 working around this restriction, including a novel
                 dynamic ownership control mechanism which we dub
                 ``adoption and abandon''.}
},

@inproceedings{pouillard_fresh_2010,
	author = {Nicolas Pouillard and François Pottier},
	file = {:/home/bernardy/Papers/A fresh look at programming with names and binders-2010.pdf:pdf},
	title = {A fresh look at programming with names and binders},
	booktitle = {Proceedings of the 15th {ACM} {SIGPLAN} international conference on Functional Programming},
	year = {2010},
	isbn = {978-1-60558-794-3},
	pages = {217--228},
	location = {Baltimore, Maryland, USA},
	doi = {http://doi.acm.org/10.1145/1863543.1863575},
	publisher = {ACM},
	address = {New York, NY, USA}
},

@inproceedings{pouillard_nameless_2011,
	author = {Nicolas Pouillard},
	file = {:/home/bernardy/Papers/Nameless, Painless-2011.pdf:pdf},
	title = {Nameless, Painless},
	booktitle = {Proceedings of the 16th {ACM} {SIGPLAN} international conference on Functional Programming},
	series = {ICFP '11},
	year = {2011},
	pages = {320--332},
	publisher = {ACM},
	address = {New York, NY, USA},
	note = {to appear}
},

@article{pouillard_unified_2012,
	author = {Nicolas Pouillard and François Pottier},
	file = {:/home/bernardy/Papers/A unified treatment of syntax with binders-2012.pdf:pdf},
	title = {A unified treatment of syntax with binders},
	journal = {Journal of Functional Programming},
	volume = {22},
	number = {4--5},
	pages = {614--704},
	year = {2012}
},

@book{prior_papers_2003,
	author = {Arthur N Prior and Per FV Hasle},
	title = {Papers on time and tense},
	year = {2003},
	publisher = {Oxford University Press on Demand}
},

@inproceedings{pucella_haskell_2008,
	author = {Riccardo Pucella and Jesse A. Tov},
	title = {Haskell session types with (almost) no class},
	booktitle = {Proceedings of the 1st {ACM} {SIGPLAN} Symposium on Haskell, Haskell
               2008, Victoria, BC, Canada, 25 September 2008},
	pages = {25--36},
	year = {2008},
	url = {http://doi.acm.org/10.1145/1411286.1411290},
	doi = {10.1145/1411286.1411290},
	timestamp = {Fri, 29 Jan 2010 14:44:59 +0100},
	biburl = {http://dblp.uni-trier.de/rec/bib/conf/haskell/PucellaT08},
	bibsource = {dblp computer science bibliography, http://dblp.org}
},

@inproceedings{puech_proofs_2013,
	author = {Matthias Puech},
	title = {Proofs, Upside Down - A Functional Correspondence between
               Natural Deduction and the Sequent Calculus},
	booktitle = {APLAS},
	year = {2013},
	pages = {365-380}
},

@MISC{pulman_second_2013,
	author = {S. Pulman},
	TITLE = {Second order inference in {NL} semantics},
	HOWPUBLISHED = {Talk given at the KCL Language and Cognition
                    seminar, London},
	YEAR = {2013},
	MONTH = {},
	NOTE = {},
	REVIEW = {}
},

@article{qian_modal_2016,
	author = {Sai Qian and Philippe de Groote and Maxime Amblard},
	title = {Modal Subordination in Type Theoretic Dynamic Logic},
	journal = {LiLT (Linguistic Issues in Language Technology)},
	volume = {14},
	year = {2016}
},

@article{radford_improving_2018,
	author = {Alec Radford and Karthik Narasimhan and Tim Salimans and Ilya Sutskever},
	title = {Improving language understanding by generative pre-training},
	journal = {URL https://s3-us-west-2. amazonaws. com/openai-assets/research-covers/languageunsupervised/language understanding paper. pdf},
	year = {2018}
},

@inproceedings{raina_robust_2005,
	author = {Rajat Raina and Andrew Y. Ng and Christopher D. Manning},
	address = {Pittsburgh, Pennsylvania},
	series = {{AAAI}'05},
	title = {Robust textual inference via learning and abductive reasoning},
	isbn = {978-1-57735-236-5},
	abstract = {We present a system for textual inference (the task of inferring whether a sentence follows from another text) that uses learning and a logical-formula semantic representation of the text. More precisely, our system begins by parsing and then transforming sentences into a logical formula-like representation similar to the one used by (Harabagiu et al., 2000). An abductive theorem prover then tries to find the minimum "cost" set of assumptions necessary to show that one statement follows from the other. These costs reflect how likely different assumptions are, and are learned automatically using information from syntactic/semantic features and from linguistic resources such as WordNet. If one sentence follows from the other given only highly plausible, low cost assumptions, then we conclude that it can be inferred. Our approach can be viewed as combining statistical machine learning and classical logical reasoning, in the hope of marrying the robustness and scalability of learning with the preciseness and elegance of logical theorem proving. We give experimental results from the recent PASCAL RTE 2005 challenge competition on recognizing textual inferences, where a system using this inference algorithm achieved the highest confidence weighted score.},
	urldate = {2021-03-02},
	booktitle = {Proceedings of the 20th national conference on {Artificial} intelligence - {Volume} 3},
	publisher = {AAAI Press},
	month = {jul},
	year = {2005},
	pages = {1099--1105}
},

@inproceedings{ramsey_algebraic_2001,
	author = {Norman Ramsey and Elöd Csirmaz},
	file = {:/home/bernardy/Papers/An algebraic approach to file synchronization-2001.pdf:pdf},
	title = {An algebraic approach to file synchronization},
	isbn = {0163-5948},
	doi = {10.1145/503271.503233},
	booktitle = {{ESEC/FSE-9:} Proceedings of the 8th European software engineering conference held jointly with 9th {ACM} {SIGSOFT} international symposium on Foundations of software engineering},
	publisher = {{ACM} Press},
	year = {2001},
	keywords = {synch, vc},
	pages = {175--185}
},

@Book{ranta_type-theoretical_1994,
	author = {Aarne Ranta},
	title = {Type-Theoretical Grammar},
	publisher = {Oxford University Press},
	year = {1994}
},

@article{ranta_grammatical_2004,
	author = {Aarne Ranta},
	title = {Grammatical Framework},
	volume = {14},
	number = {2},
	journal = {Journal of Functional Programming},
	publisher = {Cambridge University Press},
	year = {2004},
	pages = {145--189}
},

@book{ranta_grammatical_2011,
	author = {Aarne Ranta},
	title = {Grammatical {Framework}: Programming with multilingual grammars},
	year = {2011},
	isbn = {1-57586-626-9},
	url = {http://www.grammaticalframework.org/gf-book/},
	abstract = {Grammars of natural languages are complex systems, and their computer implementation requires both programming skills and linguistic knowledge, especially when dealing with other languages than English. This book makes such tasks accessible for a wide range of programmers. It introduces GF (Grammatical Framework), which is a programming language designed for writing grammars, which may moreover address several languages in parallel. The book shows how to write grammars in GF and use them in applications such as tourist phrasebooks, spoken dialogue systems, and natural language interfaces. The examples and exercises address several languages, and the readers are guided to look at their own languages from the computational perspective.

With an emphasis on good engineering, the book promotes modularity and division of labour - in particular, the use of libraries. It introduces the GF Resource Grammar Library, which currently addresses 16 languages. This number is constantly growing due to contributions from the international GF community. The library makes it painless to build applications and to port them to new languages. The book introduces a wide range of such applications, which run on platforms ranging from web servers to mobile phones. But the book also gives guidance for those readers who want to understand the underlying linguistics and implement resource grammars for new languages.

The book starts with a hands-on tutorial, continues with a selection of advanced topics, and ends with a complete reference manual of GF. Requiring very little background knowledge, it is accessible for second-year students that have experience with computers and an interest for languages. At the same time, its novel and advanced material makes it interesting for senior researchers in computer science, linguistics, and related fields.},
	publisher = {CSLI Publications}
},

@incollection{ratzinger_eq-mine_2007,
	author = {Jacek Ratzinger and Martin Pinzger and Harald Gall},
	title = {{EQ-Mine:} Predicting {Short-Term} Defects for Software Evolution},
	url = {http://dx.doi.org/10.1007/978-3-540-71289-3_3},
	abstract = {We use 63 features extracted from sources such as versioning and issue tracking systems to predict defects in short time frames of two months. Our multivariate approach covers aspects of software projects such as size, team structure, process orientation, complexity of existing solution, difficulty of problem, coupling aspects, time constrains, and testing data. We investigate the predictability of several severities of defects in software projects. Are defects with high severity difficult to predict? Are prediction models for defects that are discovered by internal staff similar to models for defects reported from the field? We present both an exact numerical prediction of future defect numbers based on regression models as well as a classification of software components as defect-prone based on the C4.5 decision tree. We create models to accurately predict short-term defects in a study of 5 applications composed of more than 8.000 classes and 700.000 lines of code. The model quality is assessed based on 10-fold cross validation.},
	booktitle = {Fundamental Approaches to Software Engineering},
	year = {2007},
	keywords = {evolution},
	pages = {12--26}
},

@inproceedings{reed_distance_2010,
	author = {Jason Reed and Benjamin C. Pierce},
	title = {Distance makes the types grow stronger: a calculus for differential
               privacy},
	booktitle = {Proceeding of the 15th {ACM} {SIGPLAN} international conference on
               Functional programming, {ICFP} 2010, Baltimore, Maryland, USA, September
               27-29, 2010},
	pages = {157--168},
	year = {2010},
	crossref = {DBLP:conf/icfp/2010},
	url = {https://doi.org/10.1145/1863543.1863568},
	doi = {10.1145/1863543.1863568},
	timestamp = {Tue, 06 Nov 2018 16:59:25 +0100},
	biburl = {https://dblp.org/rec/bib/conf/icfp/ReedP10},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@phdthesis{reinhart_syntactic_1976,
	author = {Tanya Miriam Reinhart},
	type = {Thesis},
	title = {The syntactic domain of anaphora},
	copyright = {M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.},
	url = {https://dspace.mit.edu/handle/1721.1/16400},
	abstract = {Thesis. 1976. Ph.D.--Massachusetts Institute of Technology. Dept. of Foreign Literatures and Linguistics.},
	language = {eng},
	urldate = {2021-03-06},
	school = {Massachusetts Institute of Technology},
	year = {1976},
	note = {Accepted: 2005-08-02T20:38:55Z}
},

@InProceedings{retore_montagovian_2013,
	author = {C. Retor{\'e}},
	title = {The Montagovian Generative Lexicon {T}yn: a Type Theoretical Framework for Natural Language Semantics},
	booktitle = {Proc of TYPES2013},
	editor = {R. Matthes and A. Schubert },
	year = {2013},
	OPTeditor = {},
	OPTpublisher = {},
	OPTisbn = {},
	OPTseries = {},
	OPTpages = {},
	OPTvolume = {}
},

@conference{reynolds_theory_1974,
	author = {John C. Reynolds},
	file = {:/home/bernardy/Papers/Towards a theory of type structure-1974.pdf:pdf},
	title = {Towards a theory of type structure},
	booktitle = {Colloque sur la Programmation},
	pages = {408--425},
	year = {1974},
	organization = {Springer}
},

@article{reynolds_types_1983,
	author = {John C. Reynolds},
	file = {:/home/bernardy/Papers/Types, abstraction and parametric polymorphism-1983.pdf:pdf},
	title = {Types, abstraction and parametric polymorphism},
	volume = {83},
	number = {1},
	journal = {Information processing},
	year = {1983},
	pages = {513--523},
	see = {part2:ma_types_1992}
},

@article{reynolds_definitional_1998,
	author = {John C. Reynolds},
	title = {Definitional Interpreters for {Higher-Order} Programming Languages},
	volume = {11},
	url = {http://portal.acm.org/citation.cfm?id=609184},
	abstract = {Higher-order programming languages (i.e., languages in which procedures or labels can occur as values) are usually defined by interpreters that are themselves written in a programming language based on the lambda calculus (i.e., an applicative language such as pure {LISP).} Examples include {McCarthy‘s} definition of {LISP,} Landin‘s {SECD} machine, the Vienna definition of {PL/I,} Reynolds‘ definitions of {GEDANKEN,} and recent unpublished work by L. Morris and C. Wadsworth. Such definitions can be classified according to whether the interpreter contains higher-order functions, and whether the order of application (i.e., call by value versus call by name) in the defined language depends upon the order of application in the defining language. As an example, we consider the definition of a simple applicative programming language by means of an interpreter written in a similar language. Definitions in each of the above classifications are derived from one another by informal but constructive methods. The treatment of imperative features such as jumps and assignment is also discussed.},
	number = {4},
	journal = {Higher-Order and Symbolic Computation},
	year = {1998},
	keywords = {applicative language, closure, continuation, gedanken, higher-order function, interpreter, j-operator, lambda calculus, language definition, lisp, order of application, pal, programming language, reference, secd machine},
	pages = {363--397}
},

@article{rhiger_type-safe_????,
	author = {Morten Rhiger},
	file = {:/home/bernardy/Papers/Type-safe pattern combinators-????.pdf:pdf},
	title = {Type-safe pattern combinators},
	url = {http://www.itu.dk/people/mir/typesafepatterns.pdf},
	journal = {Journal of Functional Programming},
	keywords = {open}
},

@inproceedings{ridge_simple_2014,
	author = {Tom Ridge},
	title = {Simple, Efficient, Sound and Complete Combinator Parsing for All Context-Free Grammars, Using an Oracle},
	booktitle = {Software Language Engineering - 7th International Conference, {SLE}
               2014, V{\"{a}}ster{\aa}s, Sweden, September 15-16, 2014. Proceedings},
	pages = {261--281},
	year = {2014},
	url = {http://dx.doi.org/10.1007/978-3-319-11245-9_15},
	doi = {10.1007/978-3-319-11245-9_15},
	timestamp = {Tue, 09 Sep 2014 10:57:11 +0200},
	biburl = {http://dblp.uni-trier.de/rec/bib/conf/sle/Ridge14},
	bibsource = {dblp computer science bibliography, http://dblp.org}
},

@article{rivas_notions_2014,
	author = {Exequiel Rivas and Mauro Jaskelioff},
	title = {Notions of Computation as Monoids},
	journal = {CoRR},
	volume = {abs/1406.4823},
	year = {2014},
	url = {http://arxiv.org/abs/1406.4823},
	archivePrefix = {arXiv},
	eprint = {1406.4823},
	timestamp = {Mon, 13 Aug 2018 16:48:44 +0200},
	biburl = {https://dblp.org/rec/journals/corr/RivasJ14.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@article{robbes_change-based_2007,
	author = {Romain Robbes and Michele Lanza},
	file = {:/home/bernardy/Papers/A Change-based Approach to Software Evolution-2007.pdf:pdf},
	title = {A Change-based Approach to Software Evolution},
	volume = {166},
	url = {http://dx.doi.org/10.1016/j.entcs.2006.06.015},
	abstract = {Software evolution research is limited by the amount of information available to researchers: Current version control tools do not store all the information generated by developers. They do not record every intermediate version of the system issued, but only snapshots taken when a developer commits source code into the repository. Additionally, most software evolution analysis tools are not a part of the day-to-day programming activities, because analysis tools are resource intensive and not integrated in development environments. We propose to model development information as change operations that we retrieve directly from the programming environment the developers are using, while they are effecting changes to the system. This accurate and incremental information opens new ways for both developers and researchers to explore and evolve complex systems.},
	journal = {Electronic Notes in Theoretical Computer Science},
	month = {jan},
	year = {2007},
	keywords = {evolution},
	pages = {93--109}
},

@incollection{robbes_approach_2007,
	author = {Romain Robbes and Michele Lanza and Mircea Lungu},
	title = {An Approach to Software Evolution Based on Semantic Change},
	url = {http://dx.doi.org/10.1007/978-3-540-71289-3_4},
	abstract = {The analysis of the evolution of software systems is a useful source of information for a variety of activities, such as reverse engineering, maintenance, and predicting the future evolution of these systems. Current software evolution research is mainly based on the information contained in versioning systems such as {CVS} and {SubVersion.} But the evolutionary information contained therein is incomplete and of low quality, hence limiting the scope of evolution research. It is incomplete because the historical information is only recorded at the explicit request of the developers (a commit in the classical checkin/checkout model). It is of low quality because the file-based nature of versioning systems leads to a view of software as being a set of files. In this paper we present a novel approach to software evolution analysis which is based on the recording of all semantic changes performed on a system, such as refactorings. We describe our approach in detail, and demonstrate how it can be used to perform fine-grained software evolution analysis.},
	booktitle = {Fundamental Approaches to Software Engineering},
	year = {2007},
	keywords = {evolution},
	pages = {27--41}
},

@book{roberts_modal_1987,
	author = {Craige Roberts},
	title = {Modal Subordination, Anaphora, and Distributivity},
	year = {1987},
	school = {University of Massachusetts Amherst},
	url = {https://www.asc.ohio-state.edu/roberts.21/dissertation.pdf}
},

@article{roberts_modal_1989,
	author = {Craige Roberts},
	publisher = {Springer},
	pages = {683--721},
	number = {6},
	doi = {10.1007/BF00632602},
	journal = {Linguistics and Philosophy},
	year = {1989},
	title = {Modal Subordination and Pronominal Anaphora in Discourse},
	volume = {12}
},

@article{roberts_general_2004,
	author = {Gareth O. Roberts and Jeffrey S. Rosenthal},
	doi = {10.1214/154957804100000024},
	fjournal = {Probability Surveys},
	journal = {Probab. Surveys},
	pages = {20--71},
	publisher = {The Institute of Mathematical Statistics and the Bernoulli Society},
	title = {General state space Markov chains and MCMC algorithms},
	url = {https://doi.org/10.1214/154957804100000024},
	volume = {1},
	year = {2004}
},

@misc{robertson_fontspec_2010,
	author = {Will Robertson and Khaled Hosny},
	file = {:/home/bernardy/Papers/The fontspec package-2010.pdf:pdf},
	title = {{The fontspec package}},
	year = {2010}
},

@inproceedings{rodriguez_comparing_2008,
	author = {Alexey Rodriguez and Johan Jeuring and Patrik Jansson and Alex Gerdes and Oleg Kiselyov and Bruno C. d. S. Oliveira},
	address = {Victoria, {BC,} Canada},
	title = {Comparing libraries for generic programming in haskell},
	isbn = {978-1-60558-064-7},
	url = {http://portal.acm.org/citation.cfm?id=1411286.1411301},
	doi = {10.1145/1411286.1411301},
	abstract = {Datatype-generic programming is defining functions that depend on the structure, or "shape", of datatypes. It has been around for more than 10 years, and a lot of progress has been made, in particular in the lazy functional programming language Haskell. There are more than 10 proposals for generic programming libraries orlanguage extensions for Haskell. To compare and characterise the many generic programming libraries in atyped functional language, we introduce a set of criteria and develop a generic programming benchmark: a set of characteristic examples testing various facets of datatype-generic programming. We have implemented the benchmark for nine existing Haskell generic programming libraries and present the evaluation of the libraries. The comparison is useful for reaching a common standard for generic programming, but also for a programmer who has to choose a particular approach for datatype-generic programming.},
	booktitle = {Proceedings of the first {ACM} {SIGPLAN} symposium on Haskell},
	publisher = {{ACM}},
	year = {2008},
	keywords = {datatype-generic programming, libraries comparison},
	pages = {111--122},
	see = {:hinze_generic_2009;:sheard_generic_2007}
},

@techreport{rodriguez_generic_????,
	author = {Alexey Rodriguez and Stefan Holdermans and Andres Löh and Johan Jeuring},
	title = {Generic programming with fixed points for mutually recursive datatypes},
	number = {{UU-CS-2008-019}},
	institution = {Utrecht University},
	keywords = {multirec}
},

@InProceedings{romano_investigating_2006,
	author = {L. Romano and M. Kuylekov and I. Szpektor and I. Dagan and A. Lavelli},
	title = {Investigating a generic paraphrase-based approach for relation extraction.},
	booktitle = {Proceedings of EACL 2006.},
	year = {2006},
	pages = {409-416},
	OPTorganization = {},
	OPTpublisher = {},
	OPTaddress = {},
	OPTmonth = {},
	OPTnote = {}
},

@inproceedings{rountev_off-line_2000,
	author = {Atanas Rountev and Satish Chandra},
	title = {Off-line variable substitution for scaling points-to analysis},
	booktitle = {{PLDI} '00: Proceedings of the {ACM} {SIGPLAN} 2000 conference on Programming language design and implementation},
	publisher = {{ACM}},
	year = {2000},
	keywords = {points-to},
	pages = {47--56}
},

@techreport{rountev_practical_2000,
	author = {A Rountev and B Ryder},
	title = {Practical points-to analysis for programs built with libraries},
	url = {#},
	year = {2000},
	keywords = {points-to}
},

@incollection{ruffell_pervasiveness_2006,
	author = {Fraser Ruffell and Jason Selby},
	title = {The Pervasiveness of Global Data in Evolving Software Systems},
	url = {http://dx.doi.org/10.1007/11693017_30},
	abstract = {In this research, we investigate the role of common coupling in evolving software systems. It can be argued that most software developers understand that the use of global data has many harmful side-effects, and thus should be avoided. We are therefore interested in the answer to the following question: if global data does exist within a software project, how does global data usage evolve over a software projectâs lifetime? Perhaps the constant refactoring and perfective maintenance eliminates global data usage, or conversely, perhaps the constant addition of features and rapid development introduce an increasing reliance on global data? We are also interested in identifying if global data usage patterns are useful as a software metric that is indicative of an interesting or significant event in the softwareâs lifetime.},
	booktitle = {Fundamental Approaches to Software Engineering},
	year = {2006},
	keywords = {coupling, evolution},
	pages = {396--410}
},

@inproceedings{runciman_smallcheck_2008,
	author = {Colin Runciman and Matthew Naylor and Fredrik Lindblad},
	address = {Victoria, {BC,} Canada},
	title = {Smallcheck and lazy smallcheck: automatic exhaustive testing for small values},
	isbn = {978-1-60558-064-7},
	shorttitle = {Smallcheck and lazy smallcheck},
	url = {http://portal.acm.org/citation.cfm?id=1411292},
	doi = {10.1145/1411286.1411292},
	abstract = {This paper describes two Haskell libraries for property-based testing. Following the lead of {QuickCheck,} these testing libraries {SmallCheck} and Lazy {SmallCheck} also use type-based generators to obtain test-sets of finite values for which properties are checked, and report any counter-examples found. But instead of using a sample of randomly generated values they test properties for all values up to some limiting depth, progressively increasing this limit. The paper explains the design and implementation of both libraries and evaluates them in comparison with each other and with {QuickCheck.}},
	booktitle = {Proceedings of the first {ACM} {SIGPLAN} symposium on Haskell},
	publisher = {{ACM}},
	year = {2008},
	keywords = {embedded language, exhaustive search, lazy evaluation, property-based testing, type classes},
	pages = {37--48}
},

@article{rytter_optimal_1987,
	author = {Wojciech Rytter and Raffaele Giancarlo},
	title = {Optimal parallel parsing of bracket languages},
	journal = {Theoretical computer science},
	volume = {53},
	number = {2},
	pages = {295--306},
	year = {1987},
	publisher = {Elsevier}
},

@inproceedings{saedi_wordnet_2018,
	author = {Chakaveh Saedi and Ant{\'{o}}nio Branco and Jo{\~{a}}o Ant{\'{o}}nio Rodrigues and Jo{\~{a}}o Silva},
	title = {WordNet Embeddings},
	booktitle = {Rep4NLP@ACL},
	pages = {122--131},
	publisher = {Association for Computational Linguistics},
	year = {2018}
},

@inproceedings{saff_theory-infected_2007,
	author = {David Saff},
	address = {Montreal, Quebec, Canada},
	title = {Theory-infected: or how i learned to stop worrying and love universal quantification},
	isbn = {978-1-59593-865-7},
	shorttitle = {Theory-infected},
	url = {http://portal.acm.org/citation.cfm?id=1297919},
	doi = {10.1145/1297846.1297919},
	abstract = {Writing developer tests as software is built can provide peace of mind. As the software grows, running the tests can prove that everything still works as the developer envisioned it. But what about the behavior the developer failed to envision? Although verifying a few well-picked scenarios is often enough, experienced developers know bugs can often lurk even in well-tested code, when correct but untested inputs provoke obviously wrong responses. This leads to worry.},
	booktitle = {Companion to the 22nd {ACM} {SIGPLAN} conference on Object-oriented programming systems and applications companion},
	publisher = {{ACM}},
	year = {2007},
	keywords = {junit, partial specification, testing, theories},
	pages = {846--847}
},

@InProceedings{sala_representation_2018,
	author = {Frederic Sala and Chris De Sa and Albert Gu and Christopher Re},
	title = {Representation Tradeoffs for Hyperbolic Embeddings},
	booktitle = {Proceedings of the 35th International Conference on Machine Learning},
	pages = {4460--4469},
	year = {2018},
	editor = {Dy, Jennifer and Krause, Andreas},
	volume = {80},
	series = {Proceedings of Machine Learning Research},
	address = {Stockholmsmässan, Stockholm Sweden},
	month = {10--15 Jul},
	publisher = {PMLR},
	abstract = {Hyperbolic embeddings offer excellent quality with few dimensions when embedding hierarchical data structures. We give a combinatorial construction that embeds trees into hyperbolic space with arbitrarily low distortion without optimization. On WordNet, this algorithm obtains a mean-average-precision of 0.989 with only two dimensions, outperforming existing work by 0.11 points. We provide bounds characterizing the precision-dimensionality tradeoff inherent in any hyperbolic embedding. To embed general metric spaces, we propose a hyperbolic generalization of multidimensional scaling (h-MDS). We show how to perform exact recovery of hyperbolic points from distances, provide a perturbation analysis, and give a recovery result that enables us to reduce dimensionality. Finally, we extract lessons from the algorithms and theory above to design a scalable PyTorch-based implementation that can handle incomplete information.}
},

@article{sanfilippo_probabilistic_2018,
	author = {Giuseppe Sanfilippo and Niki Pfeifer and David E. Over and Angelo Gilio},
	title = {Probabilistic inferences from conjoined to iterated conditionals},
	journal = {International Journal of Approximate Reasoning},
	volume = {93},
	pages = {103 - 118},
	year = {2018},
	issn = {0888-613X},
	doi = {https://doi.org/10.1016/j.ijar.2017.10.027}
},

@inproceedings{santos_type_2020,
	author = {Armando Santos and Jos{\'{e}} N. Oliveira},
	editor = {Tom Schrijvers},
	title = {Type your matrices for great good: a Haskell library of typed matrices
               and applications (functional pearl)},
	booktitle = {Proceedings of the 13th {ACM} {SIGPLAN} International Symposium on
               Haskell, Haskell@ICFP 2020, Virtual Event, USA, August 7, 2020},
	pages = {54--66},
	publisher = {{ACM}},
	year = {2020},
	url = {https://doi.org/10.1145/3406088.3409019},
	doi = {10.1145/3406088.3409019},
	timestamp = {Sun, 25 Oct 2020 23:03:01 +0100},
	biburl = {https://dblp.org/rec/conf/haskell/SantosO20.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@inproceedings{saraiva_functional_2000,
	author = {João Saraiva and S. Doaitse Swierstra and Matthijs F. Kuiper},
	title = {Functional Incremental Attribute Evaluation},
	isbn = {{3-540-67263-X}},
	url = {http://portal.acm.org/citation.cfm?id=647476.727632&coll=ACM&dl=ACM&CFID=13026192&CFTOKEN=34892732},
	booktitle = {Proceedings of the 9th International Conference on Compiler Construction},
	publisher = {{Springer-Verlag}},
	year = {2000},
	pages = {279--294}
},

@misc{schrijvers_open_2007,
	author = {Tom Schrijvers and Martin Sulzmann and Simon {Peyton Jones} and Manuel Chakravarty},
	title = {Towards open type functions for Haskell},
	abstract = {We report on an extension of Haskell with type(-level) functions and equality constraints. We illustrate their usefulness in the context of phantom types, {GADTs} and type classes. Problems in the context of type checking are identified and we sketch our solution: a decidable type checking algorithm for a restricted class of type functions. Moreover, functional dependencies are now obsolete: we show how they can be encoded as type functions.},
	journal = {Implementing Functional Languages},
	year = {2007},
	keywords = {open, typeclass},
	howpublished = {\url{}}
},

@inproceedings{schrijvers_type_2008,
	author = {Tom Schrijvers and Simon {Peyton Jones} and Manuel Chakravarty and Martin Sulzmann},
	address = {Victoria, {BC,} Canada},
	title = {Type checking with open type functions},
	isbn = {978-1-59593-919-7},
	url = {http://portal.acm.org/citation.cfm?id=1411204.1411215},
	doi = {10.1145/1411204.1411215},
	abstract = {We report on an extension of Haskell with open type-level functions and equality constraints that unifies earlier work on {GADTs,} functional dependencies, and associated types. The contribution of the paper is that we identify and characterise the key technical challenge of entailment checking; and we give a novel, decidable, sound, and complete algorithm to solve it, together with some practically-important variants. Our system is implemented in {GHC,} and is already in active use.},
	booktitle = {Proceedings of the 13th {ACM} {SIGPLAN} international conference on Functional Programming},
	publisher = {{ACM}},
	year = {2008},
	keywords = {haskell, type checking, type families, type functions},
	pages = {51--62}
},

@article{schrijvers_monadic_2009,
	author = {Tom Schrijvers and Peter Stuckey and Philip Wadler},
	title = {Monadic constraint programming},
	journal = {Journal of Functional Programming},
	pages = {1--35},
	year = {2009},
	publisher = {Cambridge Univ Press},
	volume = {19},
	issue = {06}
},

@inproceedings{scott_relating_1980,
	author = {Dana Scott},
	file = {:/home/bernardy/Papers/Relating theories of the lambda calculus-1980.pdf:pdf},
	booktitle = {Curry Festschreift: Essays in Combinatory Logic, Lambda Calculus},
	title = {{Relating theories of the lambda calculus}},
	url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Relating+Theories+of+the+lambda+calculus\#0},
	year = {1980}
},

@unpublished{seidel_proving_2010,
	author = {Daniel Seidel and Janis Voigtl\"{a}nder},
	file = {:/home/bernardy/Papers/Proving Properties About Functions on Lists Involving Element Tests-2010.pdf:pdf},
	title = {{Proving Properties About Functions on Lists Involving Element Tests}},
	year = {2010}
},

@inproceedings{sennhauser_evaluating_2018,
	author = {Luzi Sennhauser and Robert C. Berwick},
	title = {Evaluating the ability of {LSTMs} to learn context-free grammars},
	journal = {Proceedings of the 2018 {EMNLP} Workshop {BlackboxNLP}},
	citations = {37 in 2021},
	year = {2018}
},

@article{shalyminov_challenging_2017,
	author = {Igor Shalyminov and Arash Eshghi and Oliver Lemon},
	title = {Challenging Neural Dialogue Models with Natural Data: Memory Networks Fail on Incremental Phenomena},
	journal = {arXiv preprint arXiv:1709.07840},
	year = {2017}
},

@article{shan_monads_2002,
	author = {Chung{-}chieh Shan},
	title = {Monads for natural language semantics},
	journal = {CoRR},
	volume = {cs.CL/0205026},
	year = {2002},
	url = {http://arxiv.org/abs/cs.CL/0205026}
},

@inproceedings{shan_exact_2017,
	author = {Chung-chieh Shan and Norman Ramsey},
	title = {Exact Bayesian Inference by Symbolic Disintegration},
	booktitle = {Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages},
	series = {POPL},
	year = {2017},
	location = {Paris, France},
	pages = {130--144}
},

@inproceedings{sheard_template_2002,
	author = {Tim Sheard and Simon {Peyton Jones}},
	title = {Template meta-programming for Haskell},
	booktitle = {Proceedings of the 2002 ACM SIGPLAN workshop on Haskell},
	series = {Haskell '02},
	year = {2002},
	isbn = {1-58113-605-6},
	location = {Pittsburgh, Pennsylvania},
	pages = {1--16},
	numpages = {16},
	url = {http://doi.acm.org/10.1145/581690.581691},
	doi = {http://doi.acm.org/10.1145/581690.581691},
	acmid = {581691},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {meta programming, templates}
},

@incollection{sheard_generic_2007,
	author = {Tim Sheard},
	title = {Generic Programming in Ωmega},
	volume = {Volume 4719/2007},
	url = {http://dx.doi.org/10.1007/978-3-540-76786-2_5},
	abstract = {Generic programming is about making programs more adaptable by making them more general. Generic programs often embody non-traditional kinds of abstraction; ordinary programs are obtained from them by suitably instantiating their parameters. In contrast with normal programs, the parameters of a generic program are often quite rich in structure; for example they may be other programs, types or type constructors, class hierarchies, or even programming paradigms.},
	booktitle = {{Datatype-Generic} Programming},
	year = {2007},
	keywords = {wgp08},
	pages = {258--284},
	see = {:hinze_generic_2009}
},

@article{sheeran_hardware_2005,
	author = {Mary Sheeran},
	title = {Hardware Design and Functional Programming: a Perfect Match},
	volume = {11},
	abstract = {This paper aims to explain why I am still fascinated by the use of functional languages in hardware design. I hope that some readers will be tempted to tackle some of the hard problems that I outline in the final section. In particular, I believe that programming language researchers have much to contribute to the field of hardware design.},
	number = {7},
	journal = {Journal of Universal Computer Science},
	year = {2005},
	note = {{\textbar}http://www.jucs.org/jucs\_11\_7/hardware\_design\_and\_functional{\textbar}},
	pages = {1135–1158}
},

@misc{sheeran_searching_2007,
	author = {Mary Sheeran},
	type = {talk},
	title = {Searching for prefix networks to fit in a context using a lazy functional programming language},
	year = {2007}
},

@phdthesis{shelley_understanding_2011,
	author = {Lewis Karen Shelley},
	title = {Understanding dynamic discourse},
	institution = {Rutgers, The State University of New Jersey},
	year = {2011},
	type = {{Ph.D. Thesis}}
},

@inproceedings{shi_linear_2009,
	author = {R. Shi and H. Xi},
	title = {A linear type system for multicore programming},
	booktitle = {Proceedings of Simposio Brasileiro de Linguagens de Programacao, Gramado, Brazil (August 2009)},
	year = {2009}
},

@inproceedings{shinwell_freshml_2003,
	author = {Mark R Shinwell and Andrew M Pitts and Murdoch J Gabbay},
	title = {FreshML: Programming with binders made simple},
	booktitle = {Proceedings of the eighth {ACM} {SIGPLAN} international conference on Functional Programming},
	pages = {263--274},
	year = {2003},
	organization = {ACM}
},

@article{shulman_brouwers_2018,
	author = {Michael Shulman},
	title = {Brouwer's fixed-point theorem in real-cohesive homotopy type theory},
	journal = {Mathematical Structures in Computer Science},
	volume = {28},
	number = {6},
	pages = {856--941},
	year = {2018},
	url = {https://doi.org/10.1017/S0960129517000147},
	doi = {10.1017/S0960129517000147},
	timestamp = {Fri, 08 Jun 2018 15:43:35 +0200},
	biburl = {https://dblp.org/rec/bib/journals/mscs/Shulman18},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@inproceedings{siek_essential_2005,
	author = {Jeremy Siek and Andrew Lumsdaine},
	address = {Chicago, {{IL},} {{USA}}},
	title = {Essential Language Support for Generic Programming},
	url = {http://dx.doi.org/http://doi.acm.org/10.1145/1065010.1065021},
	booktitle = {{{PLDI}} '05: Proceedings of the {{ACM}} {{SIGPLAN}} 2005 conference on Programming language design and implementation},
	publisher = {{{ACM}} Press},
	year = {2005},
	keywords = {concept, file-import-08-06-27},
	pages = {73--84}
},

@inbook{sikkel_parsing_1997,
	author = {Klaas Sikkel and Anton Nijholt},
	title = {Parsing of context-free languages},
	booktitle = {The Handbook of Formal Languages, volume II},
	pages = {61--100},
	year = {1997},
	editor = {G. Rozenberg and A. Salomaa},
	publisher = {Springer-Verlag}
},

@phdthesis{siles_investigation_2010,
	author = {Vincent Siles},
	title = {Investigation on the typing of equality in type systems},
	year = {2010},
	type = {PhD Thesis},
	school = {École Polytechnique}
},

@article{siles_pure_2012,
	author = {Vincent Siles and Hugo Herbelin},
	title = {Pure Type System conversion is always typable},
	journal = {Journal of Functional Programmming},
	volume = {22},
	number = {2},
	year = {2012},
	pages = {153-180},
	ee = {http://journals.cambridge.org/action/displayAbstract?aid=8573390},
	bibsource = {DBLP, http://dblp.uni-trier.de}
},

@article{smith_derivation_1993,
	author = {D. Smith},
	title = {Derivation of parallel sorting algorithms},
	journal = {Parallel algorithm derivation and program transformation},
	pages = {55--69},
	year = {1993},
	publisher = {Springer}
},

@unpublished{smith_galois_????,
	author = {Peter Smith},
	title = {The Galois Connection between syntax and semantics}
},

@misc{snoyman_conduit_2015,
	author = {Michael Snoyman},
	title = {The conduit package},
	url = {http://www.stackage.org/package/conduit},
	year = {2015}
},

@incollection{sowrirajan_managing_2003,
	author = {Sundararajan Sowrirajan and Andre Hoek},
	title = {Managing the Evolution of Distributed and Interrelated Components},
	url = {http://www.springerlink.com/content/pkjprnpx6ffk30ud},
	abstract = {Software systems are increasingly being built by integrating pre-existing components developed by different, geographically distributed organizations. Each component typically evolves independently over time, not only in terms of its functionality, but also in terms of its exposed interfaces and dependencies on other components. Given that those other components may also evolve, creating an application by assembling sets of components typically involves managing a complex web of evolving dependencies. Traditional configuration management systems assume a form of centralized control that simply does not suffice in these situations. Needed are new configuration management systems that span multiple organizations, operate in a distributed and decentralized fashion, and help in managing the consistent evolution of independently developed, inter-related sets of components. A critical aspect of these new configuration management systems is that they must respect the different levels of autonomy, privacy, and trust that exist among different organizations. In this paper, we introduce {TWICS,} an early example of such a new configuration management system. Key aspects of {TWICS} are that it maintains traditional configuration management functionality to support the development of individual components, but integrates policy-driven deployment functionality to support different organizations in evolving their inter-related components.},
	booktitle = {Software Configuration Management},
	year = {2003},
	keywords = {evolution},
	pages = {217--230}
},

@incollection{sozeau_first-class_2008,
	author = {Matthieu Sozeau and Nicolas Oury},
	title = {{First-Class} Type Classes},
	url = {http://dx.doi.org/10.1007/978-3-540-71067-7_23},
	abstract = {Type Classes have met a large success in Haskell and Isabelle, as a solution for sharing notations by overloading and for specifying with abstract structures by quantification on contexts.
However, both systems are limited by second-class implementations of these constructs, and these limitations are only overcomed
by ad-hoc extensions to the respective systems. We propose an embedding of type classes into a dependent type theory that
is first-class and supports some of the most popular extensions right away. The implementation is correspondingly cheap, general
and integrates well inside the system, as we have experimented in Coq. We show how it can be used to help structured programming
and proving by way of examples.},
	booktitle = {Theorem Proving in Higher Order Logics},
	year = {2008},
	pages = {278--293}
},

@article{stalnaker_common_2002,
	author = {Robert Stalnaker},
	title = {Common {{Ground}}},
	year = {2002},
	volume = {25},
	pages = {701--721},
	journal = {Linguistics and Philosophy},
	number = {5-6}
},

@article{staples_combinator_1973,
	author = {John Staples},
	title = {Combinator realizability of constructive finite type analysis},
	journal = {Cambridge Summer School in Mathematical Logic},
	pages = {253--273},
	year = {1973},
	publisher = {Springer}
},

@article{steedman_productions_2000,
	author = {Mark Steedman},
	title = {The productions of time},
	journal = {Draft. Available at http://www. cogsci. ed. ac. uk/steedman/papers. html},
	year = {2000}
},

@inproceedings{steuwer_lift_2017,
	author = {Michel Steuwer and Toomas Remmelg and Christophe Dubach},
	title = {Lift: a functional data-parallel IR for high-performance GPU code generation},
	booktitle = {Code Generation and Optimization (CGO), 2017 IEEE/ACM International Symposium on},
	pages = {74--85},
	year = {2017},
	organization = {IEEE}
},

@inproceedings{stewart_dynamic_2005,
	author = {Don Stewart and Manuel Chakravarty},
	title = {Dynamic applications from the ground up},
	isbn = {{159593071X}},
	url = {http://dx.doi.org/10.1145/1088348.1088352},
	booktitle = {Haskell '05: Proceedings of the 2005 {ACM} {SIGPLAN} workshop on Haskell},
	publisher = {{ACM} Press},
	year = {2005},
	keywords = {haskell},
	pages = {27--38}
},

@inproceedings{stewart_xmonad_2007,
	author = {Don Stewart and Spencer Sjanssen},
	title = {Xmonad},
	isbn = {9781595936745},
	url = {http://dx.doi.org/10.1145/1291201.1291218},
	booktitle = {Haskell '07: Proceedings of the {ACM} {SIGPLAN} workshop on Haskell workshop},
	publisher = {{ACM}},
	year = {2007},
	keywords = {haskell},
	pages = {119}
},

@article{strachey_fundamental_1967,
	author = {C. Strachey},
	file = {:/home/bernardy/Papers/Fundamental concepts in programming languages-2000.pdf:pdf},
	title = {{Fundamental concepts in programming languages}},
	journal = {Higher-Order and Symbolic Computation},
	volume = {13},
	number = {1},
	pages = {11--49},
	year = {1967},
	publisher = {Springer}
},

@article{strassen_gaussian_1969,
	author = {Volker Strassen},
	title = {Gaussian elimination is not optimal},
	journal = {Numerische Mathematik},
	publisher = {Springer Berlin / Heidelberg},
	issn = {0029-599X},
	keyword = {Mathematics and Statistics},
	pages = {354-356},
	volume = {13},
	issue = {4},
	url = {http://dx.doi.org/10.1007/BF02165411},
	note = {10.1007/BF02165411},
	year = {1969}
},

@inproceedings{sulzmann_modular_2006,
	author = {Martin Sulzmann and Meng Wang},
	title = {Modular generic programming with extensible superclasses},
	isbn = {1595934926},
	url = {http://dx.doi.org/10.1145/1159861.1159869},
	booktitle = {{WGP} '06: Proceedings of the 2006 {ACM} {SIGPLAN} workshop on Generic programming},
	publisher = {{ACM}},
	year = {2006},
	keywords = {open, typeclass},
	pages = {55--65}
},

@inproceedings{sulzmann_system_2007,
	author = {Martin Sulzmann and Manuel Chakravarty and Simon {Peyton Jones} and Kevin Donnelly},
	title = {System F with type equality coercions},
	isbn = {{159593393X}},
	url = {http://dx.doi.org/10.1145/1190315.1190324},
	booktitle = {{TLDI} '07: Proceedings of the 2007 {ACM} {SIGPLAN} international workshop on Types in languages design and implementation},
	publisher = {{ACM}},
	year = {2007},
	keywords = {typeclass},
	pages = {53--66}
},

@article{sulzmann_understanding_2007,
	author = {Martin Sulzmann and Gregory J. Duck and Simon {Peyton-Jones} and Peter Stuckey},
	file = {:/home/bernardy/Papers/Understanding functional dependencies via constraint handling rules-2007.pdf:pdf},
	title = {Understanding functional dependencies via constraint handling rules},
	volume = {17},
	doi = {10.1017/S0956796806006137},
	issn = {0956-7968},
	url = {http://dx.doi.org/10.1017/S0956796806006137},
	number = {1},
	issn = {0956-7968},
	journal = {Journal of Functional Programming},
	year = {2007},
	keywords = {typeclass},
	pages = {83--129}
},

@article{sundholm_constructive_1989,
	author = {G{\"o}ran Sundholm},
	title = {Constructive generalized quantifiers},
	journal = {Synthese},
	volume = {79},
	number = {1},
	pages = {1--12},
	year = {1989},
	publisher = {Springer}
},

@incollection{suppes_probabilistic_1966,
	author = {Patrick Suppes},
	title = {Probabilistic Inference and the Concept of Total Evidence},
	editor = {Jaakko Hintikka and Patrick Suppes},
	series = {Studies in Logic and the Foundations of Mathematics},
	publisher = {Elsevier},
	volume = {43},
	pages = {49--65},
	year = {1966},
	booktitle = {Aspects of Inductive Logic}
},

@article{sutton_vagueness_2016,
	author = {Peter R. Sutton and Hana Filip},
	title = {Vagueness, {Overlap}, and {Countability}},
	volume = {20},
	copyright = {Copyright (c) 2019 Peter R. Sutton, Hana Filip},
	issn = {2629-6055},
	url = {https://ojs.ub.uni-konstanz.de/sub/index.php/sub/article/view/292},
	abstract = {We propose a novel semantic analysis of the mass/count distinction, within a new framework combining the theory of mereology with Probabilistic Type Theory with Records, Prob-TTR (Cooper et al. 2014)). While the notions akin to VAGUENESS (Chierchia 2010) and OVERLAP (Landman 2011) are needed to ground this distinction, neither on its own is sufficient to accommodate the whole range of data, especially the puzzling intra- and crosslinguistic variation in count vs. mass encoding. This variation becomes tractable, if we generally treat the grammatical differences between mass and count nouns as following from the interaction of two notions: namely, VAGUENESS sharpened in terms of graded (probabilistic) type judgements, and DISJOINTNESS relative to a probability threshold. As a result, in the form-denotation mappings, this leads us to a novel semantic classification of nouns into four classes. The mass/count distinction is a bipartite grammatical distinction manifested in the standard diagnostics like a direct combination with numerals, the indefinite article and quantifiers like every, much, among others.},
	language = {en},
	urldate = {2021-03-06},
	journal = {Proceedings of Sinn und Bedeutung},
	year = {2016},
	pages = {730--747}
},

@Article{sutton_probabilistic_2018,
	author = {Peter R. Sutton},
	title = {Probabilistic Approaches to Vagueness and Semantic Competency},
	volume = {83},
	issn = {1572-8420},
	url = {https://doi.org/10.1007/s10670-017-9910-6},
	doi = {10.1007/s10670-017-9910-6},
	abstract = {Wright (Synthese 30:325–365, 1975) holds that the following two theses are jointly incoherent: (T1) Rules determine correct language use. (T2) These rules are discoverable via internal reflection on language use.I argue that incoherence is derivable from (T1) alone and examine two types of probabilistic accounts that model a modification of (T1), one in terms of inexact knowledge, the other in terms of viewing semantic rules as reasons for linguistic actions. Both accommodate tolerance by breaking the link between justified assertion and truth, but incoherence threatens their conception of justified assertion (the ‘relocation problem’). I argue that the rules-as-reasons approach can relocate sharp boundaries to a place where they are not only more tolerable, but to be expected.},
	language = {en},
	number = {4},
	urldate = {2021-03-01},
	journal = {Erkenntnis},
	month = {aug},
	year = {2018},
	pages = {711--740}
},

@inproceedings{svenningsson_shortcut_2002,
	author = {Josef Svenningsson},
	address = {Pittsburg {PA,} {USA}},
	title = {Shortcut fusion for accumulating parameters \& zip-like functions},
	url = {http://portal.acm.org/citation.cfm?id=581491},
	doi = {10.1145/583852.581491},
	abstract = {We present an alternative approach to shortcut fusion based on the function unfoldr,. Despite its simplicity the technique can remove intermediate lists in examples which are known to be difficult. We show that it can remove all lists from definitions involving zip-like functions and functions using accumulating parameters.},
	booktitle = {Proceedings of the seventh {ACM} {SIGPLAN} international conference on Functional Programming},
	publisher = {{ACM}},
	year = {2002},
	keywords = {deforestation, functional programming, intermediate data structures, optimisation, program transformation},
	pages = {124--132}
},

@phdthesis{svenningsson_scalable_2007,
	author = {Josef Svenningsson},
	title = {Scalable Program Analysis},
	school = {Chalmers Tekniska Högskola},
	type = {PhD Thesis},
	year = {2007}
},

@inproceedings{svensson_obsidian_2008,
	author = {Joel Svensson and Mary Sheeran and Koen Claessen},
	title = {Obsidian: A domain specific embedded language for parallel programming of graphics processors},
	booktitle = {Symposium on Implementation and Application of Functional Languages},
	pages = {156--173},
	year = {2008},
	organization = {Springer}
},

@phdthesis{svensson_obsidian_????,
	author = {Joel Svensson},
	title = {Obsidian: GPU Kernel Programming in Haskell},
	school = {Chalmers Tekniska Högskola},
	type = {Licenciate Thesis}
},

@article{swaine_time_2008,
	author = {Michael Swaine},
	title = {It's Time to Get Good at Functional Programming},
	issn = {{1044-789X}},
	url = {http://www.ddj.com/development-tools/212201710},
	journal = {Dr. Dobb's},
	month = {dec},
	year = {2008}
},

@inproceedings{swamy_secure_2011,
	author = {Nikhil Swamy and Juan Chen and C{\'e}dric Fournet and Pierre-Yves Strub and Karthikeyan Bhargavan and Jean Yang},
	title = {Secure distributed programming with value-dependent types},
	booktitle = {Proceedings of the 16th {ACM} {SIGPLAN} international conference on Functional Programming},
	month = {September},
	year = {2011},
	location = {Tokyo, Japan},
	pages = {266--278},
	ee = {http://doi.acm.org/10.1145/2034773.2034811}
},

@inproceedings{swayamdipta_greedy_2016,
	author = {Swabha Swayamdipta and Miguel Ballesteros and Chris Dyer and Noah A. Smith},
	title = {Greedy, Joint Syntactic-Semantic Parsing with Stack LSTMs},
	booktitle = {Proceedings of the 20th {SIGNLL} Conference on Computational Natural
               Language Learning, CoNLL 2016, Berlin, Germany, August 11-12, 2016},
	pages = {187--197},
	year = {2016},
	crossref = {DBLP:conf/conll/2016},
	url = {http://aclweb.org/anthology/K/K16/K16-1019.pdf},
	timestamp = {Fri, 02 Sep 2016 09:34:40 +0200},
	biburl = {http://dblp.org/rec/bib/conf/conll/SwayamdiptaBDS16},
	bibsource = {dblp computer science bibliography, http://dblp.org}
},

@inproceedings{swierstra_fast_1999,
	author = {S. Doaitse Swierstra and Pablo R. Azero Alcocer},
	file = {:/home/bernardy/Papers/Fast, Error Correcting Parser Combinators A Short Tutorial-1999.pdf:pdf},
	title = {Fast, Error Correcting Parser Combinators: A Short Tutorial},
	isbn = {{3-540-66694-X}},
	shorttitle = {Fast, Error Correcting Parser Combinatiors},
	url = {http://portal.acm.org/citation.cfm?id=647009.712536&coll=ACM&dl=ACM&CFID=13026192&CFTOKEN=34892732},
	booktitle = {Proceedings of the 26th Conference on Current Trends in Theory and Practice of Informatics},
	publisher = {{Springer-Verlag}},
	year = {1999},
	pages = {112--131}
},

@article{swierstra_combinator_2000,
	author = {S. Doaitse Swierstra},
	title = {Combinator parsers: From toys to tools.},
	volume = {41},
	shorttitle = {generators; D.3.4 {[Programming} languages]},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.30.7601},
	doi = {10.1.1.30.7601},
	number = {1},
	journal = {Electronic Notes in Theoretical Computer Science},
	year = {2000}
},

@article{swierstra_data_2008,
	author = {Wouter Swierstra},
	file = {:/home/bernardy/Papers/Data types  la carte-2008.pdf:pdf},
	title = {Data types à la carte},
	volume = {Forthcoming},
	url = {http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=1813324},
	abstract = {This paper describes a technique for assembling both data types and functions from isolated individual components. We also explore how the same technology can be used to combine free monads and, as a result, structure Haskell's monolithic {IO} monad.},
	number = {-1},
	journal = {Journal of Functional Programming},
	year = {2008},
	keywords = {aop, open},
	pages = {1--14}
},

@inproceedings{swierstra_combinator_2009,
	author = {S. Doaitse Swierstra},
	file = {:/home/bernardy/Papers/Combinator Parsing A Short Tutorial-2009.pdf:pdf},
	address = {Piriapolis},
	series = {Lecture Notes in Computer Science},
	title = {Combinator Parsing: A Short Tutorial},
	volume = {5520},
	url = {http://www.cs.uu.nl/research/techreps/repo/CS-2008/2008-044.pdf},
	booktitle = {Language Engineering and Rigorous Software Development},
	publisher = {Springer},
	year = {2009},
	pages = {252--300}
},

@article{swierstra_linear_2009,
	author = {S. Doaitse Swierstra and Olaf Chitil},
	date-Added = {2009-02-13 10:17:23 +0100},
	date-Modified = {2010-02-15 23:09:49 +0100},
	doi = {10.1017/S0956796808006990},
	journal = {Journal of Functional Programming},
	number = {01},
	pages = {1-16},
	title = {Linear, bounded, functional pretty-printing},
	volume = {19},
	year = {2009},
	abstract = {ABSTRACT We present two implementations of Oppen's pretty-printing algorithm in Haskell that meet the efficiency of Oppen's imperative solution but have a simpler and a clear structure. We start with an implementation that uses lazy evaluation to simulate two co-operating processes. Then we present an implementation that uses higher-order functions for delimited continuations to simulate co-routines with explicit scheduling. }
},

@unpublished{takeuti_theory_2004,
	author = {Izumi Takeuti},
	title = {The Theory of Parametricity in Lambda Cube},
	year = {2004},
	note = {Manuscript},
	keywords = {parametricity}
},

@article{talman_natural_2018,
	author = {Aarne Talman and Anssi Yli-Jyr{\"a} and J{\"o}rg Tiedemann},
	title = {Natural Language Inference with Hierarchical BiLSTM Max Pooling Architecture},
	journal = {arXiv preprint arXiv:1808.08762},
	year = {2018}
},

@article{talman_testing_2018,
	author = {Aarne Talman and Stergios Chatzikyriakidis},
	title = {Testing the Generalization Power of Neural Network Models Across NLI Benchmarks},
	journal = {arXiv preprint arXiv:1810.09774},
	year = {2018}
},

@inproceedings{tanaka_factivity_2015,
	author = {Ribeka Tanaka and Koji Mineshima and Daisuke Bekki},
	title = {Factivity and presupposition in dependent type semantics},
	booktitle = {Proceedings of TyTLeS, ESSLLI2015},
	year = {2015}
},

@book{tantau_tikz_2006,
	author = {Till Tantau},
	file = {:/home/bernardy/Papers/TikZ and pgf-2006.pdf:pdf},
	booktitle = {October},
	title = {{TikZ and pgf}},
	year = {2006}
},

@book{tantau_beamer_2007,
	author = {Till Tantau},
	file = {:/home/bernardy/Papers/The beamer class 3.07-2007.pdf:pdf},
	pages = {1--224},
	title = {{The beamer class 3.07}},
	year = {2007}
},

@inproceedings{thielecke_control_2003,
	author = {Hayo Thielecke},
	title = {From control effects to typed continuation passing},
	booktitle = {ACM SIGPLAN Notices},
	volume = {38},
	number = {1},
	pages = {139--149},
	year = {2003},
	organization = {ACM}
},

@article{tichy_rcs_1985,
	author = {Walter Tichy},
	title = {{RCS} --- A System for Version Control},
	volume = {15},
	url = {http://citeseer.ist.psu.edu/tichy85rcs.html},
	abstract = {An important problem in program development and maintenance is version control, i.e., the task of keeping a software system consisting of many versions and configurations well organized. The Revision Control System {(RCS)} is a software tool that assists with that task. {RCS} manages revisions of text documents, in particular source programs, documentation, and test data. It automates the storing, retrieval, logging and identification of revisions, and it provides selection mechanisms for composing ...},
	number = {7},
	journal = {Software --- Practice and Experience},
	year = {1985},
	keywords = {vc},
	pages = {637--654}
},

@article{tillmann_parameterized_2005,
	author = {Nikolai Tillmann and Wolfram Schulte},
	title = {Parameterized unit tests},
	volume = {30},
	url = {http://portal.acm.org/citation.cfm?id=1081749},
	doi = {10.1145/1095430.1081749},
	abstract = {Parameterized unit tests extend the current industry practice of using closed unit tests defined as parameterless methods. Parameterized unit tests separate two concerns: 1) They specify the external behavior of the involved methods for all test arguments. 2) Test cases can be re-obtained as traditional closed unit tests by instantiating the parameterized unit tests. Symbolic execution and constraint solving can be used to automatically choose a minimal set of inputs that exercise a parameterized unit test with respect to possible code paths of the implementation. In addition, parameterized unit tests can be used as symbolic summaries which allows symbolic execution to scale for arbitrary abstraction levels. We have developed a prototype tool which computes test cases from parameterized unit tests. We report on its first use testing parts of the {.NET} base class library.},
	number = {5},
	journal = {{SIGSOFT} Software Engineering Notes},
	year = {2005},
	keywords = {algebraic data types, automatic test input generation, constraint solving, symbolic execution, unit testing},
	pages = {253--262}
},

@book{tomita_efficient_1986,
	author = {Masaru Tomita},
	title = {Efficient Parsing for Natural Language},
	year = {1986},
	publisher = {Kluwer Adademic Publishers}
},

@inproceedings{tov_theory_2011,
	author = {Jesse A. Tov and Riccardo Pucella},
	title = {A theory of substructural types and control},
	booktitle = {Proceedings of the 26th Annual {ACM} {SIGPLAN} Conference on Object-Oriented
               Programming, Systems, Languages, and Applications, {OOPSLA} 2011,
               part of {SPLASH} 2011, Portland, OR, USA, October 22 - 27, 2011},
	pages = {625--642},
	year = {2011},
	url = {http://doi.acm.org/10.1145/2048066.2048115},
	doi = {10.1145/2048066.2048115},
	timestamp = {Tue, 25 Oct 2011 20:48:58 +0200},
	biburl = {http://dblp.uni-trier.de/rec/bib/conf/oopsla/TovP11},
	bibsource = {dblp computer science bibliography, http://dblp.org}
},

@inproceedings{tov_practical_2011,
	author = {Jesse A Tov and Riccardo Pucella},
	title = {Practical affine types},
	booktitle = {POPL},
	pages = {447--458},
	year = {2011},
	organization = {ACM}
},

@phdthesis{tov_practical_2012,
	author = {Jesse A. Tov},
	title = {Practical Programming with Substructural Types},
	year = {2012},
	school = {Northeastern University}
},

@inproceedings{tredici_semantic_2017,
	author = {Marco Del Tredici and Raquel Fern{\'a}ndez},
	title = {Semantic {{Variation}} in {{Online Communities}} of {{Practice}}},
	booktitle = {{{IWCS}} 2017 - 12th {{International Conference}} on {{Computational Semantics}} - {{Long}} Papers},
	year = {2017}
},

@article{trinder_algorithm+_1998,
	author = {P.W. Trinder and Kevin Hammond and H.W. Loidl and Simon {Peyton Jones}},
	title = {Algorithm+ strategy= parallelism},
	journal = {Journal of functional programming},
	volume = {8},
	number = {1},
	pages = {23--60},
	year = {1998},
	publisher = {Cambridge University Press}
},

@InBook{troelstra_handbook_1998,
	author = {Anne Sjerp Troelstra},
	editor = {Samuel R. Buss},
	title = {Handbook of proof theory},
	chapter = {Realizability},
	publisher = {Elsevier},
	year = {1998}
},

@inproceedings{tse_translating_2004,
	author = {Stephen Tse and Steve Zdancewic},
	title = {Translating dependency into parametricity},
	booktitle = {ACM SIGPLAN Notices},
	volume = {39},
	number = {9},
	pages = {115--125},
	year = {2004},
	organization = {ACM}
},

@conference{turbak_cycle_2001,
	author = {F. Turbak and JB Wells},
	file = {:/home/bernardy/Papers/Cycle therapy A prescription for fold and unfold on regular trees-2001.pdf:pdf},
	title = {{Cycle therapy: A prescription for fold and unfold on regular trees}},
	booktitle = {Proceedings of the 3rd ACM SIGPLAN international conference on Principles and practice of declarative programming},
	pages = {149},
	year = {2001},
	organization = {ACM}
},

@inproceedings{unger_dynamic_2011,
	author = {Christina Unger},
	title = {Dynamic semantics as monadic computation},
	booktitle = {JSAI International Symposium on Artificial Intelligence},
	pages = {68--81},
	year = {2011},
	organization = {Springer}
},

@book{unknownauthor_wordnet_1998,
	author = { UnknownAuthor},
	abstract = {WordNet, an electronic lexical database, is considered to be the most important resource available to researchers in computational linguistics, text analysis, and many related areas. Its design is inspired by current psycholinguistic and computational theories of human lexical memory. English nouns, verbs, adjectives, and adverbs are organized into synonym sets, each representing one underlying lexicalized concept. Different relations link the synonym sets. The purpose of this volume is twofold. First, it discusses the design of WordNet and the theoretical motivations behind it. Second, it provides a survey of representative applications, including word sense identification, information retrieval, selectional preferences of verbs, and lexical chains.},
	added-at = {2017-11-01T11:46:20.000+0100},
	address = {Cambridge, MA},
	editor = {Fellbaum, Christiane},
	groups = {public},
	isbn = {978-0-262-06197-1},
	keywords = {01821 101 mitpress book shelf ai language processing ontology lexicon},
	publisher = {MIT Press},
	series = {Language, Speech, and Communication},
	title = {WordNet: An Electronic Lexical Database},
	year = {1998}
},

@article{valiant_general_1975,
	author = {L.G. Valiant},
	file = {:/home/bernardy/Papers/General context-free recognition in less than cubic time-1975.pdf:pdf},
	title = {General context-free recognition in less than cubic time},
	journal = {Journal of computer and system sciences},
	volume = {10},
	number = {2},
	pages = {308--314},
	year = {1975},
	publisher = {Elsevier}
},

@inproceedings{valliappan_exponential_2019,
	author = {Nachiappan Valliappan and Alejandro Russo},
	title = {Exponential Elimination for Bicartesian Closed Categorical Combinators},
	year = {2019},
	isbn = {9781450372497},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3354166.3354185},
	doi = {10.1145/3354166.3354185},
	abstract = {Categorical combinators offer a simpler alternative to typed lambda calculi for static analysis and implementation. Since categorical combinators are accompanied by a rich set of conversion rules which arise from categorical laws, they also offer a plethora of opportunities for program optimization. It is unclear, however, how such rules can be applied in a systematic manner to eliminate intermediate values such as exponentials, the categorical equivalent of higher-order functions, from a program built using combinators. Exponential elimination simplifies static analysis and enables a simple closure-free implementation of categorical combinators--reasons for which it has been sought after.In this paper, we prove exponential elimination for bicartesian closed categorical (BCC) combinators using normalization. We achieve this by showing that BCC terms can be normalized to normal forms which obey a weak subformula property. We implement normalization using Normalization by Evaluation, and also show that the generated normal forms are correct using logical relations.},
	booktitle = {Proceedings of the 21st International Symposium on Principles and Practice of Declarative Programming},
	articleno = {20},
	numpages = {13},
	keywords = {categorical combinators, normalization by evaluation, defunctionalization, subformula property},
	location = {Porto, Portugal},
	series = {PPDP '19}
},

@book{vandevoorde_c++_2002,
	author = {David Vandevoorde and Nicolai Josuttis},
	title = {C++ Templates: The Complete Guide},
	isbn = {0201734842},
	url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&path=ASIN/0201734842},
	publisher = {{{Addison-Wesley} Professional}},
	month = {nov},
	year = {2002},
	keywords = {cpp, templates, wgp08}
},

@article{vaswani_attention_2017,
	author = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
	title = {Attention {{Is All You Need}}},
	year = {2017},
	month = {jun},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	archiveprefix = {arXiv},
	eprint = {1706.03762},
	eprinttype = {arxiv},
	journal = {arXiv:1706.03762 [cs]},
	keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
	language = {en},
	primaryclass = {cs}
},

@article{vendrov_order-embeddings_2015,
	author = {Ivan Vendrov and Ryan Kiros and Sanja Fidler and Raquel Urtasun},
	title = {Order-Embeddings of Images and Language},
	journal = {CoRR},
	volume = {abs/1511.06361},
	year = {2015},
	eprint = {1511.06361}
},

@article{vieira_review_1998,
	author = {Renata Vieira},
	title = {A Review of the Linguistic Research on Definite Descriptions},
	journal = {Acta Semiotica et Lingvistica},
	year = {1998}
},

@inproceedings{villavicencio_reverse_2001,
	author = {G. Villavicencio and J.N. Oliveira},
	file = {:/home/bernardy/Papers/Reverse program calculation supported by code slicing-2001.pdf:pdf},
	title = {Reverse program calculation supported by code slicing},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=957808},
	abstract = {This paper sketches a discipline for reverse engineering which combines formal and semi-formal methods. Among the former is the "algebra of programming", which we apply in "reverse order" so as to reconstruct formal specifications of legacy code. The latter includes code slicing, used as a means of trimming down the complexity of handling the formal semantics of all program variables at the same time. A strong point of the approach is its constructive style. Reverse calculations go as far as imploding auxiliary variables, introducing mutual recursion (if applicable) and transforming semantic functions into standard generic programming schemata such as cata/paramorphisms. We illustrate the approach by reversing a piece of code (from C to Haskell) already studied in the code-slicing literature: the word-count (wc) program},
	booktitle = {Reverse Engineering, 2001. Proceedings. Eighth Working Conference on},
	year = {2001},
	keywords = {aop},
	doi = {10.1109/WCRE.2001.957808},
	publisher = {IEEE Computer Society},
	pages = {35--45}
},

@article{vilnis_word_2014,
	author = {Luke Vilnis and Andrew McCallum},
	title = {Word Representations via Gaussian Embedding},
	journal = {CoRR},
	volume = {abs/1412.6623},
	year = {2014},
	eprint = {1412.6623}
},

@InProceedings{vilnis_probabilistic_2018,
	author = {Luke Vilnis and Xiang Li and Shikhar Murty and Andrew McCallum},
	title = {Probabilistic Embedding of Knowledge Graphs with Box Lattice Measures},
	booktitle = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	year = {2018},
	publisher = {Association for Computational Linguistics},
	pages = {263--272},
	location = {Melbourne, Australia}
},

@article{vinyals_show_2015,
	author = {Oriol Vinyals and Alexander Toshev and Samy Bengio and Dumitru Erhan},
	title = {Show and {{Tell}}: {{A Neural Image Caption Generator}}},
	shorttitle = {Show and {{Tell}}},
	year = {2015},
	month = {apr},
	abstract = {Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing. In this paper, we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image. The model is trained to maximize the likelihood of the target description sentence given the training image. Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions. Our model is often quite accurate, which we verify both qualitatively and quantitatively. For instance, while the current state-of-the-art BLEU-1 score (the higher the better) on the Pascal dataset is 25, our approach yields 59, to be compared to human performance around 69. We also show BLEU-1 score improvements on Flickr30k, from 56 to 66, and on SBU, from 19 to 28. Lastly, on the newly released COCO dataset, we achieve a BLEU-4 of 27.7, which is the current state-of-the-art.},
	archiveprefix = {arXiv},
	eprint = {1411.4555},
	eprinttype = {arxiv},
	journal = {arXiv:1411.4555 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	primaryclass = {cs}
},

@misc{voevodsky_equivalence_2010,
	author = {Vladimir Voevodsky},
	title = {The equivalence axiom and univalent models of type theory},
	year = {2010},
	note = {\HREF{available online}{http: //www.math.ias.edu/~vladimir/Site3/home_files/}}
},

@article{voigtlnder_much_2008,
	author = {Janis Voigtländer},
	file = {:/home/bernardy/Papers/Much ado about two (pearl) a pearl on parallel prefix computation-2008.pdf:pdf},
	title = {Much ado about two (pearl): a pearl on parallel prefix computation},
	volume = {43},
	shorttitle = {Much ado about two (pearl)},
	url = {http://portal.acm.org/citation.cfm?id=1328445},
	doi = {10.1145/1328897.1328445},
	abstract = {This pearl develops a statement about parallel prefix computation in the spirit of Knuth's {0-1-Principle} for oblivious sorting algorithms. It turns out that 0-1 is not quite enough here. The perfect hammer for the nails we are going to drive in is relational parametricity.},
	number = {1},
	journal = {{SIGPLAN} Not.},
	year = {2008},
	keywords = {0-1-principle, free theorems, parallel prefix computation, relational parametricity},
	pages = {29--35}
},

@inproceedings{voigtlnder_proving_2008,
	author = {Janis Voigtländer},
	file = {:/home/bernardy/Papers/Proving correctness via free theorems the case of the destroybuild-rule-2008.pdf:pdf},
	address = {San Francisco, California, {USA}},
	title = {Proving correctness via free theorems: the case of the destroy/build-rule},
	isbn = {978-1-59593-977-7},
	shorttitle = {Proving correctness via free theorems},
	url = {http://portal.acm.org/citation.cfm?id=1328408.1328412},
	doi = {10.1145/1328408.1328412},
	abstract = {Free theorems feature prominently in the field of program transformation for pure functional languages such as Haskell. However, somewhat disappointingly, the semantic properties of so based transformations are often established only very superficially. This paper is intended as a case study showing how to use the existing theoretical foundations and formal methods for improving the situation. To that end, we investigate the correctness issue for a new transformation rule in the short cut fusion family. This destroy/build-rule provides a certain reconciliation between the competing foldr/build- and destroy/unfoldr-approaches to eliminating intermediate lists. Our emphasis is on systematically and rigorously developing the rule's correctness proof, even while paying attention to semantic aspects like potential nontermination and mixed strict/nonstrict evaluation.},
	booktitle = {Proceedings of the 2008 {ACM} {SIGPLAN} symposium on Partial evaluation and semantics-based program manipulation},
	publisher = {{ACM}},
	year = {2008},
	keywords = {correctness proofs, intermediate data structures, program transformations, rank-2 types, relational parametricity, shortcut deforestation, theorems for free},
	pages = {13--20}
},

@inproceedings{voigtlnder_bidirectionalization_2009,
	author = {Janis Voigtländer},
	file = {:/home/bernardy/Papers/Bidirectionalization for free! (Pearl)-2009.pdf:pdf},
	address = {Savannah, {GA,} {USA}},
	title = {Bidirectionalization for free! {(Pearl)}},
	isbn = {978-1-60558-379-2},
	doi = {10.1145/1480881.1480904},
	abstract = {A bidirectional transformation consists of a function get that takes a source (document or value) to a view and a function put that takes an updated view and the original source back to an updated source, governed by certain consistency conditions relating the two functions. Both the database and programming language communities have studied techniques that essentially allow a user to specify only one of get and put and have the other inferred automatically. All approaches so far to this bidirectionalization task have been syntactic in nature, either proposing a domain-specific language with limited expressiveness but built-in (and composable) backward components, or restricting get to a simple syntactic form from which some algorithm can synthesize an appropriate definition for put. Here we present a semantic approach instead. The idea is to take a general-purpose language, Haskell, and write a higher-order function that takes (polymorphic) get-functions as arguments and returns appropriate put-functions. All this on the level of semantic values, without being willing, or even able, to inspect the definition of get, and thus liberated from syntactic restraints. Our solution is inspired by relational parametricity and uses free theorems for proving the consistency conditions. It works beautifully.},
	booktitle = {Proceedings of the 36th annual {ACM} {SIGPLAN-SIGACT} symposium on Principles of programming languages},
	publisher = {{ACM}},
	year = {2009},
	keywords = {bidirectionalization, free theorems, generic programming, program transformation, relational parametricity, view-update problem},
	pages = {165--176}
},

@inproceedings{voigtlnder_free_2009,
	author = {Janis Voigtländer},
	title = {Free theorems involving type constructor classes: {Functional pearl}},
	shorttitle = {Free theorems involving type constructor classes},
	url = {http://portal.acm.org/citation.cfm?id=1631687.1596577},
	doi = {10.1145/1631687.1596577},
	abstract = {Free theorems are a charm, allowing the derivation of useful statements about programs from their (polymorphic) types alone. We show how to reap such theorems not only from polymorphism over ordinary types, but also from polymorphism over type constructors restricted by class constraints. Our prime application area is that of monads, which form the probably most popular type constructor class of Haskell. To demonstrate the broader scope, we also deal with a transparent way of introducing difference lists into a program, endowed with a neat and general correctness proof.},
	booktitle = {Proceedings of the 14th ACM SIGPLAN international conference on Functional Programming},
	isbn = {978-1-60558-332-7},
	location = {Edinburgh, Scotland},
	pages = {173--184},
	numpages = {12},
	acmid = {1596577},
	publisher = {ACM},
	address = {New York, NY, USA},
	year = {2009},
	keywords = {relational parametricity}
},

@inproceedings{voigtlnder_combining_2010,
	author = {Janis Voigtländer and Z Hu and K Matsuda and Meng Wang},
	file = {:/home/bernardy/Papers/Combining Syntactic and Semantic Bidirectionalization-2010.pdf:pdf},
	booktitle = {ICFP},
	keywords = {program transformation,view-update problem},
	pages = {1--12},
	title = {{Combining Syntactic and Semantic Bidirectionalization}},
	url = {http://www.iai.uni-bonn.de/\~{}jv/icfp10.pdf},
	year = {2010}
},

@article{vulic_hyperlex_2016,
	author = {Ivan Vulic and Daniela Gerz and Douwe Kiela and Felix Hill and Anna Korhonen},
	title = {HyperLex: {A} Large-Scale Evaluation of Graded Lexical Entailment},
	journal = {CoRR},
	volume = {abs/1608.02117},
	year = {2016},
	eprint = {1608.02117}
},

@unpublished{vytiniotis_type-safe_2009,
	author = {D. Vytiniotis and S. Weirich},
	file = {:/home/bernardy/Papers/Type-safe cast does no harm Syntactic parametricity for F and beyond-2009.pdf:pdf},
	title = {Type-safe cast does no harm: Syntactic parametricity for {Fω} and beyond},
	shorttitle = {Type-safe cast does no harm},
	year = {2009},
	note = {Preliminary version of ``Parametricity, Type Equality, and Higher-order Polymorphism''}
},

@article{vytiniotis_parametricity_2010,
	author = {Dimitrios Vytiniotis and Stephanie Weirich},
	file = {:/home/bernardy/Papers/Parametricity, Type Equality, and Higher-Order Polymorphism-2010.pdf:pdf},
	doi = {10.1017/S0956796810000079},
	journal = {Journal of Functional Programming},
	number = {02},
	pages = {175--210},
	title = {Parametricity, Type Equality, and Higher-Order Polymorphism},
	volume = {20},
	year = {2010}
},

@article{wadler_critique_1987,
	author = {Philip Wadler},
	title = {A critique of Abelson and Sussman or why calculating is better than scheming},
	journal = {ACM SIGPLAN Notices},
	volume = {22},
	number = {3},
	pages = {83--94},
	year = {1987},
	publisher = {ACM}
},

@inproceedings{wadler_ad-hoc_1989,
	author = {Philip Wadler and Stephen Blott},
	title = {How to make ad-hoc polymorphism less ad hoc},
	isbn = {0897912942},
	doi = {10.1145/75277.75283},
	booktitle = {{POPL} '89: Proceedings of the 16th {ACM} {SIGPLAN-SIGACT} symposium on Principles of programming languages},
	publisher = {{ACM}},
	year = {1989},
	keywords = {typeclass},
	pages = {60--76}
},

@inproceedings{wadler_theorems_1989,
	author = {Philip Wadler},
	address = {Imperial College, London, United Kingdom},
	title = {Theorems for free!},
	isbn = {0-89791-328-0},
	url = {http://portal.acm.org/citation.cfm?id=99404},
	doi = {10.1145/99370.99404},
	abstract = {Note: {OCR} errors may be found in this Reference List extracted from the full text article. {ACM} has opted to expose the complete List rather than only correct and linked references.},
	booktitle = {Proceedings of the fourth international conference on Functional programming languages and computer architecture},
	publisher = {{ACM}},
	year = {1989},
	keywords = {parametricity},
	pages = {347--359}
},

@article{wadler_deforestation_1990,
	author = {Philip Wadler},
	title = {Deforestation: Transforming programs to eliminate trees},
	journal = {Theoretical Computer Science},
	volume = {73},
	number = {2},
	pages = {231--248},
	year = {1990},
	publisher = {Elsevier}
},

@inproceedings{wadler_linear_1990,
	author = {Philip Wadler},
	editor = {Broy, M and Jones, C B},
	title = {Linear types can change the world},
	booktitle = {Programming Concepts and Methods},
	year = {1990},
	publisher = {North-Holland}
},

@inbook{wadler_prettier_2003,
	author = {Philip Wadler},
	title = {A prettier printer},
	Book = {The Fun of Programming, Cornerstones of Computing},
	pages = {223--243},
	editors = {Jeremy Gibbons and Oege {de Moor}},
	year = {2003},
	publisher = {Palgrave MacMillan}
},

@inproceedings{wadler_call-by-value_2003,
	author = {Philip Wadler},
	file = {:/home/bernardy/Papers/Call-by-value is dual to call-by-name-2003.pdf:pdf},
	title = {Call-by-value is dual to call-by-name},
	booktitle = {Proceedings of the eighth {ACM} {SIGPLAN} international conference on Functional Programming},
	series = {ICFP '03},
	year = {2003},
	isbn = {1-58113-756-7},
	location = {Uppsala, Sweden},
	pages = {189--201},
	numpages = {13},
	url = {http://doi.acm.org/10.1145/944705.944723},
	doi = {10.1145/944705.944723},
	acmid = {944723},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {Curry-Howard correspondence, De Morgan dual, lambda calculus, lambda mu calculus, logic, natural deduction, sequent calculus}
},

@article{wadler_girardreynolds_2003,
	author = {Philip Wadler},
	title = {The {Girard–Reynolds} isomorphism},
	volume = {186},
	url = {http://portal.acm.org/citation.cfm?id=957696},
	abstract = {The second-order polymorphic lambda calculus, F2, was independently discovered by Girard and Reynolds. Girard additionally proved a Representation Theorem: every function on natural numbers that can be proved total in second-order intuitionistic predicate logic, P2, can be represented in F2. Reynolds additionally proved an Abstraction Theorem: for a suitable notion of logical relation, every term in F2 takes related arguments into related results. We observe that the essence of Girard's result is a projection from P2 into F2, and that the essence of Reynolds's result is an embedding of F2 into P2, and that the Reynolds embedding followed by the Girard projection is the identity. The Girard projection discards all first-order quantifiers, so it seems unreasonable to expect that the Girard projection followed by the Reynolds embedding should also be the identity. However, we show that in the presence of Reynolds's parametricity property that this is indeed the case, for propositions corresponding to inductive definitions of naturals or other algebraic types.},
	number = {2},
	journal = {Information and Computation},
	year = {2003},
	pages = {260--284},
	see = {version:wadler_girardreynolds_2007}
},

@article{wadler_girardreynolds_2007,
	author = {Philip Wadler},
	file = {:/home/bernardy/Papers/The GirardReynolds isomorphism-2007.pdf:pdf},
	title = {The {Girard–Reynolds} isomorphism (second edition)},
	volume = {375},
	number = {1--3},
	journal = {Theoretical Computer Science},
	year = {2007},
	pages = {201–226}
},

@inproceedings{wadler_well-typed_2009,
	author = {Philip Wadler and Robert Bruce Findler},
	address = {York, {UK}},
	title = {{Well-Typed} Programs Can't Be Blamed},
	isbn = {978-3-642-00589-3},
	url = {http://portal.acm.org/citation.cfm?id=1532976},
	abstract = {We introduce the blame calculus, which adds the notion of blame from Findler and Felleisen's contracts to a system similar to Siek and Taha's gradual types and Flanagan's hybrid types. We characterise where positive and negative blame can arise by decomposing the usual notion of subtype into positive and negative subtypes, and show that these recombine to yield naive subtypes. Naive subtypes previously appeared in type systems that are unsound, but we believe this is the first time naive subtypes play a role in establishing type soundness.},
	booktitle = {Proceedings of the 18th European Symposium on Programming Languages and Systems: Held as Part of the Joint European Conferences on Theory and Practice of Software, {ETAPS} 2009},
	publisher = {{Springer-Verlag}},
	year = {2009},
	pages = {1--16}
},

@inproceedings{wadler_propositions_2012,
	author = {Philip Wadler},
	title = {Propositions as Sessions},
	booktitle = {Proceedings of the 17th {ACM} {SIGPLAN} international conference on Functional Programming},
	series = {ICFP '12},
	year = {2012},
	pages = {273--286},
	publisher = {ACM},
	address = {New York, NY, USA}
},

@article{wagner_efficient_1998,
	author = {Tim A. Wagner and Suzan L. Graham},
	file = {:/home/bernardy/Papers/Efficient and Flexible Incremental Parsing-1998.pdf:pdf},
	title = {Efficient and Flexible Incremental Parsing},
	volume = {20},
	number = {5},
	journal = {{ACM} Transactions on Programming Languages and Systems},
	year = {1998},
	pages = {980--1013},
	see = {:ghezzi_incremental_1979}
},

@inproceedings{wakeling_linearity_1991,
	author = {David Wakeling and Colin Runciman},
	title = {Linearity and laziness},
	booktitle = {Functional Programming Languages and Computer Architecture},
	pages = {215--240},
	year = {1991},
	organization = {Springer},
	url = {https://www.cs.york.ac.uk/plasma/publications/pdf/WakelingRuncimanFPCA91.pdf}
},

@incollection{wallace_partial_2008,
	author = {Malcolm Wallace},
	file = {:/home/bernardy/Papers/Partial Parsing Combining Choice with Commitment-2008.pdf:pdf},
	series = {Lecture Notes in Computer Science},
	title = {Partial Parsing: Combining Choice with Commitment},
	volume = {5083/2008},
	shorttitle = {Partial Parsing},
	url = {http://dx.doi.org/10.1007/978-3-540-85373-2_6},
	abstract = {Parser combinators, often monadic, are a venerable and widely-used solution to read data from some external format. However,
the capability to return a partial parse has, until now, been largely missing. When only a small portion of the entire data
is desired, it has been necessary either to parse the entire input in any case, or to break up the grammar into smaller pieces
and move some work outside the world of combinators.

This paper presents a technique for mixing lazy, demand-driven, parsing with strict parsing, all within the same set of combinators.
The grammar specification remains complete and unbroken, yet only sufficient input is consumed to satisfy the result demanded.
It is built on a combination of applicative and monadic parsers. Monadic parsing alone is insufficient to allow a choice operator to coexist with the early commitment needed for
lazy results. Applicative parsing alone can give partial results, but does not permit context-sensitive grammars. But used
together, we gain both partiality and a flexible ease of use.



Performance results demonstrate that partial parsing is often faster and more space-efficient than strict parsing, but never
worse. The trade-off is that partiality has consequences when dealing with ill-formed input.},
	booktitle = {Implementation and Application of Functional Languages},
	publisher = {Springer},
	year = {2008},
	pages = {93--110}
},

@inproceedings{wand_continuation-based_1980,
	author = {Mitchell Wand},
	title = {Continuation-based Multiprocessing},
	booktitle = {Proceedings of the 1980 ACM Conference on LISP and Functional Programming},
	series = {LFP '80},
	year = {1980},
	location = {Stanford University, California, USA},
	pages = {19--28},
	numpages = {10},
	url = {http://doi.acm.org/10.1145/800087.802786},
	doi = {10.1145/800087.802786},
	acmid = {802786},
	publisher = {ACM},
	address = {New York, NY, USA}
},

@article{wang_bilateral_2017,
	author = {Zhiguo Wang and Wael Hamza and Radu Florian},
	title = {Bilateral multi-perspective matching for natural language sentences},
	journal = {arXiv preprint arXiv:1702.03814},
	year = {2017}
},

@inproceedings{washburn_boxes_2003,
	author = {Geoffrey Washburn and Stephanie Weirich},
	file = {:/home/bernardy/Papers/Boxes go bananas encoding higher-order abstract syntax with parametric polymorphism-2003.pdf:pdf},
	address = {Uppsala, Sweden},
	title = {Boxes go bananas: encoding higher-order abstract syntax with parametric polymorphism},
	isbn = {1-58113-756-7},
	shorttitle = {Boxes go bananas},
	url = {http://portal.acm.org/citation.cfm?id=944728},
	doi = {10.1145/944705.944728},
	abstract = {Higher-order abstract syntax is a simple technique for implementing languages with functional programming. Object variables and binders are implemented by variables and binders in the host language. By using this technique, one can avoid implementing common and tricky routines dealing with variables, such as capture-avoiding substitution. However, despite the advantages this technique provides, it is not commonly used because it is difficult to write sound elimination forms (such as folds or catamorphisms) for higher-order abstract syntax. To fold over such a datatype, one must either simultaneously define an inverse operation (which may not exist) or show that all functions embedded in the datatype are {parametri.In} this paper, we show how first-class polymorphism can be used to guarantee the parametricity of functions embedded in higher-order abstract syntax. With this restriction, we implement a library of iteration operators over data-structures containing functionals. From this implementation, we derive "fusion laws" that functional programmers may use to reason about the iteration operator. Finally, we show how this use of parametric polymorphism corresponds to the Schürmann, Despeyroux and Pfenning method of enforcing parametricity through modal types. We do so by using this library to give a sound and complete encoding of their calculus into System F?. This encoding can serve as a starting point for reasoning about higher-order structures in polymorphic languages.},
	booktitle = {Proceedings of the eighth {ACM} {SIGPLAN} international conference on Functional Programming},
	publisher = {{ACM}},
	year = {2003},
	keywords = {catamorphism, higher-order abstract syntax, modal type system, parametricity, parametric polymorphism},
	pages = {249--262}
},

@inproceedings{weirich_arity-generic_2010,
	author = {Stephanie Weirich and Chris Casinghino},
	file = {:/home/bernardy/Papers/Arity-generic datatype-generic programming-2010.pdf:pdf},
	booktitle = {PLPV},
	doi = {10.1145/1816027.1816036},
	issn = {03621340},
	keywords = {agda,arity-generic programming,dependent types},
	month = {jun},
	number = {11},
	pages = {7},
	title = {{Arity-generic datatype-generic programming}},
	url = {http://portal.acm.org/citation.cfm?doid=1816027.1816036},
	volume = {44},
	year = {2010},
	see = {:gibbons_datatype-generic_2007}
},

@inproceedings{weirich_binders_2011,
	author = {Stephanie Weirich and Brent A Yorgey and Tim Sheard},
	file = {:/home/bernardy/Papers/Binders unbound-2011.pdf:pdf;:/home/bernardy/Papers/Binders unbound-2011.Yms:Yms},
	title = {Binders unbound},
	booktitle = {ACM SIGPLAN Notices},
	volume = {46},
	number = {9},
	pages = {333--345},
	year = {2011},
	organization = {ACM}
},

@article{weiss_practical_2018,
	author = {Gail Weiss and Yoav Goldberg and Eran Yahav},
	title = {On the practical computational power of finite precision RNNs for language recognition},
	journal = {arXiv preprint arXiv:1805.04908},
	year = {2018}
},

@phdthesis{werner_une_1994,
	author = {Benjamin Werner},
	type = {{PhD} Thesis},
	title = {Une théorie des constructions inductives},
	school = {Université de Paris 7},
	year = {1994}
},

@article{wilcox_design_1976,
	author = {Thomas R. Wilcox and Alan M. Davis and Michael H. Tindall},
	title = {The design and implementation of a table driven, interactive diagnostic programming system},
	volume = {19},
	url = {http://portal.acm.org/citation.cfm?id=360363.360367},
	doi = {10.1145/360363.360367},
	abstract = {{CAPS} is a highly interactive diagnostic compiler/interpreter that allows beginning programmers to prepare, debug, and execute fairly simple programs at a graphics display terminal. Complete syntax checking and most semantic analysis is performed as the program is entered and as it is subsequently edited. Analysis is performed character by character. The most remarkable feature of {CAPS} is its ability to automatically diagnose errors both at compile time and at run time. Errors are not automatically corrected. Instead, {CAPS} interacts with the student to help him find the cause of his error. Most components of {CAPS} are table driven, both to reduce the space needed for implementation and to increase the flexibility of the multilingual system. Over 500 students have used {CAPS} to learn Fortran, {PL/I,} or Cobol in conjunction with a computer assisted course on introductory computer science.},
	number = {11},
	journal = {Commun. {ACM}},
	year = {1976},
	keywords = {computer assisted instruction, computer science education, debugging, error correction, interactive programming, interpreters, table driven compilers},
	pages = {609--616}
},

@inproceedings{willcock_formalization_2004,
	author = {Jeremiah Willcock and Jaakko J{Ã¤}rvi and Andrew Lumsdaine and David Musser},
	title = {A Formalization of Concepts for Generic Programming},
	booktitle = {Concepts: a Linguistic Foundation of Generic Programming at Adobe Tech Summit},
	publisher = {{{Adobe} Systems}},
	year = {2004},
	keywords = {sibylle, wgp08}
},

@article{williams_broad-coverage_2017,
	author = {Adina Williams and Nikita Nangia and Samuel R Bowman},
	title = {A broad-coverage challenge corpus for sentence understanding through inference},
	journal = {arXiv preprint arXiv:1704.05426},
	year = {2017}
},

@book{williamson_vagueness_1994,
	author = {Timothy Williamson},
	publisher = {Routledge},
	title = {Vagueness},
	year = {1994}
},

@inproceedings{wu_effect_2014,
	author = {Nicolas Wu and Tom Schrijvers and Ralf Hinze},
	title = {Effect handlers in scope},
	booktitle = {Proceedings of the 2014 {ACM} {SIGPLAN} symposium on Haskell, Gothenburg,
               Sweden, September 4-5, 2014},
	pages = {1--12},
	year = {2014},
	url = {https://doi.org/10.1145/2633357.2633358},
	doi = {10.1145/2633357.2633358},
	timestamp = {Sat, 19 Oct 2019 20:24:41 +0200},
	biburl = {https://dblp.org/rec/bib/conf/haskell/WuSH14},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@article{xi_guarded_2003,
	author = {Hongwei Xi and Chiyan Chen and Gang Chen},
	title = {Guarded recursive datatype constructors},
	volume = {38},
	url = {http://portal.acm.org/citation.cfm?id=604150&dl=GUIDE&coll=GUIDE&CFID=38830212&CFTOKEN=12075942},
	doi = {10.1145/640128.604150},
	abstract = {We introduce a notion of guarded recursive (g.r.) datatype constructors, generalizing the notion of recursive datatypes in functional programming languages such as {ML} and Haskell. We address both theoretical and practical issues resulted from this generalization. On one hand, we design a type system to formalize the notion of g.r. datatype constructors and then prove the soundness of the type system. On the other hand, we present some significant applications (e.g., implementing objects, implementing staged computation, etc.) of g.r. datatype constructors, arguing that g.r. datatype constructors can have far-reaching consequences in programming. The main contribution of the paper lies in the recognition and then the formalization of a programming notion that is of both theoretical interest and practical use.},
	number = {1},
	journal = {{SIGPLAN} Not.},
	year = {2003},
	keywords = {{GADT,} guarded recursive datatype constructors},
	pages = {224--235},
	annote = {{{\textless}p{\textgreater}The} {GADT} paper{\textless}/p{\textgreater}}
},

@inproceedings{xu_static_2009,
	author = {Dana N. Xu and Simon {Peyton Jones} and Koen Claessen},
	file = {:/home/bernardy/Papers/Static contract checking for Haskell-2009.pdf:pdf},
	address = {Savannah, {GA,} {USA}},
	title = {Static contract checking for {H}askell},
	isbn = {978-1-60558-379-2},
	url = {http://portal.acm.org/citation.cfm?id=1480881.1480889},
	doi = {10.1145/1480881.1480889},
	abstract = {Program errors are hard to detect and are costly both to programmers who spend significant efforts in debugging, and for systems that are guarded by runtime checks. Static verification techniques have been applied to imperative and object-oriented languages, like Java and C\#, but few have been applied to a higher-order lazy functional language, like Haskell. In this paper, we describe a sound and automatic static verification framework for Haskell, that is based on contracts and symbolic execution. Our approach is modular and gives precise blame assignments at compile-time in the presence of higher-order functions and laziness.},
	booktitle = {Proceedings of the 36th annual {ACM} {SIGPLAN-SIGACT} symposium on Principles of programming languages},
	publisher = {{ACM}},
	year = {2009},
	keywords = {contract satisfaction, static contract checking},
	pages = {41--52}
},

@article{yang_overcoming_2017,
	author = {Yi Yang and Jacob Eisenstein},
	title = {Overcoming {{Language Variation}} in {{Sentiment Analysis}} with {{Social Attention}}},
	year = {2017},
	month = {dec},
	volume = {5},
	pages = {295--307},
	issn = {2307-387X},
	doi = {10.1162/tacl_a_00062},
	abstract = {Variation in language is ubiquitous, particularly in newer forms of writing such as social media. Fortunately, variation is not random; it is often linked to social properties of the author. In this paper, we show how to exploit social networks to make sentiment analysis more robust to social language variation. The key idea is linguistic homophily: the tendency of socially linked individuals to use language in similar ways. We formalize this idea in a novel attention-based neural network architecture, in which attention is divided among several basis models, depending on the author's position in the social network. This has the effect of smoothing the classification function across the social network, and makes it possible to induce personalized classifiers even for authors for whom there is no labeled data or demographic metadata. This model significantly improves the accuracies of sentiment analysis on Twitter and on review data.},
	journal = {Transactions of the Association for Computational Linguistics},
	language = {en}
},

@article{yogatama_memory_2018,
	author = {Dani Yogatama and Yishu Miao and Gabor Melis and Wang Ling and Adhiguna Kuncoro and Chris Dyer and Phil Blunsom},
	title = {Memory Architectures in Recurrent Neural Network Language Models},
	journal = {Proc. ICLR},
	year = {2018}
},

@inproceedings{yoshikawa_consistent_2018,
	author = {Masashi Yoshikawa and Koji Mineshima and Hiroshi Noji and Daisuke Bekki},
	editor = {Marilyn A. Walker and
               Heng Ji and
               Amanda Stent},
	title = {Consistent {CCG} Parsing over Multiple Sentences for Improved Logical
               Reasoning},
	booktitle = {Proceedings of the 2018 Conference of the North American Chapter of
               the Association for Computational Linguistics: Human Language Technologies,
               NAACL-HLT, New Orleans, Louisiana, USA, June 1-6, 2018, Volume 2 (Short
               Papers)},
	pages = {407--412},
	publisher = {Association for Computational Linguistics},
	year = {2018},
	url = {https://doi.org/10.18653/v1/n18-2065},
	doi = {10.18653/v1/n18-2065},
	timestamp = {Tue, 28 Jan 2020 10:30:20 +0100},
	biburl = {https://dblp.org/rec/conf/naacl/YoshikawaMNB18.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@inproceedings{yoshikawa_combining_2019,
	author = {Masashi Yoshikawa and Koji Mineshima and Hiroshi Noji and Daisuke Bekki},
	title = {Combining Axiom Injection and Knowledge Base Completion for Efficient
               Natural Language Inference},
	booktitle = {The Thirty-Third {AAAI} Conference on Artificial Intelligence, {AAAI}
               2019, The Thirty-First Innovative Applications of Artificial Intelligence
               Conference, {IAAI} 2019, The Ninth {AAAI} Symposium on Educational
               Advances in Artificial Intelligence, {EAAI} 2019, Honolulu, Hawaii,
               USA, January 27 - February 1, 2019},
	pages = {7410--7417},
	publisher = {{AAAI} Press},
	year = {2019},
	url = {https://doi.org/10.1609/aaai.v33i01.33017410},
	doi = {10.1609/aaai.v33i01.33017410},
	timestamp = {Fri, 27 Mar 2020 08:48:53 +0100},
	biburl = {https://dblp.org/rec/conf/aaai/YoshikawaMNB19.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@article{young_image_2014,
	author = {Peter Young and Alice Lai and Micah Hodosh and Julia Hockenmaier},
	title = {From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions},
	journal = {Transactions of the Association for Computational Linguistics},
	volume = {2},
	year = {2014},
	pages = {67--78}
},

@article{younger_recognition_1967,
	author = {D.H. Younger},
	title = {Recognition and parsing of context-free languages in time $n^3$},
	journal = {Information and control},
	volume = {10},
	number = {2},
	pages = {189--208},
	year = {1967},
	publisher = {Elsevier}
},

@inproceedings{yu_learning_2019,
	author = {Xiang Yu and Ngoc Thang Vu and Jonas Kuhn},
	title = {Learning the Dyck language with attention-based Seq2Seq models},
	booktitle = {Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
	pages = {138--146},
	year = {2019}
},

@InProceedings{zaenen_local_2005,
	author = {Annie Zaenen and Lauri Karttunen and Richard Crouch},
	title = {Local Textual Inference: can it be defined or circumscribed?},
	booktitle = {Proceedings of the ACL workshop on empirical modeling of semantic equivalence and entailment},
	year = {2005},
	organization = {Association for Computational Linguistics},
	pages = {31--36},
	timestamp = {2017.07.12}
},

@article{zaharia_spark_2010,
	author = {Matei Zaharia and Mosharaf Chowdhury and Michael J Franklin and Scott Shenker and Ion Stoica and  others},
	title = {Spark: Cluster computing with working sets.},
	journal = {HotCloud},
	volume = {10},
	number = {10-10},
	pages = {95},
	year = {2010}
},

@phdthesis{zeilberger_logical_2009,
	author = {Noam Zeilberger},
	file = {:/home/bernardy/Papers/The logical basis of evaluation order and pattern-matching-2009.pdf:pdf},
	title = {The logical basis of evaluation order and pattern-matching},
	year = {2009},
	school = {Carnegie Mellon University}
},

@article{zeller_unified_1997,
	author = {Andreas Zeller and Gregor Snelting},
	title = {Unified versioning through feature logic},
	volume = {6},
	url = {http://citeseer.ist.psu.edu/188532.html},
	abstract = {Software Configuration Management {(SCM)} suffers from tight coupling between {SCM} versioning models and the imposed {SCM} processes. In order to adapt {SCM} tools to {SCM} processes, rather than vice versa, we propose a unified versioning model, the version set model. Version sets denote versions, components, and configurations by feature terms, that is, boolean terms over (feature: value)-attributions. Through feature logic, we deduce consistency of abstract configurations as well as features of...},
	number = {4},
	journal = {{ACM} Transactions on Software Engineering and Methodology},
	year = {1997},
	keywords = {vc},
	pages = {398--441}
},

@inproceedings{zeller_yesterday_1999,
	author = {Andreas Zeller},
	title = {Yesterday, my program worked. Today, it does not. Why?},
	isbn = {0163-5948},
	url = {http://dx.doi.org/10.1145/318773.318946},
	booktitle = {{ESEC/FSE-7:} Proceedings of the 7th European software engineering conference held jointly with the 7th {ACM} {SIGSOFT} international symposium on Foundations of software engineering},
	publisher = {{Springer-Verlag}},
	year = {1999},
	keywords = {dd},
	pages = {253--267},
	annote = {How to find a minimal set of changes that introduced a bug. Various heuristics to avoid testing inconsistent subsets of changes.}
},

@incollection{zhu_safe_2005,
	author = {Dengping Zhu and Hongwei Xi},
	title = {Safe programming with pointers through stateful views},
	booktitle = {Practical Aspects of Declarative Languages},
	pages = {83--97},
	year = {2005},
	publisher = {Springer}
},

@phdthesis{bth_sjblom_agda_2013,
	author = {Thomas {Bååth Sjöblom}},
	type = {{MSc} Thesis},
	title = {An {Agda} proof of the correctness of {Valiant}'s algorithm for context free parsing},
	school = {Chalmers University of Technology},
	year = {2013}
},

@incollection{dal_lago_bounded_2009,
	author = {Ugo {Dal Lago} and Martin Hofmann},
	title = {Bounded linear logic, revisited},
	booktitle = {Typed Lambda Calculi and Applications},
	pages = {80--94},
	year = {2009},
	publisher = {Springer}
},

@article{dal_lago_linear_2011,
	author = {Ugo {Dal Lago} and Marco Gaboardi},
	title = {Linear Dependent Types and Relative Completeness},
	journal = {Logical Methods in Computer Science},
	volume = {8},
	number = {4},
	year = {2011},
	ee = {http://dx.doi.org/10.2168/LMCS-8(4:11)2012},
	bibsource = {DBLP, http://dblp.uni-trier.de}
},

@misc{free_software_foundation_gnu_1991,
	author = { {Free Software Foundation}},
	title = {GNU General Public License},
	version = {2},
	shorthand = {GPL},
	url = {http://www.gnu.org/licenses/gpl-2.0.html},
	year = {1991},
	month = {June}
},

@misc{free_software_foundation_gnu_2007,
	author = { {Free Software Foundation}},
	title = {GNU General Public License},
	version = {3},
	shorthand = {GPL},
	url = {http://www.gnu.org/licenses/gpl.html},
	pagination = {section},
	language = {english},
	year = {2007},
	month = {June},
	see = {:free_software_foundation_gnu_1991}
},

@phdthesis{lpez_juan_design_2015,
	author = {Victor {López Juan}},
	type = {(Work towards a {MSc} Thesis)},
	title = {Design and implementation of an Array Language with Linear Types},
	school = {Chalmers University of Technology},
	year = {2015}
},

@article{mcbride_view_2004,
	author = {Conor {McBride} and James {McKinna}},
	title = {The view from the left},
	volume = {14},
	number = {01},
	journal = {Journal of Functional Programming},
	year = {2004},
	pages = {69–111}
},

@article{mcbride_applicative_2007,
	author = {Conor {McBride} and Ross Paterson},
	file = {:/home/bernardy/Papers/Applicative programming with effects-2007.pdf:pdf},
	title = {Applicative programming with effects},
	volume = {18},
	doi = {10.1017/S0956796807006326},
	url = {http://www.journals.cambridge.org/abstract\_S0956796807006326},
	abstract = {In this article, we introduce Applicative functors â an abstract characterisation of an applicative style of effectful programming, weaker than Monads and hence more widespread. Indeed, it is the ubiquity of this programming pattern that drew us to the abstraction. We retrace our steps in this article, introducing the applicative pattern by diverse examples, then abstracting it to define the Applicative type class and introducing a bracket notation that interprets the normal application syntax in the idiom of an Applicative functor. Furthermore, we develop the properties of applicative functors and the generic operations they support. We close by identifying the categorical structure of applicative functors and examining their relationship both with Monads and with Arrow.},
	number = {01},
	journal = {Journal of Functional Programming},
	year = {2007},
	pages = {1--13}
},

@inproceedings{mcbride_clowns_2008,
	author = {Conor {McBride}},
	file = {:/home/bernardy/Papers/Clowns to the left of me, jokers to the right (pearl) dissecting data structures-2008.pdf:pdf},
	address = {San Francisco, California, {USA}},
	title = {Clowns to the left of me, jokers to the right (pearl): dissecting data structures},
	isbn = {978-1-59593-689-9},
	shorttitle = {Clowns to the left of me, jokers to the right (pearl)},
	url = {http://portal.acm.org/citation.cfm?id=1328474&dl=GUIDE&coll=GUIDE&CFID=17840475&CFTOKEN=88160233},
	doi = {10.1145/1328438.1328474},
	abstract = {This paper introduces a small but useful generalisation to the 'derivative' operation on datatypes underlying Huet's notion of 'zipper', giving a concrete representation to one-hole contexts in data which is undergoing transformation. This operator, 'dissection', turns a container-like functor into a bifunctor representing a one-hole context in which elements to the left of the hole are distinguished in type from elements to its right.},
	booktitle = {Proceedings of the 35th annual {ACM} {SIGPLAN-SIGACT} symposium on Principles of programming languages},
	publisher = {{ACM}},
	year = {2008},
	keywords = {datatype, differentiation, dissection, division, generic programming, iteration, stack, tail recursion, traversal, zipper},
	pages = {287--295}
},

@misc{mcbride_not_2010,
	author = {Conor {McBride}},
	title = {I am not a number, I am a classy Hack},
	year = {2010},
	note = {Weblog entry},
	url = {http://www.e-pig.org/epilogue/?p=773}
},

@inproceedings{mckinna_dependent_2006,
	author = {James {McKinna}},
	address = {Charleston, South Carolina, {USA}},
	title = {Why dependent types matter},
	isbn = {1-59593-027-2},
	doi = {10.1145/1111037.1111038},
	abstract = {Language designers have in recent years proposed a wealth of richer type systems for programming which seek to extend the range of statically enforced guarantees on data and code. Most such proposals have been evolutionary extensions of {ML} or Haskell, offering programmers a balanced compromise between expressive strength and existing well-understood technology. Typically they revolve around type- or kind-indexed types such as {GADTs,} supported by limited equality reasoning at the type-checking level, thus separating the dynamic behaviour of programs from the (simpler) static behaviour of indexing information occurring in their {types.I} want to argue in this talk for a more radical departure from such practice by examining full spectrum type dependency, lifting such restrictions on the data upon which types may depend. Conor {McBride} and I designed the language {EPIGRAM} for experiments in programming with inductive families of data (of which {GADTs} are a special case). Using it for illustration, I will explore some of the possibilities and challenges afforded by full spectrum type dependency at the static and dynamic level:},
	booktitle = {Conference record of the 33rd {ACM} {SIGPLAN-SIGACT} symposium on Principles of programming languages},
	publisher = {{ACM}},
	year = {2006},
	pages = {1--1}
},

@incollection{paulin-mohring_inductive_1993,
	author = {Christine {Paulin-Mohring}},
	file = {:/home/bernardy/Papers/Inductive definitions in the system Coq -- rules and properties-1993.pdf:pdf},
	title = {Inductive definitions in the system {Coq} -- rules and properties},
	url = {http://dx.doi.org/10.1007/BFb0037116},
	abstract = {In the pure Calculus of Constructions, it is possible to represent data structures and predicates using higher-order quantification. However, this representation is not satisfactory, from the point of view of both the efficiency of the underlying programs and the power of the logical system. For these reasons, the calculus was extended with a primitive notion of inductive definitions [8]. This paper describes the rules for inductive definitions in the system Coq. They are general enough to be seen as one formulation of adding inductive definitions to a typed lambda-calculus. We prove strong normalization for a subsystem of Coq corresponding to the pure Calculus of Constructions plus Inductive Definitions with only weak eliminations.},
	booktitle = {Typed Lambda Calculi and Applications},
	editor = {Marc Bezem and Jan Friso Groote},
	publisher = {Springer},
	year = {1993},
	pages = {328--345}
},

@misc{peyton_jones_bulk_1996,
	author = {Simon {Peyton Jones}},
	title = {Bulk types with class},
	url = {http://citeseer.ist.psu.edu/peytonjones97bulk.html},
	abstract = {Bulk types --- such as lists, bags, sets, finite maps, and priority queues --- are ubiquitous in programming. Yet many languages don't support them well, even though they have received a great deal of attention, especially from the database community. Haskell is currently among the culprits. This paper has two aims: to identify some of the technical difficulties, and to attempt to address them using Haskell's constructor classes. This paper appears in the proceedings of the 1997 Haskell...},
	year = {1996},
	keywords = {typeclass}
},

@inproceedings{peyton_jones_concurrent_1996,
	author = {Simon {Peyton Jones} and Andrew D. Gordon and Sigbjörn Finne},
	editor = {Hans{-}Juergen Boehm and
               Guy L. Steele Jr.},
	title = {Concurrent Haskell},
	booktitle = {Conference Record of POPL'96: The 23rd {ACM} {SIGPLAN-SIGACT} Symposium
               on Principles of Programming Languages, Papers Presented at the Symposium,
               St. Petersburg Beach, Florida, USA, January 21-24, 1996},
	pages = {295--308},
	publisher = {{ACM} Press},
	year = {1996},
	url = {https://doi.org/10.1145/237721.237794},
	doi = {10.1145/237721.237794},
	timestamp = {Tue, 25 Jun 2019 09:29:17 +0200},
	biburl = {https://dblp.org/rec/conf/popl/JonesGF96.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@inproceedings{peyton_jones_type_1997,
	author = {Simon {Peyton Jones} and Mark Jones and Erik Meijer},
	title = {Type classes: an exploration of the design space},
	url = {http://research.microsoft.com/en-us/um/people/simonpj/papers/type-class-design-space/},
	abstract = {When type classes were first introduced in Haskell they were regarded as a fairly experimental language feature, and therefore warranted a fairly conservative design. Since that time, practical experience has convinced many programmers of the benefits and convenience of type classes. However, on occasion, these same programmers have discovered examples where seemingly natural applications for type class overloading are prevented by the restrictions imposed by the Haskell design. It is possible...},
	year = {1997},
	keywords = {typeclass},
	booktitle = {{Haskell} Workshop}
},

@inproceedings{peyton_jones_stretching_1999,
	author = {Simon {Peyton Jones} and Simon Marlow and Conal Elliott},
	editor = {Pieter W. M. Koopman and
               Chris Clack},
	title = {Stretching the Storage Manager: Weak Pointers and Stable Names in
               Haskell},
	booktitle = {Implementation of Functional Languages, 11th International Workshop,
               IFL'99, Lochem, The Netherlands, September 7-10, 1999, Selected Papers},
	series = {Lecture Notes in Computer Science},
	volume = {1868},
	pages = {37--58},
	publisher = {Springer},
	year = {1999},
	url = {https://doi.org/10.1007/10722298\_3},
	doi = {10.1007/10722298\_3},
	timestamp = {Tue, 14 May 2019 10:00:35 +0200},
	biburl = {https://dblp.org/rec/conf/ifl/JonesME99.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},

@book{peyton_jones_haskell_2003,
	author = {Simon {Peyton Jones}},
	title = {Haskell 98 Language and Libraries: the Revised Report},
	publisher = {Cambridge University Press},
	year = {2003}
},

@misc{peyton_jones_wearing_2003,
	author = {Simon {Peyton Jones}},
	title = {Wearing the hair shirt: a retrospective on Haskell (2003)},
	year = {2003},
	month = {January},
	abstract = {Haskell was 15 years old at the POPL'03 meeting, when I presented this talk: it was born at a meeting at the 1987 conference on Functional Programming and Computer Architecture (FPCA'87). In this talk, which is very much a personal view, I take a look back at the language, and try to tease out what we have learned from the experience of designing and implementing it. The main areas I discuss are: syntax (briefly), laziness (the hair shirt of the title), type classes, and sexy types. On the way, I try to identify a few open questions that I think merit further study.
},
	url = {https://www.microsoft.com/en-us/research/publication/wearing-hair-shirt-retrospective-haskell-2003/},
	edition = {invited talk at POPL 2003},
	note = {invited talk at POPL 2003}
},

@misc{peyton_jones_write_2004,
	author = {Simon {Peyton Jones}},
	file = {:/home/bernardy/Papers/How to Write a Great Research Paper-2004.pdf:pdf},
	number = {2},
	pages = {844--138},
	title = {{How to Write a Great Research Paper}},
	volume = {8},
	year = {2004}
},

@Article{peyton_jones_practical_2007,
	author = {Simon {Peyton Jones} and Dimitrios Vytiniotis and Stephanie Weirich and Mark Shields},
	Title = {Practical type inference for arbitrary-rank types},
	Journal = {Journal of Functional Programming},
	Year = {2007},
	Month = {jan},
	Number = {1},
	Volume = {17},
	Owner = {rae},
	Timestamp = {2015.05.08}
},

@inproceedings{peyton_jones_harnessing_2008,
	author = {Simon {Peyton Jones} and Roman Leshchinskiy and Gabriele Keller and Manuel Chakravarty},
	file = {:/home/bernardy/Papers/Harnessing the multicores Nested data parallelism in Haskell-2008.pdf:pdf},
	title = {Harnessing the multicores: Nested data parallelism in Haskell},
	booktitle = {IARCS Annual Conference on Foundations of Software Technology and Theoretical Computer Science (FSTTCS 2008), Dagstuhl, Germany},
	year = {2008},
	organization = {Citeseer}
},

@InCollection{peyton_jones_reflection_2016,
	author = {Simon {Peyton Jones} and Stephanie Weirich and Richard A. Eisenberg and Dimitrios Vytiniotis},
	Title = {A reflection on types},
	Booktitle = {A list of successes that can change the world},
	Publisher = {Springer},
	Year = {2016},
	Note = {A festschrift in honor of Phil Wadler},
	Series = {LNCS},
	Owner = {rae},
	Timestamp = {2016.06.28}
},

@book{sun_tzu_art_2003,
	author = { {Sun Tzu}},
	authorChinese = {孫武},
	title = {{The Art of War}},
	isbn = {0140439196},
	year = {2003},
	publisher = {Penguin Classics}
},

@article{van_oosten_realizability_2002,
	author = {Jaap {Van Oosten}},
	title = {{Realizability: a historical essay}},
	journal = {Mathematical Structures in Computer Science},
	volume = {12},
	number = {03},
	pages = {239--263},
	year = {2002},
	publisher = {Cambridge Univ Press}
},

@inproceedings{da_silva_lighthouse_2006,
	author = {Isabella {da Silva} and Ping Chen and Christopher Van der Westhuizen and Roger Ripley and Andr{\textbackslash}'e van der Hoek},
	title = {Lighthouse: coordination through emerging design},
	isbn = {1595936211},
	url = {http://dx.doi.org/10.1145/1188835.1188838},
	booktitle = {eclipse '06: Proceedings of the 2006 {OOPSLA} workshop on eclipse technology {eXchange}},
	publisher = {{ACM} Press},
	year = {2006},
	keywords = {conflict-avoidance},
	pages = {11--15}
},

@inproceedings{de_bruijn_lambda_1972,
	author = {Nicolaas Govert {de Bruijn}},
	title = {Lambda calculus notation with nameless dummies},
	booktitle = {Indagationes Mathematicae},
	volume = {34},
	year = {1972},
	organization = {Elsevier}
},

@book{van_eijck_computational_2010,
	author = {Jan {van Eijck} and Christina Unger},
	address = {Cambridge},
	title = {Computational {Semantics} with {Functional} {Programming}},
	isbn = {978-0-521-76030-0},
	url = {https://www.cambridge.org/core/books/computational-semantics-with-functional-programming/0D3BAC27C39751AE4FF7F08FCC1C1364},
	abstract = {Computational semantics is the art and science of computing meaning in natural language. The meaning of a sentence is derived from the meanings of the individual words in it, and this process can be made so precise that it can be implemented on a computer. Designed for students of linguistics, computer science, logic and philosophy, this comprehensive text shows how to compute meaning using the functional programming language Haskell. It deals with both denotational meaning (where meaning comes from knowing the conditions of truth in situations), and operational meaning (where meaning is an instruction for performing cognitive action). Including a discussion of recent developments in logic, it will be invaluable to linguistics students wanting to apply logic to their studies, logic students wishing to learn how their subject can be applied to linguistics, and functional programmers interested in natural language processing as a new application area.},
	urldate = {2021-02-20},
	publisher = {Cambridge University Press},
	year = {2010},
	doi = {10.1017/CBO9780511778377}
},

@incollection{van_eijck_probabilistic_2012,
	author = {Jan {van Eijck} and Shalom Lappin},
	Address = {University of Amsterdam},
	Booktitle = {Logic and Interactive Rationality (LIRA), Volume 2},
	Editor = {Z. Christoff and P. Galeazzi and N. Gierasimszuk and A. Marcoci and S. Smets},
	Publisher = {ILLC},
	Title = {Probabilistic Semantics for Natural Language},
	abstract = {Probabilistic and stochastic methods have been fruitfully applied to a widevariety of problems in grammar induction,  natural language processing, and cognitive modeling. In this paper we explore the possibility of developing a class of combinatorial semantic representations for natural languages that compute the semantic value of a (declarative) sentence as a probabilityvalue which expresses the likelihood of competent speakers of the languageaccepting the sentence as true in a given model, relative to a specificationof the world.  Such an approach to semantic representation treats the pervasive gradience of semantic properties as intrinsic to speakers’ linguisticknowledge, rather than the result of the interference of performance factors in processing and interpretation. In order for this research program to succeed, it must solve three central problems.  First, it needs to formulatea type system that computes the probability value of a sentence from thesemantic values of its syntactic constituents. Second, it must incorporate aviable probabilistic logic into the representation of semantic knowledge inorder to model meaning entailment. Finally, it must show how the specifiedclass of semantic representations can be efficiently learned.  We construct a probabilistic semantic fragment and consider how the approach that the fragment instantiates addresses each of these three issues.},
	booktitle = {Logic and interactive rationality ({LIRA})},
	publisher = {Citeseer},
	editor = {Christoff, Zo{\textbackslash}'e and Galeazzi, Paolo and Gierasimczuk, Nina and Marcoci, Alexandru and Smets, Sonya},
	year = {2012},
	pages = {17--35}
},

@misc{the_coq_development_team_coq_2010,
	author = { {{The} Coq development team}},
	title = {The {{Coq}} proof assistant},
	url = {http://coq.inria.fr},
	year = {2010},
	see = {:the_coq_development_team_coq_2011;:the_coq_development_team_coq_2012}
},

@misc{the_coq_development_team_coq_2011,
	author = { {{The} Coq development team}},
	title = {The {{Coq}} proof assistant},
	url = {http://coq.inria.fr},
	year = {2011}
},

@misc{the_coq_development_team_coq_2012,
	author = { {{The} Coq development team}},
	title = {The {{Coq}} proof assistant},
	url = {http://coq.inria.fr},
	year = {2012},
	see = {:the_coq_development_team_coq_2011}
},

@misc{the_ghc_team_unique_2013,
	author = { {{The} GHC Team}},
	title = {The  Unique supply implementation of the Glasgow Haskell Compiler},
	url = {https://github.com/ghc/ghc/blob/master/compiler/basicTypes/UniqSupply.lhs},
	note = {retrieved Nov. 2013},
	year = {2013}
},

@misc{wikipedia_contributors_software_2009,
	author = { {{Wikipedia} contributors}},
	title = {Software engineering},
	url = {http://en.wikipedia.org/w/index.php?title=Software_engineering&oldid=313559997},
	journal = {Wikipedia, The Free Encyclopedia},
	publisher = {Wikimedia Foundation},
	month = {sep},
	year = {2009}
},

